{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connect Four RL - Training with Live Metrics\n",
        "\n",
        "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –ø–æ–∑–≤–æ–ª—è–µ—Ç:\n",
        "- –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è\n",
        "- –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ DQN –∏–ª–∏ Q-learning –∞–≥–µ–Ω—Ç–∞\n",
        "- –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ò–º–ø–æ—Ä—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!\n"
          ]
        }
      ],
      "source": [
        "# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥—É–ª–µ–π –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ (autoreload)\n",
        "# –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–º–µ–Ω—è—Ç—å –∫–æ–¥ –≤ .py —Ñ–∞–π–ª–∞—Ö –±–µ–∑ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ —è–¥—Ä–∞ –Ω–æ—É—Ç–±—É–∫–∞\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# –ò–º–ø–æ—Ä—Ç—ã\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import clear_output, display\n",
        "import threading\n",
        "from collections import defaultdict\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É\n",
        "sys.path.insert(0, str(Path().resolve().parent))\n",
        "\n",
        "from src.envs import Connect4Env, RewardConfig\n",
        "from src.agents import DQNAgent, QLearningAgent, RandomAgent, HeuristicAgent, SmartHeuristicAgent\n",
        "from src.utils import MetricsLogger\n",
        "from src.selfplay import SelfPlayConfig\n",
        "from src.training.random_opening import RandomOpeningConfig\n",
        "from src.training.train_dqn import train_dqn\n",
        "from src.training.train_qlearning import train_qlearning\n",
        "\n",
        "print(\"–ò–º–ø–æ—Ä—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã!\n",
            "–¢–∏–ø –º–æ–¥–µ–ª–∏: dqn\n",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤: 100000\n",
            "\n",
            "–ù–∞–≥—Ä–∞–¥—ã:\n",
            "  –ü–æ–±–µ–¥–∞: 1.0\n",
            "  –ü–æ—Ä–∞–∂–µ–Ω–∏–µ: -1.0\n",
            "  –ù–∏—á—å—è: 0.0\n",
            "  3 –≤ —Ä—è–¥: 0.01\n",
            "  –í—Ä–∞–∂–µ—Å–∫–∏–µ 3 –≤ —Ä—è–¥ (—à—Ç—Ä–∞—Ñ): -0.01\n",
            "  –ù–µ–≤–µ—Ä–Ω—ã–π —Ö–æ–¥: -0.1\n",
            "\n",
            "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–≤—Ä–∏—Å—Ç–∏–∫: {'random': 0.1, 'heuristic': 0.7, 'smart_heuristic': 0.2}\n",
            "\n",
            "Self-play:\n",
            "  –°—Ç–∞—Ç—É—Å: –≤–∫–ª—é—á–µ–Ω\n",
            "  –ù–∞—á–∞–ª–æ —Å —ç–ø–∏–∑–æ–¥–∞: 10000\n",
            "  –î–æ–ª—è self-play: 50.0%\n",
            "  –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ: 500 —ç–ø–∏–∑–æ–¥–æ–≤\n",
            "  –ú–∞–∫—Å. frozen –∞–≥–µ–Ω—Ç–æ–≤: 20\n",
            "\n",
            "Random opening:\n",
            "  –°—Ç–∞—Ç—É—Å: –≤–∫–ª—é—á–µ–Ω\n",
            "  –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: 0.50\n",
            "  –ü–æ–ª—É—Ö–æ–¥—ã: 2-6\n"
          ]
        }
      ],
      "source": [
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è\n",
        "TRAINING_CONFIG = {\n",
        "    # –¢–∏–ø –º–æ–¥–µ–ª–∏\n",
        "    \"model_type\": \"dqn\",  # \"dqn\" –∏–ª–∏ \"qlearning\"\n",
        "    \"network_type\": \"dueling_dqn\", \n",
        "    \n",
        "    \n",
        "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è\n",
        "    \"num_episodes\": 100000,\n",
        "    \"learning_rate\": 0.0005,\n",
        "    \"discount_factor\": 0.99,\n",
        "    \"epsilon\": 1.0,\n",
        "    \"epsilon_decay\": 0.9995,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 0.995 –¥–ª—è –±–æ–ª–µ–µ –º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ decay\n",
        "    # 0.995 -> –º–∏–Ω–∏–º—É–º –Ω–∞ —ç–ø–∏–∑–æ–¥–µ ~919 (—Å–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä–æ)\n",
        "    # 0.999 -> –º–∏–Ω–∏–º—É–º –Ω–∞ —ç–ø–∏–∑–æ–¥–µ ~4603\n",
        "    # 0.9995 -> –º–∏–Ω–∏–º—É–º –Ω–∞ —ç–ø–∏–∑–æ–¥–µ ~9209 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è 50000 —ç–ø–∏–∑–æ–¥–æ–≤)\n",
        "    # 0.9999 -> –º–∏–Ω–∏–º—É–º –Ω–∞ —ç–ø–∏–∑–æ–¥–µ ~46050 (–æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ)\n",
        "    \"epsilon_min\": 0.03,\n",
        "    \n",
        "    # DQN —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è –¥–ª—è Q-learning)\n",
        "    \"batch_size\": 32,\n",
        "    \"replay_buffer_size\": 20000,\n",
        "    \"target_update_freq\": 100,\n",
        "    \"soft_update\": True,\n",
        "    \"tau\": 0.01,\n",
        "    \n",
        "    # –û—Ü–µ–Ω–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
        "    \"eval_freq\": 100,\n",
        "    \"eval_episodes\": 100,\n",
        "    \"save_freq\": 1000,\n",
        "    \n",
        "    # –ü—É—Ç–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞)\n",
        "    \"checkpoint_dir\": str(Path().resolve().parent / \"data\" / \"checkpoints\"),\n",
        "    \"log_dir\": str(Path().resolve().parent / \"data\" / \"logs\"),\n",
        "    \n",
        "    # –î—Ä—É–≥–∏–µ\n",
        "    \"device\": None,  # None –¥–ª—è auto-detect, –∏–ª–∏ \"cuda\" –∏–ª–∏ \"cpu\"\n",
        "    \"seed\": 42,\n",
        "}\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞–≥—Ä–∞–¥\n",
        "REWARD_CONFIG = RewardConfig(\n",
        "    win=1.0,  # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –ø–æ–±–µ–¥—É\n",
        "    loss=-1.0,  # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –ø–æ—Ä–∞–∂–µ–Ω–∏–µ\n",
        "    draw=0.0,  # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –Ω–∏—á—å—é\n",
        "    three_in_row=0.01,  # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ 3 –≤ —Ä—è–¥ (–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞)\n",
        "    opponent_three_in_row=-0.01,  # –®—Ç—Ä–∞—Ñ –∑–∞ –≤—Ä–∞–∂–µ—Å–∫–∏–µ 3 –≤ —Ä—è–¥ (–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —à—Ç—Ä–∞—Ñ)\n",
        "    invalid_action=-0.1,  # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –Ω–µ–≤–µ—Ä–Ω—ã–π —Ö–æ–¥\n",
        ")\n",
        "\n",
        "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –æ–ø–ø–æ–Ω–µ–Ω—Ç–æ–≤\n",
        "HEURISTIC_DISTRIBUTION = {\n",
        "    \"random\": 0.1,\n",
        "    \"heuristic\": 0.7,\n",
        "    \"smart_heuristic\": 0.2,\n",
        "}\n",
        "\n",
        "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è self-play (–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π —Å–µ–±—è)\n",
        "# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ SELF_PLAY_CONFIG = None, —á—Ç–æ–±—ã –æ—Ç–∫–ª—é—á–∏—Ç—å self-play\n",
        "SELF_PLAY_CONFIG = SelfPlayConfig(\n",
        "    start_episode=10000,  # –° –∫–∞–∫–æ–≥–æ —ç–ø–∏–∑–æ–¥–∞ –Ω–∞—á–∏–Ω–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å frozen DQN\n",
        "    save_every=500,  # –ö–∞–∫ —á–∞—Å—Ç–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—É—é \"–≤–µ—Ä—Å–∏—é —Å–µ–±—è\" –≤ –ø—É–ª (–º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –æ—Ç save_freq)\n",
        "    max_frozen_agents=20,  # –°–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π –º–∞–∫—Å–∏–º—É–º –¥–µ—Ä–∂–∞—Ç—å –≤ –ø—É–ª–µ\n",
        "    fraction=0.5,  # –î–æ–ª—è —ç–ø–∏–∑–æ–¥–æ–≤, –≥–¥–µ –æ–ø–ø–æ–Ω–µ–Ω—Ç = frozen DQN (0.0-1.0)\n",
        ")\n",
        "\n",
        "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö —Å—Ç–∞—Ä—Ç–æ–≤—ã—Ö –ø–æ–∑–∏—Ü–∏–π (–ø—Ä–æ–ª–æ–≥ –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º –∞–≥–µ–Ω—Ç–∞)\n",
        "# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ RANDOM_OPENING_CONFIG = None, —á—Ç–æ–±—ã –æ—Ç–∫–ª—é—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–ª–æ–≥\n",
        "RANDOM_OPENING_CONFIG = RandomOpeningConfig(\n",
        "    probability=0.5,  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–∞–ø—É—Å–∫–∞ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø—Ä–æ–ª–æ–≥–∞ –ø–µ—Ä–µ–¥ —ç–ø–∏–∑–æ–¥–æ–º\n",
        "    min_half_moves=2,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—É—Ö–æ–¥–æ–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø—Ä–æ–ª–æ–≥–∞\n",
        "    max_half_moves=6,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—É—Ö–æ–¥–æ–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø—Ä–æ–ª–æ–≥–∞\n",
        ")\n",
        "\n",
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "PLOT_CONFIG = {\n",
        "    \"update_freq\": 50,  # –û–±–Ω–æ–≤–ª—è—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ –∫–∞–∂–¥—ã–µ N —ç–ø–∏–∑–æ–¥–æ–≤\n",
        "    \"metrics_to_plot\": [\n",
        "        \"win_rate\",\n",
        "        \"loss_rate\",\n",
        "        \"episode_reward\",\n",
        "        \"episode_length\",\n",
        "        \"epsilon\",\n",
        "        \"train_loss\",\n",
        "        \"train_avg_q\",\n",
        "        \"train_td_error\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "print(\"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã!\")\n",
        "print(f\"–¢–∏–ø –º–æ–¥–µ–ª–∏: {TRAINING_CONFIG['model_type']}\")\n",
        "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤: {TRAINING_CONFIG['num_episodes']}\")\n",
        "print(f\"\\n–ù–∞–≥—Ä–∞–¥—ã:\")\n",
        "print(f\"  –ü–æ–±–µ–¥–∞: {REWARD_CONFIG.win}\")\n",
        "print(f\"  –ü–æ—Ä–∞–∂–µ–Ω–∏–µ: {REWARD_CONFIG.loss}\")\n",
        "print(f\"  –ù–∏—á—å—è: {REWARD_CONFIG.draw}\")\n",
        "print(f\"  3 –≤ —Ä—è–¥: {REWARD_CONFIG.three_in_row}\")\n",
        "print(f\"  –í—Ä–∞–∂–µ—Å–∫–∏–µ 3 –≤ —Ä—è–¥ (—à—Ç—Ä–∞—Ñ): {REWARD_CONFIG.opponent_three_in_row}\")\n",
        "print(f\"  –ù–µ–≤–µ—Ä–Ω—ã–π —Ö–æ–¥: {REWARD_CONFIG.invalid_action}\")\n",
        "print(f\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–≤—Ä–∏—Å—Ç–∏–∫: {HEURISTIC_DISTRIBUTION}\")\n",
        "print(\"\\nSelf-play:\")\n",
        "if SELF_PLAY_CONFIG is None:\n",
        "    print(\"  –°—Ç–∞—Ç—É—Å: –æ—Ç–∫–ª—é—á–µ–Ω\")\n",
        "else:\n",
        "    print(\"  –°—Ç–∞—Ç—É—Å: –≤–∫–ª—é—á–µ–Ω\")\n",
        "    print(f\"  –ù–∞—á–∞–ª–æ —Å —ç–ø–∏–∑–æ–¥–∞: {SELF_PLAY_CONFIG.start_episode}\")\n",
        "    print(f\"  –î–æ–ª—è self-play: {SELF_PLAY_CONFIG.fraction:.1%}\")\n",
        "    print(f\"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ: {SELF_PLAY_CONFIG.save_every} —ç–ø–∏–∑–æ–¥–æ–≤\")\n",
        "    print(f\"  –ú–∞–∫—Å. frozen –∞–≥–µ–Ω—Ç–æ–≤: {SELF_PLAY_CONFIG.max_frozen_agents}\")\n",
        "\n",
        "print(\"\\nRandom opening:\")\n",
        "if RANDOM_OPENING_CONFIG is None:\n",
        "    print(\"  –°—Ç–∞—Ç—É—Å: –æ—Ç–∫–ª—é—á–µ–Ω\")\n",
        "else:\n",
        "    print(\"  –°—Ç–∞—Ç—É—Å: –≤–∫–ª—é—á–µ–Ω\")\n",
        "    print(f\"  –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {RANDOM_OPENING_CONFIG.probability:.2f}\")\n",
        "    print(f\"  –ü–æ–ª—É—Ö–æ–¥—ã: {RANDOM_OPENING_CONFIG.min_half_moves}-{RANDOM_OPENING_CONFIG.max_half_moves}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –º–µ—Ç—Ä–∏–∫\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_metrics_from_csv(log_dir: str, metrics_file: str = None) -> pd.DataFrame:\n",
        "    \"\"\"–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ CSV —Ñ–∞–π–ª–∞.\n",
        "    \n",
        "    Args:\n",
        "        log_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –ª–æ–≥–∞–º–∏\n",
        "        metrics_file: –ü—É—Ç—å –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ñ–∞–π–ª—É –º–µ—Ç—Ä–∏–∫ (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è)\n",
        "    \"\"\"\n",
        "    if metrics_file and Path(metrics_file).exists():\n",
        "        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π —Ñ–∞–π–ª\n",
        "        df = pd.read_csv(metrics_file)\n",
        "        return df\n",
        "    \n",
        "    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏!)\n",
        "    csv_files = list(Path(log_dir).glob(\"metrics_*.csv\"))\n",
        "    if not csv_files:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è (st_ctime), –∞ –Ω–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "    # –≠—Ç–æ –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ, —Ç–∞–∫ –∫–∞–∫ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –æ–±—É—á–µ–Ω–∏—è\n",
        "    latest_file = max(csv_files, key=lambda x: x.stat().st_ctime)\n",
        "    df = pd.read_csv(latest_file)\n",
        "    return df\n",
        "\n",
        "def plot_metrics(df: pd.DataFrame, metrics_to_plot: list, figsize=(15, 10)):\n",
        "    \"\"\"–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ –º–µ—Ç—Ä–∏–∫.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤\")\n",
        "        return\n",
        "    \n",
        "    n_metrics = len(metrics_to_plot)\n",
        "    n_cols = 2\n",
        "    n_rows = (n_metrics + n_cols - 1) // n_cols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
        "    if n_metrics == 1:\n",
        "        axes = [axes]\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "    \n",
        "    for i, metric in enumerate(metrics_to_plot):\n",
        "        if metric not in df.columns:\n",
        "            continue\n",
        "        \n",
        "        ax = axes[i]\n",
        "        ax.plot(df['step'], df[metric], label=metric, linewidth=2)\n",
        "        ax.set_xlabel('Episode')\n",
        "        ax.set_ylabel(metric)\n",
        "        ax.set_title(f'{metric} over time')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend()\n",
        "        \n",
        "        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
        "        if len(df) > 0:\n",
        "            last_val = df[metric].iloc[-1]\n",
        "            ax.axhline(y=last_val, color='r', linestyle='--', alpha=0.5)\n",
        "            ax.text(len(df), last_val, f'{last_val:.3f}', \n",
        "                   verticalalignment='bottom', fontsize=9)\n",
        "    \n",
        "    # –°–∫—Ä—ã–≤–∞–µ–º –ª–∏—à–Ω–∏–µ subplots\n",
        "    for i in range(n_metrics, len(axes)):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_win_rate_comparison(df: pd.DataFrame):\n",
        "    \"\"\"–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è win/draw/loss rates.\"\"\"\n",
        "    if df.empty or 'win_rate' not in df.columns:\n",
        "        return\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    \n",
        "    if 'win_rate' in df.columns:\n",
        "        ax.plot(df['step'], df['win_rate'], label='Win Rate', color='green', linewidth=2)\n",
        "    if 'draw_rate' in df.columns:\n",
        "        ax.plot(df['step'], df['draw_rate'], label='Draw Rate', color='gray', linewidth=2)\n",
        "    if 'loss_rate' in df.columns:\n",
        "        ax.plot(df['step'], df['loss_rate'], label='Loss Rate', color='red', linewidth=2)\n",
        "    \n",
        "    ax.set_xlabel('Episode')\n",
        "    ax.set_ylabel('Rate')\n",
        "    ax.set_title('Win/Draw/Loss Rates over Time')\n",
        "    ax.set_ylim([0, 1])\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"–§—É–Ω–∫—Ü–∏–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–æ—Ç–æ–≤—ã!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π\n",
        "\n",
        "–ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ. –ì—Ä–∞—Ñ–∏–∫–∏ –±—É–¥—É—Ç –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è:\n",
            "   Checkpoints: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602\n",
            "   Logs: /home/holidin/projects/RL/data/logs/dqn_20251110_220602\n",
            "–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...\n",
            "–û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ!\n",
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é —è—á–µ–π–∫—É –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting DQN training...\n",
            "Network architecture: DUELING_DQN\n",
            "Episodes: 100000\n",
            "Learning rate: 0.0005\n",
            "Discount factor: 0.99\n",
            "Initial epsilon: 1.0\n",
            "Target update: soft (freq: 100)\n",
            "Soft update tau: 0.01\n",
            "Device: cuda\n",
            "Heuristic distribution: {'random': 0.1, 'heuristic': 0.7, 'smart_heuristic': 0.2}\n",
            "Self-play: configured\n",
            "  Start episode: 10000\n",
            "  Self-play fraction: 50.0%\n",
            "  Save every: 500 episodes\n",
            "  Max frozen agents: 20\n",
            "Random opening: p=0.50, half-moves=2-6\n",
            "\n",
            "  Detailed metrics: Max Q: 0.5504 | Min Q: -0.9187 | Target Q: -0.1189 | Grad Norm (clipped): 0.1702 | Total train steps: 394 | Step count: 425\n",
            "Episode 100/100000 | Win: 16.00% | Draw: 0.00% | Loss: 84.00% | Epsilon: 0.9512 | Buffer: 762/20000 (3.8%) | Train steps: 7 | Loss: 0.0068 | Avg Q: -0.1408 | TD Error: 0.0544 | Grad Norm: 0.1340\n",
            "  Detailed metrics: Max Q: 0.3195 | Min Q: -1.0010 | Target Q: -0.1403 | Grad Norm (clipped): 0.1340 | Total train steps: 731 | Step count: 762\n",
            "  Detailed metrics: Max Q: 0.2715 | Min Q: -1.0096 | Target Q: -0.1434 | Grad Norm (clipped): 0.1403 | Total train steps: 1099 | Step count: 1130\n",
            "Episode 200/100000 | Win: 17.00% | Draw: 0.00% | Loss: 83.00% | Epsilon: 0.9048 | Buffer: 1511/20000 (7.6%) | Train steps: 14 | Loss: 0.0066 | Avg Q: -0.1595 | TD Error: 0.0497 | Grad Norm: 0.1292\n",
            "  Detailed metrics: Max Q: 0.3138 | Min Q: -1.0585 | Target Q: -0.1670 | Grad Norm (clipped): 0.1292 | Total train steps: 1480 | Step count: 1511\n",
            "  Detailed metrics: Max Q: 0.7368 | Min Q: -1.0622 | Target Q: -0.1415 | Grad Norm (clipped): 0.1031 | Total train steps: 1890 | Step count: 1921\n",
            "Episode 300/100000 | Win: 12.00% | Draw: 1.00% | Loss: 87.00% | Epsilon: 0.8607 | Buffer: 2371/20000 (11.9%) | Train steps: 12 | Loss: 0.0104 | Avg Q: -0.1153 | TD Error: 0.0502 | Grad Norm: 0.1322\n",
            "  Detailed metrics: Max Q: 0.2788 | Min Q: -1.0431 | Target Q: -0.1226 | Grad Norm (clipped): 0.1322 | Total train steps: 2340 | Step count: 2371\n",
            "  Detailed metrics: Max Q: 0.5277 | Min Q: -1.0498 | Target Q: -0.1393 | Grad Norm (clipped): 0.1355 | Total train steps: 2758 | Step count: 2789\n",
            "Episode 400/100000 | Win: 13.00% | Draw: 0.00% | Loss: 87.00% | Epsilon: 0.8187 | Buffer: 3137/20000 (15.7%) | Train steps: 13 | Loss: 0.0108 | Avg Q: -0.1741 | TD Error: 0.0533 | Grad Norm: 0.1581\n",
            "  Detailed metrics: Max Q: 0.5202 | Min Q: -1.0552 | Target Q: -0.1775 | Grad Norm (clipped): 0.1581 | Total train steps: 3106 | Step count: 3137\n",
            "  Detailed metrics: Max Q: 0.0122 | Min Q: -1.0614 | Target Q: -0.1316 | Grad Norm (clipped): 0.1557 | Total train steps: 3448 | Step count: 3479\n",
            "Episode 500/100000 | Win: 15.00% | Draw: 0.00% | Loss: 85.00% | Epsilon: 0.7788 | Buffer: 3897/20000 (19.5%) | Train steps: 9 | Loss: 0.0089 | Avg Q: -0.1836 | TD Error: 0.0478 | Grad Norm: 0.1252\n",
            "  Detailed metrics: Max Q: 0.3982 | Min Q: -1.0933 | Target Q: -0.1882 | Grad Norm (clipped): 0.1252 | Total train steps: 3866 | Step count: 3897\n",
            "  Detailed metrics: Max Q: 0.1683 | Min Q: -1.0930 | Target Q: -0.1475 | Grad Norm (clipped): 0.1049 | Total train steps: 4334 | Step count: 4365\n",
            "Episode 600/100000 | Win: 14.00% | Draw: 0.00% | Loss: 86.00% | Epsilon: 0.7408 | Buffer: 4794/20000 (24.0%) | Train steps: 1 | Loss: 0.0043 | Avg Q: -0.1710 | TD Error: 0.0396 | Grad Norm: 0.0996\n",
            "  Detailed metrics: Max Q: 0.0264 | Min Q: -1.0654 | Target Q: -0.1505 | Grad Norm (clipped): 0.0996 | Total train steps: 4763 | Step count: 4794\n",
            "  Detailed metrics: Max Q: 0.3831 | Min Q: -0.8534 | Target Q: -0.1495 | Grad Norm (clipped): 0.1270 | Total train steps: 5127 | Step count: 5158\n",
            "Episode 700/100000 | Win: 16.00% | Draw: 1.00% | Loss: 83.00% | Epsilon: 0.7046 | Buffer: 5609/20000 (28.0%) | Train steps: 5 | Loss: 0.0133 | Avg Q: -0.2093 | TD Error: 0.0614 | Grad Norm: 0.1641\n",
            "  Detailed metrics: Max Q: 0.3660 | Min Q: -1.1241 | Target Q: -0.1887 | Grad Norm (clipped): 0.1641 | Total train steps: 5578 | Step count: 5609\n",
            "  Detailed metrics: Max Q: 0.0329 | Min Q: -1.0786 | Target Q: -0.1201 | Grad Norm (clipped): 0.0523 | Total train steps: 5941 | Step count: 5972\n",
            "Episode 800/100000 | Win: 17.00% | Draw: 2.00% | Loss: 81.00% | Epsilon: 0.6703 | Buffer: 6392/20000 (32.0%) | Train steps: 11 | Loss: 0.0102 | Avg Q: -0.1172 | TD Error: 0.0446 | Grad Norm: 0.1211\n",
            "  Detailed metrics: Max Q: 0.2893 | Min Q: -1.0399 | Target Q: -0.1280 | Grad Norm (clipped): 0.1211 | Total train steps: 6361 | Step count: 6392\n",
            "  Detailed metrics: Max Q: 0.6216 | Min Q: -1.0669 | Target Q: -0.1506 | Grad Norm (clipped): 0.1595 | Total train steps: 6767 | Step count: 6798\n",
            "Episode 900/100000 | Win: 17.00% | Draw: 1.00% | Loss: 82.00% | Epsilon: 0.6376 | Buffer: 7200/20000 (36.0%) | Train steps: 7 | Loss: 0.0054 | Avg Q: -0.1322 | TD Error: 0.0440 | Grad Norm: 0.1139\n",
            "  Detailed metrics: Max Q: 0.4580 | Min Q: -1.0286 | Target Q: -0.1511 | Grad Norm (clipped): 0.1139 | Total train steps: 7169 | Step count: 7200\n",
            "  Detailed metrics: Max Q: 0.5369 | Min Q: -1.0438 | Target Q: -0.1293 | Grad Norm (clipped): 0.0963 | Total train steps: 7588 | Step count: 7619\n",
            "Episode 1000/100000 | Win: 28.00% | Draw: 0.00% | Loss: 72.00% | Epsilon: 0.6065 | Buffer: 8043/20000 (40.2%) | Train steps: 3 | Loss: 0.0053 | Avg Q: -0.1589 | TD Error: 0.0441 | Grad Norm: 0.1350\n",
            "  Detailed metrics: Max Q: 0.6875 | Min Q: -1.2360 | Target Q: -0.1357 | Grad Norm (clipped): 0.1350 | Total train steps: 8012 | Step count: 8043\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_1000.pt\n",
            "  Added frozen opponent from episode 1000 to pool (total: 1)\n",
            "  Detailed metrics: Max Q: 0.2978 | Min Q: -1.0459 | Target Q: -0.1545 | Grad Norm (clipped): 0.1099 | Total train steps: 8414 | Step count: 8445\n",
            "Episode 1100/100000 | Win: 11.00% | Draw: 0.00% | Loss: 89.00% | Epsilon: 0.5769 | Buffer: 8860/20000 (44.3%) | Train steps: 14 | Loss: 0.0053 | Avg Q: -0.1568 | TD Error: 0.0407 | Grad Norm: 0.1020\n",
            "  Detailed metrics: Max Q: 0.4573 | Min Q: -1.0907 | Target Q: -0.1616 | Grad Norm (clipped): 0.1020 | Total train steps: 8829 | Step count: 8860\n",
            "  Detailed metrics: Max Q: 0.5403 | Min Q: -1.1117 | Target Q: -0.1163 | Grad Norm (clipped): 0.0972 | Total train steps: 9220 | Step count: 9251\n",
            "Episode 1200/100000 | Win: 13.00% | Draw: 0.00% | Loss: 87.00% | Epsilon: 0.5487 | Buffer: 9638/20000 (48.2%) | Train steps: 9 | Loss: 0.0063 | Avg Q: -0.1718 | TD Error: 0.0413 | Grad Norm: 0.1180\n",
            "  Detailed metrics: Max Q: 0.2964 | Min Q: -1.1097 | Target Q: -0.1694 | Grad Norm (clipped): 0.1180 | Total train steps: 9607 | Step count: 9638\n",
            "  Detailed metrics: Max Q: 0.3687 | Min Q: -1.0782 | Target Q: -0.1030 | Grad Norm (clipped): 0.1492 | Total train steps: 10027 | Step count: 10058\n",
            "Episode 1300/100000 | Win: 21.00% | Draw: 1.00% | Loss: 78.00% | Epsilon: 0.5220 | Buffer: 10462/20000 (52.3%) | Train steps: 6 | Loss: 0.0037 | Avg Q: -0.1795 | TD Error: 0.0379 | Grad Norm: 0.0810\n",
            "  Detailed metrics: Max Q: 0.3395 | Min Q: -1.0397 | Target Q: -0.1815 | Grad Norm (clipped): 0.0810 | Total train steps: 10431 | Step count: 10462\n",
            "  Detailed metrics: Max Q: 0.1949 | Min Q: -1.1077 | Target Q: -0.1902 | Grad Norm (clipped): 0.1060 | Total train steps: 10861 | Step count: 10892\n",
            "Episode 1400/100000 | Win: 18.00% | Draw: 0.00% | Loss: 82.00% | Epsilon: 0.4965 | Buffer: 11338/20000 (56.7%) | Train steps: 13 | Loss: 0.0087 | Avg Q: -0.1346 | TD Error: 0.0458 | Grad Norm: 0.1338\n",
            "  Detailed metrics: Max Q: 0.3726 | Min Q: -1.0432 | Target Q: -0.1407 | Grad Norm (clipped): 0.1338 | Total train steps: 11307 | Step count: 11338\n",
            "  Detailed metrics: Max Q: 0.5400 | Min Q: -0.9894 | Target Q: -0.1448 | Grad Norm (clipped): 0.1364 | Total train steps: 11760 | Step count: 11791\n",
            "Episode 1500/100000 | Win: 14.00% | Draw: 0.00% | Loss: 86.00% | Epsilon: 0.4723 | Buffer: 12225/20000 (61.1%) | Train steps: 6 | Loss: 0.0049 | Avg Q: -0.1576 | TD Error: 0.0416 | Grad Norm: 0.1189\n",
            "  Detailed metrics: Max Q: 0.5703 | Min Q: -1.0837 | Target Q: -0.1489 | Grad Norm (clipped): 0.1189 | Total train steps: 12194 | Step count: 12225\n",
            "  Detailed metrics: Max Q: 0.3859 | Min Q: -1.0527 | Target Q: -0.1416 | Grad Norm (clipped): 0.0889 | Total train steps: 12644 | Step count: 12675\n",
            "Episode 1600/100000 | Win: 33.00% | Draw: 0.00% | Loss: 67.00% | Epsilon: 0.4492 | Buffer: 13092/20000 (65.5%) | Train steps: 3 | Loss: 0.0068 | Avg Q: -0.1101 | TD Error: 0.0452 | Grad Norm: 0.1338\n",
            "  Detailed metrics: Max Q: 0.6295 | Min Q: -1.0678 | Target Q: -0.1181 | Grad Norm (clipped): 0.1338 | Total train steps: 13061 | Step count: 13092\n",
            "  Detailed metrics: Max Q: 0.6190 | Min Q: -1.0639 | Target Q: -0.1514 | Grad Norm (clipped): 0.0963 | Total train steps: 13526 | Step count: 13557\n",
            "Episode 1700/100000 | Win: 25.00% | Draw: 0.00% | Loss: 75.00% | Epsilon: 0.4273 | Buffer: 14021/20000 (70.1%) | Train steps: 10 | Loss: 0.0048 | Avg Q: -0.1771 | TD Error: 0.0429 | Grad Norm: 0.0957\n",
            "  Detailed metrics: Max Q: 0.3374 | Min Q: -1.0903 | Target Q: -0.1860 | Grad Norm (clipped): 0.0957 | Total train steps: 13990 | Step count: 14021\n",
            "  Detailed metrics: Max Q: 0.4411 | Min Q: -1.0876 | Target Q: -0.1817 | Grad Norm (clipped): 0.1077 | Total train steps: 14503 | Step count: 14534\n",
            "Episode 1800/100000 | Win: 21.00% | Draw: 0.00% | Loss: 79.00% | Epsilon: 0.4065 | Buffer: 14954/20000 (74.8%) | Train steps: 4 | Loss: 0.0051 | Avg Q: -0.1839 | TD Error: 0.0411 | Grad Norm: 0.1020\n",
            "  Detailed metrics: Max Q: 0.2907 | Min Q: -1.1295 | Target Q: -0.1808 | Grad Norm (clipped): 0.1020 | Total train steps: 14923 | Step count: 14954\n",
            "  Detailed metrics: Max Q: 0.2382 | Min Q: -1.0972 | Target Q: -0.1513 | Grad Norm (clipped): 0.0841 | Total train steps: 15332 | Step count: 15363\n",
            "Episode 1900/100000 | Win: 17.00% | Draw: 2.00% | Loss: 81.00% | Epsilon: 0.3866 | Buffer: 15754/20000 (78.8%) | Train steps: 6 | Loss: 0.0059 | Avg Q: -0.1477 | TD Error: 0.0449 | Grad Norm: 0.1174\n",
            "  Detailed metrics: Max Q: 0.6226 | Min Q: -1.1019 | Target Q: -0.1464 | Grad Norm (clipped): 0.1174 | Total train steps: 15723 | Step count: 15754\n",
            "  Detailed metrics: Max Q: 0.3695 | Min Q: -1.0284 | Target Q: -0.1537 | Grad Norm (clipped): 0.1022 | Total train steps: 16179 | Step count: 16210\n",
            "Episode 2000/100000 | Win: 25.00% | Draw: 1.00% | Loss: 74.00% | Epsilon: 0.3678 | Buffer: 16625/20000 (83.1%) | Train steps: 9 | Loss: 0.0082 | Avg Q: -0.1577 | TD Error: 0.0467 | Grad Norm: 0.1487\n",
            "  Detailed metrics: Max Q: 0.5677 | Min Q: -1.1214 | Target Q: -0.1573 | Grad Norm (clipped): 0.1487 | Total train steps: 16594 | Step count: 16625\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_2000.pt\n",
            "  Added frozen opponent from episode 2000 to pool (total: 2)\n",
            "  Detailed metrics: Max Q: 0.4764 | Min Q: -0.9203 | Target Q: -0.1485 | Grad Norm (clipped): 0.1019 | Total train steps: 17008 | Step count: 17039\n",
            "Episode 2100/100000 | Win: 16.00% | Draw: 0.00% | Loss: 84.00% | Epsilon: 0.3498 | Buffer: 17431/20000 (87.2%) | Train steps: 9 | Loss: 0.0202 | Avg Q: -0.1691 | TD Error: 0.0530 | Grad Norm: 0.1938\n",
            "  Detailed metrics: Max Q: 0.6342 | Min Q: -1.1281 | Target Q: -0.1641 | Grad Norm (clipped): 0.1938 | Total train steps: 17400 | Step count: 17431\n",
            "  Detailed metrics: Max Q: 0.4702 | Min Q: -1.0802 | Target Q: -0.1406 | Grad Norm (clipped): 0.1140 | Total train steps: 17904 | Step count: 17935\n",
            "Episode 2200/100000 | Win: 12.00% | Draw: 0.00% | Loss: 88.00% | Epsilon: 0.3328 | Buffer: 18386/20000 (91.9%) | Train steps: 15 | Loss: 0.0074 | Avg Q: -0.1841 | TD Error: 0.0445 | Grad Norm: 0.1093\n",
            "  Detailed metrics: Max Q: 0.3384 | Min Q: -1.0757 | Target Q: -0.1832 | Grad Norm (clipped): 0.1093 | Total train steps: 18355 | Step count: 18386\n",
            "  Detailed metrics: Max Q: 0.3779 | Min Q: -1.0378 | Target Q: -0.1495 | Grad Norm (clipped): 0.1083 | Total train steps: 18871 | Step count: 18902\n",
            "Episode 2300/100000 | Win: 30.00% | Draw: 3.00% | Loss: 67.00% | Epsilon: 0.3165 | Buffer: 19410/20000 (97.0%) | Train steps: 6 | Loss: 0.0046 | Avg Q: -0.1811 | TD Error: 0.0454 | Grad Norm: 0.1068\n",
            "  Detailed metrics: Max Q: 0.3415 | Min Q: -1.0818 | Target Q: -0.1757 | Grad Norm (clipped): 0.1068 | Total train steps: 19379 | Step count: 19410\n",
            "  Detailed metrics: Max Q: 0.6555 | Min Q: -1.0666 | Target Q: -0.1845 | Grad Norm (clipped): 0.1087 | Total train steps: 19829 | Step count: 19860\n",
            "Episode 2400/100000 | Win: 26.00% | Draw: 0.00% | Loss: 74.00% | Epsilon: 0.3011 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0095 | Avg Q: -0.1730 | TD Error: 0.0434 | Grad Norm: 0.1006\n",
            "  Detailed metrics: Max Q: 0.3383 | Min Q: -1.0474 | Target Q: -0.1793 | Grad Norm (clipped): 0.1006 | Total train steps: 20303 | Step count: 20334\n",
            "  Detailed metrics: Max Q: 0.4922 | Min Q: -1.0704 | Target Q: -0.1832 | Grad Norm (clipped): 0.1335 | Total train steps: 20764 | Step count: 20795\n",
            "Episode 2500/100000 | Win: 12.00% | Draw: 1.00% | Loss: 87.00% | Epsilon: 0.2864 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0040 | Avg Q: -0.2246 | TD Error: 0.0405 | Grad Norm: 0.0989\n",
            "  Detailed metrics: Max Q: 0.2618 | Min Q: -1.1156 | Target Q: -0.2203 | Grad Norm (clipped): 0.0989 | Total train steps: 21211 | Step count: 21242\n",
            "  Detailed metrics: Max Q: 0.3187 | Min Q: -0.9631 | Target Q: -0.1731 | Grad Norm (clipped): 0.1089 | Total train steps: 21687 | Step count: 21718\n",
            "Episode 2600/100000 | Win: 25.00% | Draw: 2.00% | Loss: 73.00% | Epsilon: 0.2724 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0043 | Avg Q: -0.1629 | TD Error: 0.0398 | Grad Norm: 0.0995\n",
            "  Detailed metrics: Max Q: 0.5362 | Min Q: -1.0587 | Target Q: -0.1682 | Grad Norm (clipped): 0.0995 | Total train steps: 22136 | Step count: 22167\n",
            "  Detailed metrics: Max Q: 0.3702 | Min Q: -1.0875 | Target Q: -0.2119 | Grad Norm (clipped): 0.1512 | Total train steps: 22596 | Step count: 22627\n",
            "Episode 2700/100000 | Win: 27.00% | Draw: 2.00% | Loss: 71.00% | Epsilon: 0.2592 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0081 | Avg Q: -0.1742 | TD Error: 0.0449 | Grad Norm: 0.1295\n",
            "  Detailed metrics: Max Q: 0.5915 | Min Q: -1.0945 | Target Q: -0.1610 | Grad Norm (clipped): 0.1295 | Total train steps: 23059 | Step count: 23090\n",
            "  Detailed metrics: Max Q: 0.5382 | Min Q: -1.0629 | Target Q: -0.1573 | Grad Norm (clipped): 0.1318 | Total train steps: 23513 | Step count: 23544\n",
            "Episode 2800/100000 | Win: 27.00% | Draw: 0.00% | Loss: 73.00% | Epsilon: 0.2465 | Buffer: 20000/20000 (100.0%) | Train steps: 15 | Loss: 0.0045 | Avg Q: -0.1644 | TD Error: 0.0417 | Grad Norm: 0.1112\n",
            "  Detailed metrics: Max Q: 0.6533 | Min Q: -1.0688 | Target Q: -0.1719 | Grad Norm (clipped): 0.1112 | Total train steps: 23932 | Step count: 23963\n",
            "  Detailed metrics: Max Q: 0.1485 | Min Q: -1.1173 | Target Q: -0.1856 | Grad Norm (clipped): 0.0762 | Total train steps: 24387 | Step count: 24418\n",
            "Episode 2900/100000 | Win: 46.00% | Draw: 0.00% | Loss: 54.00% | Epsilon: 0.2345 | Buffer: 20000/20000 (100.0%) | Train steps: 16 | Loss: 0.0069 | Avg Q: -0.1749 | TD Error: 0.0482 | Grad Norm: 0.1111\n",
            "  Detailed metrics: Max Q: 0.5847 | Min Q: -1.0240 | Target Q: -0.1755 | Grad Norm (clipped): 0.1111 | Total train steps: 24848 | Step count: 24879\n",
            "  Detailed metrics: Max Q: 0.5580 | Min Q: -1.0838 | Target Q: -0.1676 | Grad Norm (clipped): 0.0969 | Total train steps: 25406 | Step count: 25437\n",
            "Episode 3000/100000 | Win: 28.00% | Draw: 0.00% | Loss: 72.00% | Epsilon: 0.2230 | Buffer: 20000/20000 (100.0%) | Train steps: 13 | Loss: 0.0042 | Avg Q: -0.1484 | TD Error: 0.0433 | Grad Norm: 0.1042\n",
            "  Detailed metrics: Max Q: 0.7256 | Min Q: -0.9916 | Target Q: -0.1399 | Grad Norm (clipped): 0.1042 | Total train steps: 25840 | Step count: 25871\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_3000.pt\n",
            "  Added frozen opponent from episode 3000 to pool (total: 3)\n",
            "  Detailed metrics: Max Q: 0.5281 | Min Q: -1.0973 | Target Q: -0.2075 | Grad Norm (clipped): 0.1155 | Total train steps: 26312 | Step count: 26343\n",
            "Episode 3100/100000 | Win: 30.00% | Draw: 0.00% | Loss: 70.00% | Epsilon: 0.2122 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0047 | Avg Q: -0.1811 | TD Error: 0.0395 | Grad Norm: 0.0875\n",
            "  Detailed metrics: Max Q: 0.4411 | Min Q: -0.9862 | Target Q: -0.1801 | Grad Norm (clipped): 0.0875 | Total train steps: 26793 | Step count: 26824\n",
            "  Detailed metrics: Max Q: 0.5420 | Min Q: -1.0234 | Target Q: -0.1521 | Grad Norm (clipped): 0.1166 | Total train steps: 27288 | Step count: 27319\n",
            "Episode 3200/100000 | Win: 33.00% | Draw: 2.00% | Loss: 65.00% | Epsilon: 0.2018 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0120 | Avg Q: -0.1406 | TD Error: 0.0542 | Grad Norm: 0.1760\n",
            "  Detailed metrics: Max Q: 0.9126 | Min Q: -0.8814 | Target Q: -0.1528 | Grad Norm (clipped): 0.1760 | Total train steps: 27713 | Step count: 27744\n",
            "  Detailed metrics: Max Q: 0.6550 | Min Q: -1.0732 | Target Q: -0.1595 | Grad Norm (clipped): 0.1470 | Total train steps: 28152 | Step count: 28183\n",
            "Episode 3300/100000 | Win: 25.00% | Draw: 1.00% | Loss: 74.00% | Epsilon: 0.1920 | Buffer: 20000/20000 (100.0%) | Train steps: 14 | Loss: 0.0073 | Avg Q: -0.1425 | TD Error: 0.0451 | Grad Norm: 0.1209\n",
            "  Detailed metrics: Max Q: 0.5729 | Min Q: -0.8811 | Target Q: -0.1436 | Grad Norm (clipped): 0.1209 | Total train steps: 28599 | Step count: 28630\n",
            "  Detailed metrics: Max Q: 0.7099 | Min Q: -1.0266 | Target Q: -0.1676 | Grad Norm (clipped): 0.0860 | Total train steps: 29105 | Step count: 29136\n",
            "Episode 3400/100000 | Win: 24.00% | Draw: 3.00% | Loss: 73.00% | Epsilon: 0.1826 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0040 | Avg Q: -0.2345 | TD Error: 0.0422 | Grad Norm: 0.1067\n",
            "  Detailed metrics: Max Q: 0.3385 | Min Q: -1.0554 | Target Q: -0.2262 | Grad Norm (clipped): 0.1067 | Total train steps: 29580 | Step count: 29611\n",
            "  Detailed metrics: Max Q: 0.3440 | Min Q: -0.8433 | Target Q: -0.1520 | Grad Norm (clipped): 0.0658 | Total train steps: 30015 | Step count: 30046\n",
            "Episode 3500/100000 | Win: 37.00% | Draw: 0.00% | Loss: 63.00% | Epsilon: 0.1737 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0043 | Avg Q: -0.1818 | TD Error: 0.0433 | Grad Norm: 0.1160\n",
            "  Detailed metrics: Max Q: 0.5654 | Min Q: -1.0556 | Target Q: -0.1765 | Grad Norm (clipped): 0.1160 | Total train steps: 30499 | Step count: 30530\n",
            "  Detailed metrics: Max Q: 0.4380 | Min Q: -1.0400 | Target Q: -0.1988 | Grad Norm (clipped): 0.1332 | Total train steps: 30908 | Step count: 30939\n",
            "Episode 3600/100000 | Win: 40.00% | Draw: 2.00% | Loss: 58.00% | Epsilon: 0.1652 | Buffer: 20000/20000 (100.0%) | Train steps: 12 | Loss: 0.0048 | Avg Q: -0.1954 | TD Error: 0.0445 | Grad Norm: 0.1014\n",
            "  Detailed metrics: Max Q: 0.5898 | Min Q: -1.0371 | Target Q: -0.1978 | Grad Norm (clipped): 0.1014 | Total train steps: 31368 | Step count: 31399\n",
            "  Detailed metrics: Max Q: 0.7954 | Min Q: -1.0365 | Target Q: -0.1941 | Grad Norm (clipped): 0.1484 | Total train steps: 31807 | Step count: 31838\n",
            "Episode 3700/100000 | Win: 34.00% | Draw: 0.00% | Loss: 66.00% | Epsilon: 0.1572 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0038 | Avg Q: -0.1623 | TD Error: 0.0405 | Grad Norm: 0.0874\n",
            "  Detailed metrics: Max Q: 0.3763 | Min Q: -0.9723 | Target Q: -0.1640 | Grad Norm (clipped): 0.0874 | Total train steps: 32270 | Step count: 32301\n",
            "  Detailed metrics: Max Q: 0.8715 | Min Q: -1.0924 | Target Q: -0.1898 | Grad Norm (clipped): 0.1303 | Total train steps: 32732 | Step count: 32763\n",
            "Episode 3800/100000 | Win: 32.00% | Draw: 1.00% | Loss: 67.00% | Epsilon: 0.1495 | Buffer: 20000/20000 (100.0%) | Train steps: 4 | Loss: 0.0043 | Avg Q: -0.2193 | TD Error: 0.0443 | Grad Norm: 0.0955\n",
            "  Detailed metrics: Max Q: 0.4912 | Min Q: -1.0658 | Target Q: -0.2178 | Grad Norm (clipped): 0.0955 | Total train steps: 33232 | Step count: 33263\n",
            "  Detailed metrics: Max Q: 0.5019 | Min Q: -1.0484 | Target Q: -0.1979 | Grad Norm (clipped): 0.0881 | Total train steps: 33734 | Step count: 33765\n",
            "Episode 3900/100000 | Win: 33.00% | Draw: 0.00% | Loss: 67.00% | Epsilon: 0.1422 | Buffer: 20000/20000 (100.0%) | Train steps: 17 | Loss: 0.0057 | Avg Q: -0.1758 | TD Error: 0.0423 | Grad Norm: 0.1011\n",
            "  Detailed metrics: Max Q: 0.8521 | Min Q: -0.9810 | Target Q: -0.1796 | Grad Norm (clipped): 0.1011 | Total train steps: 34214 | Step count: 34245\n",
            "  Detailed metrics: Max Q: 0.4487 | Min Q: -0.9688 | Target Q: -0.1765 | Grad Norm (clipped): 0.1337 | Total train steps: 34681 | Step count: 34712\n",
            "Episode 4000/100000 | Win: 36.00% | Draw: 0.00% | Loss: 64.00% | Epsilon: 0.1353 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0045 | Avg Q: -0.1849 | TD Error: 0.0438 | Grad Norm: 0.1040\n",
            "  Detailed metrics: Max Q: 0.8035 | Min Q: -1.0349 | Target Q: -0.1898 | Grad Norm (clipped): 0.1040 | Total train steps: 35104 | Step count: 35135\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_4000.pt\n",
            "  Added frozen opponent from episode 4000 to pool (total: 4)\n",
            "  Detailed metrics: Max Q: 0.9745 | Min Q: -0.9360 | Target Q: -0.1257 | Grad Norm (clipped): 0.1291 | Total train steps: 35566 | Step count: 35597\n",
            "Episode 4100/100000 | Win: 37.00% | Draw: 0.00% | Loss: 63.00% | Epsilon: 0.1287 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0037 | Avg Q: -0.1748 | TD Error: 0.0419 | Grad Norm: 0.0886\n",
            "  Detailed metrics: Max Q: 0.5270 | Min Q: -0.9731 | Target Q: -0.1734 | Grad Norm (clipped): 0.0886 | Total train steps: 36038 | Step count: 36069\n",
            "  Detailed metrics: Max Q: 0.7076 | Min Q: -1.0037 | Target Q: -0.1714 | Grad Norm (clipped): 0.1114 | Total train steps: 36472 | Step count: 36503\n",
            "Episode 4200/100000 | Win: 43.00% | Draw: 0.00% | Loss: 57.00% | Epsilon: 0.1224 | Buffer: 20000/20000 (100.0%) | Train steps: 10 | Loss: 0.0043 | Avg Q: -0.1879 | TD Error: 0.0452 | Grad Norm: 0.1029\n",
            "  Detailed metrics: Max Q: 0.8036 | Min Q: -1.0335 | Target Q: -0.1888 | Grad Norm (clipped): 0.1029 | Total train steps: 36912 | Step count: 36943\n",
            "  Detailed metrics: Max Q: 1.0323 | Min Q: -1.0096 | Target Q: -0.1753 | Grad Norm (clipped): 0.1985 | Total train steps: 37327 | Step count: 37358\n",
            "Episode 4300/100000 | Win: 48.00% | Draw: 2.00% | Loss: 50.00% | Epsilon: 0.1164 | Buffer: 20000/20000 (100.0%) | Train steps: 4 | Loss: 0.0044 | Avg Q: -0.1665 | TD Error: 0.0442 | Grad Norm: 0.0909\n",
            "  Detailed metrics: Max Q: 0.6554 | Min Q: -1.0101 | Target Q: -0.1684 | Grad Norm (clipped): 0.0909 | Total train steps: 37813 | Step count: 37844\n",
            "  Detailed metrics: Max Q: 0.7002 | Min Q: -1.0502 | Target Q: -0.1720 | Grad Norm (clipped): 0.1186 | Total train steps: 38304 | Step count: 38335\n",
            "Episode 4400/100000 | Win: 46.00% | Draw: 2.00% | Loss: 52.00% | Epsilon: 0.1107 | Buffer: 20000/20000 (100.0%) | Train steps: 18 | Loss: 0.0046 | Avg Q: -0.1558 | TD Error: 0.0426 | Grad Norm: 0.0979\n",
            "  Detailed metrics: Max Q: 0.7048 | Min Q: -1.0396 | Target Q: -0.1576 | Grad Norm (clipped): 0.0979 | Total train steps: 38763 | Step count: 38794\n",
            "  Detailed metrics: Max Q: 0.9093 | Min Q: -0.9689 | Target Q: -0.1257 | Grad Norm (clipped): 0.1091 | Total train steps: 39259 | Step count: 39290\n",
            "Episode 4500/100000 | Win: 58.00% | Draw: 1.00% | Loss: 41.00% | Epsilon: 0.1053 | Buffer: 20000/20000 (100.0%) | Train steps: 2 | Loss: 0.0055 | Avg Q: -0.1729 | TD Error: 0.0495 | Grad Norm: 0.1160\n",
            "  Detailed metrics: Max Q: 0.7781 | Min Q: -0.8646 | Target Q: -0.1587 | Grad Norm (clipped): 0.1160 | Total train steps: 39744 | Step count: 39775\n",
            "  Detailed metrics: Max Q: 0.7362 | Min Q: -1.0536 | Target Q: -0.1773 | Grad Norm (clipped): 0.1071 | Total train steps: 40252 | Step count: 40283\n",
            "Episode 4600/100000 | Win: 46.00% | Draw: 3.00% | Loss: 51.00% | Epsilon: 0.1002 | Buffer: 20000/20000 (100.0%) | Train steps: 5 | Loss: 0.0037 | Avg Q: -0.1920 | TD Error: 0.0418 | Grad Norm: 0.0903\n",
            "  Detailed metrics: Max Q: 0.7187 | Min Q: -0.9965 | Target Q: -0.1993 | Grad Norm (clipped): 0.0903 | Total train steps: 40664 | Step count: 40695\n",
            "  Detailed metrics: Max Q: 0.8115 | Min Q: -0.9945 | Target Q: -0.1434 | Grad Norm (clipped): 0.1083 | Total train steps: 41164 | Step count: 41195\n",
            "Episode 4700/100000 | Win: 49.00% | Draw: 2.00% | Loss: 49.00% | Epsilon: 0.0953 | Buffer: 20000/20000 (100.0%) | Train steps: 3 | Loss: 0.0049 | Avg Q: -0.1934 | TD Error: 0.0466 | Grad Norm: 0.1099\n",
            "  Detailed metrics: Max Q: 0.7761 | Min Q: -1.0294 | Target Q: -0.1922 | Grad Norm (clipped): 0.1099 | Total train steps: 41619 | Step count: 41650\n",
            "  Detailed metrics: Max Q: 0.7998 | Min Q: -1.0397 | Target Q: -0.1481 | Grad Norm (clipped): 0.1139 | Total train steps: 42079 | Step count: 42110\n",
            "Episode 4800/100000 | Win: 52.00% | Draw: 1.00% | Loss: 47.00% | Epsilon: 0.0907 | Buffer: 20000/20000 (100.0%) | Train steps: 1 | Loss: 0.0025 | Avg Q: -0.1392 | TD Error: 0.0370 | Grad Norm: 0.0552\n",
            "  Detailed metrics: Max Q: 0.9842 | Min Q: -0.6621 | Target Q: -0.1352 | Grad Norm (clipped): 0.0552 | Total train steps: 42565 | Step count: 42596\n",
            "  Detailed metrics: Max Q: 0.7528 | Min Q: -1.0066 | Target Q: -0.1737 | Grad Norm (clipped): 0.1361 | Total train steps: 43000 | Step count: 43031\n",
            "Episode 4900/100000 | Win: 50.00% | Draw: 1.00% | Loss: 49.00% | Epsilon: 0.0862 | Buffer: 20000/20000 (100.0%) | Train steps: 17 | Loss: 0.0071 | Avg Q: -0.1586 | TD Error: 0.0480 | Grad Norm: 0.1159\n",
            "  Detailed metrics: Max Q: 0.6583 | Min Q: -0.9760 | Target Q: -0.1558 | Grad Norm (clipped): 0.1159 | Total train steps: 43525 | Step count: 43556\n",
            "  Detailed metrics: Max Q: 0.7231 | Min Q: -0.9073 | Target Q: -0.1252 | Grad Norm (clipped): 0.1044 | Total train steps: 43991 | Step count: 44022\n",
            "Episode 5000/100000 | Win: 62.00% | Draw: 0.00% | Loss: 38.00% | Epsilon: 0.0820 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0053 | Avg Q: -0.1506 | TD Error: 0.0491 | Grad Norm: 0.1193\n",
            "  Detailed metrics: Max Q: 0.8390 | Min Q: -1.0660 | Target Q: -0.1525 | Grad Norm (clipped): 0.1193 | Total train steps: 44451 | Step count: 44482\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_5000.pt\n",
            "  Added frozen opponent from episode 5000 to pool (total: 5)\n",
            "  Detailed metrics: Max Q: 0.9423 | Min Q: -0.9970 | Target Q: -0.1270 | Grad Norm (clipped): 0.1259 | Total train steps: 44879 | Step count: 44910\n",
            "Episode 5100/100000 | Win: 49.00% | Draw: 1.00% | Loss: 50.00% | Epsilon: 0.0780 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0049 | Avg Q: -0.1848 | TD Error: 0.0451 | Grad Norm: 0.0971\n",
            "  Detailed metrics: Max Q: 0.6423 | Min Q: -0.9305 | Target Q: -0.1871 | Grad Norm (clipped): 0.0971 | Total train steps: 45375 | Step count: 45406\n",
            "  Detailed metrics: Max Q: 0.8838 | Min Q: -0.9812 | Target Q: -0.1587 | Grad Norm (clipped): 0.1598 | Total train steps: 45808 | Step count: 45839\n",
            "Episode 5200/100000 | Win: 55.00% | Draw: 0.00% | Loss: 45.00% | Epsilon: 0.0742 | Buffer: 20000/20000 (100.0%) | Train steps: 15 | Loss: 0.0074 | Avg Q: -0.1572 | TD Error: 0.0532 | Grad Norm: 0.1232\n",
            "  Detailed metrics: Max Q: 0.8650 | Min Q: -1.0163 | Target Q: -0.1481 | Grad Norm (clipped): 0.1232 | Total train steps: 46283 | Step count: 46314\n",
            "  Detailed metrics: Max Q: 0.7821 | Min Q: -1.0537 | Target Q: -0.1536 | Grad Norm (clipped): 0.1042 | Total train steps: 46746 | Step count: 46777\n",
            "Episode 5300/100000 | Win: 57.00% | Draw: 0.00% | Loss: 43.00% | Epsilon: 0.0706 | Buffer: 20000/20000 (100.0%) | Train steps: 13 | Loss: 0.0086 | Avg Q: -0.1507 | TD Error: 0.0549 | Grad Norm: 0.1305\n",
            "  Detailed metrics: Max Q: 0.8893 | Min Q: -0.9913 | Target Q: -0.1481 | Grad Norm (clipped): 0.1305 | Total train steps: 47165 | Step count: 47196\n",
            "  Detailed metrics: Max Q: 0.9327 | Min Q: -1.0739 | Target Q: -0.1540 | Grad Norm (clipped): 0.1160 | Total train steps: 47613 | Step count: 47644\n",
            "Episode 5400/100000 | Win: 60.00% | Draw: 1.00% | Loss: 39.00% | Epsilon: 0.0672 | Buffer: 20000/20000 (100.0%) | Train steps: 10 | Loss: 0.0072 | Avg Q: -0.1420 | TD Error: 0.0498 | Grad Norm: 0.1373\n",
            "  Detailed metrics: Max Q: 0.8543 | Min Q: -0.9967 | Target Q: -0.1327 | Grad Norm (clipped): 0.1373 | Total train steps: 48083 | Step count: 48114\n",
            "  Detailed metrics: Max Q: 1.0050 | Min Q: -1.0639 | Target Q: -0.0783 | Grad Norm (clipped): 0.1286 | Total train steps: 48481 | Step count: 48512\n",
            "Episode 5500/100000 | Win: 56.00% | Draw: 1.00% | Loss: 43.00% | Epsilon: 0.0639 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0096 | Avg Q: -0.1699 | TD Error: 0.0551 | Grad Norm: 0.1448\n",
            "  Detailed metrics: Max Q: 0.8917 | Min Q: -1.0026 | Target Q: -0.1778 | Grad Norm (clipped): 0.1448 | Total train steps: 48912 | Step count: 48943\n",
            "  Detailed metrics: Max Q: 0.9727 | Min Q: -0.9758 | Target Q: -0.1437 | Grad Norm (clipped): 0.1013 | Total train steps: 49388 | Step count: 49419\n",
            "Episode 5600/100000 | Win: 62.00% | Draw: 3.00% | Loss: 35.00% | Epsilon: 0.0608 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0156 | Avg Q: -0.1367 | TD Error: 0.0618 | Grad Norm: 0.1771\n",
            "  Detailed metrics: Max Q: 0.7865 | Min Q: -0.9558 | Target Q: -0.1183 | Grad Norm (clipped): 0.1771 | Total train steps: 49852 | Step count: 49883\n",
            "  Detailed metrics: Max Q: 0.8707 | Min Q: -0.8989 | Target Q: -0.1056 | Grad Norm (clipped): 0.1183 | Total train steps: 50337 | Step count: 50368\n",
            "Episode 5700/100000 | Win: 65.00% | Draw: 0.00% | Loss: 35.00% | Epsilon: 0.0578 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0072 | Avg Q: -0.1529 | TD Error: 0.0526 | Grad Norm: 0.1164\n",
            "  Detailed metrics: Max Q: 0.9377 | Min Q: -1.0484 | Target Q: -0.1596 | Grad Norm (clipped): 0.1164 | Total train steps: 50800 | Step count: 50831\n",
            "  Detailed metrics: Max Q: 0.8260 | Min Q: -0.9718 | Target Q: -0.1130 | Grad Norm (clipped): 0.1168 | Total train steps: 51254 | Step count: 51285\n",
            "Episode 5800/100000 | Win: 55.00% | Draw: 2.00% | Loss: 43.00% | Epsilon: 0.0550 | Buffer: 20000/20000 (100.0%) | Train steps: 3 | Loss: 0.0071 | Avg Q: -0.0457 | TD Error: 0.0584 | Grad Norm: 0.1513\n",
            "  Detailed metrics: Max Q: 1.1453 | Min Q: -1.0904 | Target Q: -0.0516 | Grad Norm (clipped): 0.1513 | Total train steps: 51728 | Step count: 51759\n",
            "  Detailed metrics: Max Q: 1.0102 | Min Q: -0.9409 | Target Q: -0.1035 | Grad Norm (clipped): 0.1106 | Total train steps: 52250 | Step count: 52281\n",
            "Episode 5900/100000 | Win: 50.00% | Draw: 1.00% | Loss: 49.00% | Epsilon: 0.0523 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0179 | Avg Q: -0.1317 | TD Error: 0.0604 | Grad Norm: 0.1730\n",
            "  Detailed metrics: Max Q: 0.8588 | Min Q: -1.0152 | Target Q: -0.1336 | Grad Norm (clipped): 0.1730 | Total train steps: 52738 | Step count: 52769\n",
            "  Detailed metrics: Max Q: 0.8002 | Min Q: -0.9863 | Target Q: -0.1304 | Grad Norm (clipped): 0.0998 | Total train steps: 53184 | Step count: 53215\n",
            "Episode 6000/100000 | Win: 65.00% | Draw: 2.00% | Loss: 33.00% | Epsilon: 0.0497 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0055 | Avg Q: -0.1503 | TD Error: 0.0509 | Grad Norm: 0.1213\n",
            "  Detailed metrics: Max Q: 0.8893 | Min Q: -1.0185 | Target Q: -0.1492 | Grad Norm (clipped): 0.1213 | Total train steps: 53657 | Step count: 53688\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_6000.pt\n",
            "  Added frozen opponent from episode 6000 to pool (total: 6)\n",
            "  Detailed metrics: Max Q: 0.9474 | Min Q: -1.0687 | Target Q: -0.1020 | Grad Norm (clipped): 0.1624 | Total train steps: 54115 | Step count: 54146\n",
            "Episode 6100/100000 | Win: 68.00% | Draw: 2.00% | Loss: 30.00% | Epsilon: 0.0473 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0104 | Avg Q: -0.0801 | TD Error: 0.0624 | Grad Norm: 0.1742\n",
            "  Detailed metrics: Max Q: 1.0558 | Min Q: -0.8694 | Target Q: -0.0748 | Grad Norm (clipped): 0.1742 | Total train steps: 54569 | Step count: 54600\n",
            "  Detailed metrics: Max Q: 1.1079 | Min Q: -1.0577 | Target Q: -0.1131 | Grad Norm (clipped): 0.1435 | Total train steps: 55021 | Step count: 55052\n",
            "Episode 6200/100000 | Win: 60.00% | Draw: 1.00% | Loss: 39.00% | Epsilon: 0.0450 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0126 | Avg Q: -0.0854 | TD Error: 0.0608 | Grad Norm: 0.1719\n",
            "  Detailed metrics: Max Q: 1.0078 | Min Q: -0.9892 | Target Q: -0.0841 | Grad Norm (clipped): 0.1719 | Total train steps: 55406 | Step count: 55437\n",
            "  Detailed metrics: Max Q: 0.9593 | Min Q: -0.9137 | Target Q: -0.0983 | Grad Norm (clipped): 0.1975 | Total train steps: 55884 | Step count: 55915\n",
            "Episode 6300/100000 | Win: 72.00% | Draw: 0.00% | Loss: 28.00% | Epsilon: 0.0428 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0068 | Avg Q: -0.0985 | TD Error: 0.0539 | Grad Norm: 0.1068\n",
            "  Detailed metrics: Max Q: 0.8299 | Min Q: -1.0244 | Target Q: -0.0974 | Grad Norm (clipped): 0.1068 | Total train steps: 56297 | Step count: 56328\n",
            "  Detailed metrics: Max Q: 0.9565 | Min Q: -0.9940 | Target Q: -0.0796 | Grad Norm (clipped): 0.1460 | Total train steps: 56771 | Step count: 56802\n",
            "Episode 6400/100000 | Win: 56.00% | Draw: 2.00% | Loss: 42.00% | Epsilon: 0.0407 | Buffer: 20000/20000 (100.0%) | Train steps: 1 | Loss: 0.0056 | Avg Q: -0.1519 | TD Error: 0.0493 | Grad Norm: 0.1025\n",
            "  Detailed metrics: Max Q: 0.9170 | Min Q: -1.0738 | Target Q: -0.1556 | Grad Norm (clipped): 0.1025 | Total train steps: 57164 | Step count: 57195\n",
            "  Detailed metrics: Max Q: 0.9194 | Min Q: -1.0267 | Target Q: -0.0571 | Grad Norm (clipped): 0.1190 | Total train steps: 57603 | Step count: 57634\n",
            "Episode 6500/100000 | Win: 67.00% | Draw: 0.00% | Loss: 33.00% | Epsilon: 0.0387 | Buffer: 20000/20000 (100.0%) | Train steps: 12 | Loss: 0.0117 | Avg Q: -0.0704 | TD Error: 0.0607 | Grad Norm: 0.1475\n",
            "  Detailed metrics: Max Q: 1.0160 | Min Q: -0.9918 | Target Q: -0.0758 | Grad Norm (clipped): 0.1475 | Total train steps: 58026 | Step count: 58057\n",
            "  Detailed metrics: Max Q: 1.0025 | Min Q: -0.9785 | Target Q: -0.1047 | Grad Norm (clipped): 0.1114 | Total train steps: 58472 | Step count: 58503\n",
            "Episode 6600/100000 | Win: 66.00% | Draw: 0.00% | Loss: 34.00% | Epsilon: 0.0369 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0096 | Avg Q: -0.0492 | TD Error: 0.0582 | Grad Norm: 0.1417\n",
            "  Detailed metrics: Max Q: 1.0005 | Min Q: -0.9696 | Target Q: -0.0491 | Grad Norm (clipped): 0.1417 | Total train steps: 58920 | Step count: 58951\n",
            "  Detailed metrics: Max Q: 0.9675 | Min Q: -1.0194 | Target Q: -0.0633 | Grad Norm (clipped): 0.1486 | Total train steps: 59412 | Step count: 59443\n",
            "Episode 6700/100000 | Win: 74.00% | Draw: 0.00% | Loss: 26.00% | Epsilon: 0.0351 | Buffer: 20000/20000 (100.0%) | Train steps: 5 | Loss: 0.0106 | Avg Q: -0.0604 | TD Error: 0.0642 | Grad Norm: 0.1541\n",
            "  Detailed metrics: Max Q: 1.0336 | Min Q: -0.8977 | Target Q: -0.0480 | Grad Norm (clipped): 0.1541 | Total train steps: 59889 | Step count: 59920\n",
            "  Detailed metrics: Max Q: 1.0006 | Min Q: -0.9420 | Target Q: -0.0572 | Grad Norm (clipped): 0.1692 | Total train steps: 60348 | Step count: 60379\n",
            "Episode 6800/100000 | Win: 74.00% | Draw: 0.00% | Loss: 26.00% | Epsilon: 0.0333 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0190 | Avg Q: -0.0963 | TD Error: 0.0722 | Grad Norm: 0.1661\n",
            "  Detailed metrics: Max Q: 0.9222 | Min Q: -1.0554 | Target Q: -0.0948 | Grad Norm (clipped): 0.1661 | Total train steps: 60779 | Step count: 60810\n",
            "  Detailed metrics: Max Q: 0.9637 | Min Q: -0.9788 | Target Q: -0.0503 | Grad Norm (clipped): 0.1642 | Total train steps: 61208 | Step count: 61239\n",
            "Episode 6900/100000 | Win: 55.00% | Draw: 2.00% | Loss: 43.00% | Epsilon: 0.0317 | Buffer: 20000/20000 (100.0%) | Train steps: 13 | Loss: 0.0120 | Avg Q: -0.0811 | TD Error: 0.0634 | Grad Norm: 0.1589\n",
            "  Detailed metrics: Max Q: 0.9851 | Min Q: -1.0040 | Target Q: -0.0866 | Grad Norm (clipped): 0.1589 | Total train steps: 61667 | Step count: 61698\n",
            "  Detailed metrics: Max Q: 1.0220 | Min Q: -0.8150 | Target Q: -0.0074 | Grad Norm (clipped): 0.1207 | Total train steps: 62128 | Step count: 62159\n",
            "Episode 7000/100000 | Win: 72.00% | Draw: 1.00% | Loss: 27.00% | Epsilon: 0.0302 | Buffer: 20000/20000 (100.0%) | Train steps: 2 | Loss: 0.0101 | Avg Q: -0.0688 | TD Error: 0.0711 | Grad Norm: 0.1402\n",
            "  Detailed metrics: Max Q: 1.0271 | Min Q: -1.1792 | Target Q: -0.0628 | Grad Norm (clipped): 0.1402 | Total train steps: 62563 | Step count: 62594\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_7000.pt\n",
            "  Added frozen opponent from episode 7000 to pool (total: 7)\n",
            "  Detailed metrics: Max Q: 1.0015 | Min Q: -0.9650 | Target Q: -0.0582 | Grad Norm (clipped): 0.1725 | Total train steps: 63009 | Step count: 63040\n",
            "Episode 7100/100000 | Win: 70.00% | Draw: 1.00% | Loss: 29.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 10 | Loss: 0.0115 | Avg Q: -0.0290 | TD Error: 0.0647 | Grad Norm: 0.1452\n",
            "  Detailed metrics: Max Q: 1.0567 | Min Q: -0.9477 | Target Q: -0.0292 | Grad Norm (clipped): 0.1452 | Total train steps: 63467 | Step count: 63498\n",
            "  Detailed metrics: Max Q: 1.0624 | Min Q: -1.0982 | Target Q: -0.0345 | Grad Norm (clipped): 0.1375 | Total train steps: 63935 | Step count: 63966\n",
            "Episode 7200/100000 | Win: 69.00% | Draw: 0.00% | Loss: 31.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0121 | Avg Q: -0.0305 | TD Error: 0.0653 | Grad Norm: 0.1506\n",
            "  Detailed metrics: Max Q: 0.9338 | Min Q: -0.9671 | Target Q: -0.0298 | Grad Norm (clipped): 0.1506 | Total train steps: 64348 | Step count: 64379\n",
            "  Detailed metrics: Max Q: 0.9423 | Min Q: -0.9429 | Target Q: -0.0410 | Grad Norm (clipped): 0.1163 | Total train steps: 64817 | Step count: 64848\n",
            "Episode 7300/100000 | Win: 79.00% | Draw: 0.00% | Loss: 21.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0110 | Avg Q: -0.0915 | TD Error: 0.0630 | Grad Norm: 0.1389\n",
            "  Detailed metrics: Max Q: 0.9488 | Min Q: -1.0198 | Target Q: -0.0951 | Grad Norm (clipped): 0.1389 | Total train steps: 65208 | Step count: 65239\n",
            "  Detailed metrics: Max Q: 1.0671 | Min Q: -0.9082 | Target Q: -0.0019 | Grad Norm (clipped): 0.1509 | Total train steps: 65663 | Step count: 65694\n",
            "Episode 7400/100000 | Win: 66.00% | Draw: 1.00% | Loss: 33.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0125 | Avg Q: -0.0310 | TD Error: 0.0583 | Grad Norm: 0.1422\n",
            "  Detailed metrics: Max Q: 1.0632 | Min Q: -0.9037 | Target Q: -0.0395 | Grad Norm (clipped): 0.1422 | Total train steps: 66061 | Step count: 66092\n",
            "  Detailed metrics: Max Q: 0.9632 | Min Q: -0.8845 | Target Q: -0.0334 | Grad Norm (clipped): 0.1409 | Total train steps: 66493 | Step count: 66524\n",
            "Episode 7500/100000 | Win: 65.00% | Draw: 2.00% | Loss: 33.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0127 | Avg Q: -0.0311 | TD Error: 0.0592 | Grad Norm: 0.1559\n",
            "  Detailed metrics: Max Q: 1.0465 | Min Q: -0.9396 | Target Q: -0.0313 | Grad Norm (clipped): 0.1559 | Total train steps: 66913 | Step count: 66944\n",
            "  Detailed metrics: Max Q: 0.9655 | Min Q: -0.9607 | Target Q: -0.0630 | Grad Norm (clipped): 0.1349 | Total train steps: 67354 | Step count: 67385\n",
            "Episode 7600/100000 | Win: 68.00% | Draw: 0.00% | Loss: 32.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0173 | Avg Q: -0.0194 | TD Error: 0.0723 | Grad Norm: 0.1785\n",
            "  Detailed metrics: Max Q: 1.0090 | Min Q: -0.9532 | Target Q: -0.0194 | Grad Norm (clipped): 0.1785 | Total train steps: 67743 | Step count: 67774\n",
            "  Detailed metrics: Max Q: 1.0385 | Min Q: -0.9159 | Target Q: 0.0388 | Grad Norm (clipped): 0.1494 | Total train steps: 68191 | Step count: 68222\n",
            "Episode 7700/100000 | Win: 64.00% | Draw: 0.00% | Loss: 36.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0199 | Avg Q: -0.0977 | TD Error: 0.0748 | Grad Norm: 0.2156\n",
            "  Detailed metrics: Max Q: 0.9668 | Min Q: -1.0108 | Target Q: -0.0832 | Grad Norm (clipped): 0.2156 | Total train steps: 68571 | Step count: 68602\n",
            "  Detailed metrics: Max Q: 1.0037 | Min Q: -0.8138 | Target Q: 0.0185 | Grad Norm (clipped): 0.1347 | Total train steps: 68976 | Step count: 69007\n",
            "Episode 7800/100000 | Win: 54.00% | Draw: 1.00% | Loss: 45.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0100 | Avg Q: -0.0354 | TD Error: 0.0682 | Grad Norm: 0.1359\n",
            "  Detailed metrics: Max Q: 0.9318 | Min Q: -0.9646 | Target Q: -0.0306 | Grad Norm (clipped): 0.1359 | Total train steps: 69362 | Step count: 69393\n",
            "  Detailed metrics: Max Q: 0.9401 | Min Q: -0.9651 | Target Q: -0.0458 | Grad Norm (clipped): 0.1674 | Total train steps: 69824 | Step count: 69855\n",
            "Episode 7900/100000 | Win: 73.00% | Draw: 0.00% | Loss: 27.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 4 | Loss: 0.0132 | Avg Q: -0.0098 | TD Error: 0.0699 | Grad Norm: 0.1730\n",
            "  Detailed metrics: Max Q: 1.0742 | Min Q: -0.9078 | Target Q: -0.0063 | Grad Norm (clipped): 0.1730 | Total train steps: 70246 | Step count: 70277\n",
            "  Detailed metrics: Max Q: 1.0339 | Min Q: -0.8558 | Target Q: -0.0340 | Grad Norm (clipped): 0.2057 | Total train steps: 70677 | Step count: 70708\n",
            "Episode 8000/100000 | Win: 61.00% | Draw: 0.00% | Loss: 39.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 2 | Loss: 0.0186 | Avg Q: -0.0216 | TD Error: 0.0813 | Grad Norm: 0.2014\n",
            "  Detailed metrics: Max Q: 1.0906 | Min Q: -0.7640 | Target Q: 0.0079 | Grad Norm (clipped): 0.2014 | Total train steps: 71090 | Step count: 71121\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_8000.pt\n",
            "  Added frozen opponent from episode 8000 to pool (total: 8)\n",
            "  Detailed metrics: Max Q: 1.0340 | Min Q: -0.8878 | Target Q: -0.0473 | Grad Norm (clipped): 0.0754 | Total train steps: 71510 | Step count: 71541\n",
            "Episode 8100/100000 | Win: 66.00% | Draw: 0.00% | Loss: 34.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 12 | Loss: 0.0120 | Avg Q: -0.0051 | TD Error: 0.0688 | Grad Norm: 0.1578\n",
            "  Detailed metrics: Max Q: 1.0662 | Min Q: -1.0120 | Target Q: -0.0110 | Grad Norm (clipped): 0.1578 | Total train steps: 71966 | Step count: 71997\n",
            "  Detailed metrics: Max Q: 1.0534 | Min Q: -1.0085 | Target Q: -0.0544 | Grad Norm (clipped): 0.1685 | Total train steps: 72368 | Step count: 72399\n",
            "Episode 8200/100000 | Win: 76.00% | Draw: 1.00% | Loss: 23.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0136 | Avg Q: -0.0417 | TD Error: 0.0680 | Grad Norm: 0.1688\n",
            "  Detailed metrics: Max Q: 0.9881 | Min Q: -0.9210 | Target Q: -0.0251 | Grad Norm (clipped): 0.1688 | Total train steps: 72813 | Step count: 72844\n",
            "  Detailed metrics: Max Q: 1.1127 | Min Q: -0.9816 | Target Q: 0.0017 | Grad Norm (clipped): 0.1579 | Total train steps: 73254 | Step count: 73285\n",
            "Episode 8300/100000 | Win: 82.00% | Draw: 0.00% | Loss: 18.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 5 | Loss: 0.0142 | Avg Q: -0.0061 | TD Error: 0.0672 | Grad Norm: 0.1530\n",
            "  Detailed metrics: Max Q: 1.0764 | Min Q: -0.8905 | Target Q: 0.0045 | Grad Norm (clipped): 0.1530 | Total train steps: 73675 | Step count: 73706\n",
            "  Detailed metrics: Max Q: 0.9427 | Min Q: -1.0382 | Target Q: -0.0173 | Grad Norm (clipped): 0.1655 | Total train steps: 74068 | Step count: 74099\n",
            "Episode 8400/100000 | Win: 81.00% | Draw: 1.00% | Loss: 18.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 12 | Loss: 0.0156 | Avg Q: 0.0432 | TD Error: 0.0710 | Grad Norm: 0.1629\n",
            "  Detailed metrics: Max Q: 1.0696 | Min Q: -0.9083 | Target Q: 0.0364 | Grad Norm (clipped): 0.1629 | Total train steps: 74474 | Step count: 74505\n",
            "  Detailed metrics: Max Q: 0.9740 | Min Q: -0.9681 | Target Q: -0.0448 | Grad Norm (clipped): 0.1228 | Total train steps: 74902 | Step count: 74933\n",
            "Episode 8500/100000 | Win: 65.00% | Draw: 2.00% | Loss: 33.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 13 | Loss: 0.0122 | Avg Q: -0.0245 | TD Error: 0.0691 | Grad Norm: 0.1626\n",
            "  Detailed metrics: Max Q: 1.0648 | Min Q: -1.0420 | Target Q: -0.0293 | Grad Norm (clipped): 0.1626 | Total train steps: 75381 | Step count: 75412\n",
            "  Detailed metrics: Max Q: 1.0743 | Min Q: -0.9838 | Target Q: 0.0345 | Grad Norm (clipped): 0.1598 | Total train steps: 75781 | Step count: 75812\n",
            "Episode 8600/100000 | Win: 67.00% | Draw: 2.00% | Loss: 31.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 5 | Loss: 0.0199 | Avg Q: -0.0262 | TD Error: 0.0812 | Grad Norm: 0.1982\n",
            "  Detailed metrics: Max Q: 1.0937 | Min Q: -0.8370 | Target Q: -0.0214 | Grad Norm (clipped): 0.1982 | Total train steps: 76162 | Step count: 76193\n",
            "  Detailed metrics: Max Q: 1.0824 | Min Q: -0.7784 | Target Q: -0.0890 | Grad Norm (clipped): 0.1926 | Total train steps: 76551 | Step count: 76582\n",
            "Episode 8700/100000 | Win: 71.00% | Draw: 1.00% | Loss: 28.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 6 | Loss: 0.0196 | Avg Q: 0.0481 | TD Error: 0.0821 | Grad Norm: 0.2333\n",
            "  Detailed metrics: Max Q: 1.0415 | Min Q: -0.9328 | Target Q: 0.0532 | Grad Norm (clipped): 0.2333 | Total train steps: 76933 | Step count: 76964\n",
            "  Detailed metrics: Max Q: 0.9879 | Min Q: -0.9806 | Target Q: 0.0488 | Grad Norm (clipped): 0.1166 | Total train steps: 77373 | Step count: 77404\n",
            "Episode 8800/100000 | Win: 73.00% | Draw: 1.00% | Loss: 26.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0093 | Avg Q: -0.0047 | TD Error: 0.0613 | Grad Norm: 0.1386\n",
            "  Detailed metrics: Max Q: 1.0275 | Min Q: -0.9722 | Target Q: -0.0010 | Grad Norm (clipped): 0.1386 | Total train steps: 77825 | Step count: 77856\n",
            "  Detailed metrics: Max Q: 1.0496 | Min Q: -0.9576 | Target Q: -0.0083 | Grad Norm (clipped): 0.1752 | Total train steps: 78245 | Step count: 78276\n",
            "Episode 8900/100000 | Win: 65.00% | Draw: 2.00% | Loss: 33.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 4 | Loss: 0.0146 | Avg Q: 0.0558 | TD Error: 0.0739 | Grad Norm: 0.1630\n",
            "  Detailed metrics: Max Q: 1.0497 | Min Q: -0.8262 | Target Q: 0.0784 | Grad Norm (clipped): 0.1630 | Total train steps: 78685 | Step count: 78716\n",
            "  Detailed metrics: Max Q: 1.0660 | Min Q: -0.9896 | Target Q: 0.0604 | Grad Norm (clipped): 0.1546 | Total train steps: 79058 | Step count: 79089\n",
            "Episode 9000/100000 | Win: 65.00% | Draw: 2.00% | Loss: 33.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 5 | Loss: 0.0126 | Avg Q: -0.0904 | TD Error: 0.0709 | Grad Norm: 0.1398\n",
            "  Detailed metrics: Max Q: 0.9382 | Min Q: -1.0369 | Target Q: -0.0757 | Grad Norm (clipped): 0.1398 | Total train steps: 79478 | Step count: 79509\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_9000.pt\n",
            "  Added frozen opponent from episode 9000 to pool (total: 9)\n",
            "  Detailed metrics: Max Q: 1.0701 | Min Q: -0.8341 | Target Q: 0.0541 | Grad Norm (clipped): 0.1561 | Total train steps: 79920 | Step count: 79951\n",
            "Episode 9100/100000 | Win: 70.00% | Draw: 2.00% | Loss: 28.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 3 | Loss: 0.0138 | Avg Q: -0.0520 | TD Error: 0.0666 | Grad Norm: 0.1994\n",
            "  Detailed metrics: Max Q: 1.0594 | Min Q: -1.0749 | Target Q: -0.0409 | Grad Norm (clipped): 0.1994 | Total train steps: 80285 | Step count: 80316\n",
            "  Detailed metrics: Max Q: 1.1722 | Min Q: -0.9412 | Target Q: 0.0521 | Grad Norm (clipped): 0.2044 | Total train steps: 80696 | Step count: 80727\n",
            "Episode 9200/100000 | Win: 75.00% | Draw: 2.00% | Loss: 23.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0119 | Avg Q: 0.0424 | TD Error: 0.0679 | Grad Norm: 0.1451\n",
            "  Detailed metrics: Max Q: 1.0439 | Min Q: -0.8900 | Target Q: 0.0424 | Grad Norm (clipped): 0.1451 | Total train steps: 81118 | Step count: 81149\n",
            "  Detailed metrics: Max Q: 1.0987 | Min Q: -0.8219 | Target Q: 0.0665 | Grad Norm (clipped): 0.2000 | Total train steps: 81543 | Step count: 81574\n",
            "Episode 9300/100000 | Win: 73.00% | Draw: 0.00% | Loss: 27.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0149 | Avg Q: 0.0161 | TD Error: 0.0713 | Grad Norm: 0.1737\n",
            "  Detailed metrics: Max Q: 1.0249 | Min Q: -1.0178 | Target Q: 0.0083 | Grad Norm (clipped): 0.1737 | Total train steps: 81978 | Step count: 82009\n",
            "  Detailed metrics: Max Q: 1.0464 | Min Q: -0.9014 | Target Q: 0.0199 | Grad Norm (clipped): 0.1843 | Total train steps: 82385 | Step count: 82416\n",
            "Episode 9400/100000 | Win: 76.00% | Draw: 0.00% | Loss: 24.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0206 | Avg Q: 0.0011 | TD Error: 0.0831 | Grad Norm: 0.2016\n",
            "  Detailed metrics: Max Q: 1.1427 | Min Q: -1.0553 | Target Q: -0.0068 | Grad Norm (clipped): 0.2016 | Total train steps: 82870 | Step count: 82901\n",
            "  Detailed metrics: Max Q: 1.0148 | Min Q: -0.9274 | Target Q: 0.0386 | Grad Norm (clipped): 0.1671 | Total train steps: 83294 | Step count: 83325\n",
            "Episode 9500/100000 | Win: 79.00% | Draw: 2.00% | Loss: 19.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 6 | Loss: 0.0138 | Avg Q: 0.0550 | TD Error: 0.0780 | Grad Norm: 0.1536\n",
            "  Detailed metrics: Max Q: 1.0584 | Min Q: -1.0222 | Target Q: 0.0662 | Grad Norm (clipped): 0.1536 | Total train steps: 83736 | Step count: 83767\n",
            "  Detailed metrics: Max Q: 1.1023 | Min Q: -1.0742 | Target Q: 0.0649 | Grad Norm (clipped): 0.1798 | Total train steps: 84174 | Step count: 84205\n",
            "Episode 9600/100000 | Win: 75.00% | Draw: 1.00% | Loss: 24.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 4 | Loss: 0.0125 | Avg Q: 0.0845 | TD Error: 0.0719 | Grad Norm: 0.1358\n",
            "  Detailed metrics: Max Q: 1.0568 | Min Q: -0.9028 | Target Q: 0.0792 | Grad Norm (clipped): 0.1358 | Total train steps: 84620 | Step count: 84651\n",
            "  Detailed metrics: Max Q: 1.0189 | Min Q: -0.9649 | Target Q: 0.0789 | Grad Norm (clipped): 0.1580 | Total train steps: 85079 | Step count: 85110\n",
            "Episode 9700/100000 | Win: 75.00% | Draw: 1.00% | Loss: 24.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 4 | Loss: 0.0231 | Avg Q: -0.0056 | TD Error: 0.0873 | Grad Norm: 0.2108\n",
            "  Detailed metrics: Max Q: 1.0968 | Min Q: -0.9794 | Target Q: -0.0158 | Grad Norm (clipped): 0.2108 | Total train steps: 85533 | Step count: 85564\n",
            "  Detailed metrics: Max Q: 1.0531 | Min Q: -0.9199 | Target Q: 0.0872 | Grad Norm (clipped): 0.1770 | Total train steps: 85998 | Step count: 86029\n",
            "Episode 9800/100000 | Win: 62.00% | Draw: 2.00% | Loss: 36.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 5 | Loss: 0.0218 | Avg Q: 0.0461 | TD Error: 0.0927 | Grad Norm: 0.2016\n",
            "  Detailed metrics: Max Q: 0.9299 | Min Q: -0.8587 | Target Q: 0.0588 | Grad Norm (clipped): 0.2016 | Total train steps: 86409 | Step count: 86440\n",
            "  Detailed metrics: Max Q: 1.0963 | Min Q: -0.8211 | Target Q: 0.0919 | Grad Norm (clipped): 0.1444 | Total train steps: 86856 | Step count: 86887\n",
            "Episode 9900/100000 | Win: 56.00% | Draw: 0.00% | Loss: 44.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 5 | Loss: 0.0173 | Avg Q: 0.0810 | TD Error: 0.0682 | Grad Norm: 0.1836\n",
            "  Detailed metrics: Max Q: 1.0603 | Min Q: -0.9053 | Target Q: 0.0920 | Grad Norm (clipped): 0.1836 | Total train steps: 87244 | Step count: 87275\n",
            "  Detailed metrics: Max Q: 1.0442 | Min Q: -0.9327 | Target Q: 0.0778 | Grad Norm (clipped): 0.1748 | Total train steps: 87693 | Step count: 87724\n",
            "Episode 10000/100000 | Win: 93.00% | Draw: 0.00% | Loss: 7.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 12 | Loss: 0.0177 | Avg Q: 0.0745 | TD Error: 0.0771 | Grad Norm: 0.1867\n",
            "  Detailed metrics: Max Q: 1.0473 | Min Q: -0.9928 | Target Q: 0.0759 | Grad Norm (clipped): 0.1867 | Total train steps: 88145 | Step count: 88176\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_10000.pt\n",
            "  Added frozen opponent from episode 10000 to pool (total: 10)\n",
            "  Detailed metrics: Max Q: 1.0374 | Min Q: -0.9512 | Target Q: 0.0846 | Grad Norm (clipped): 0.1458 | Total train steps: 88596 | Step count: 88627\n",
            "Episode 10100/100000 | Win: 50.00% | Draw: 0.00% | Loss: 50.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 4 | Loss: 0.0232 | Avg Q: 0.0925 | TD Error: 0.0942 | Grad Norm: 0.2062\n",
            "  Detailed metrics: Max Q: 1.0367 | Min Q: -0.8549 | Target Q: 0.1018 | Grad Norm (clipped): 0.2062 | Total train steps: 89051 | Step count: 89082\n",
            "  Detailed metrics: Max Q: 0.9831 | Min Q: -0.8915 | Target Q: 0.1082 | Grad Norm (clipped): 0.1257 | Total train steps: 89475 | Step count: 89506\n",
            "Episode 10200/100000 | Win: 89.00% | Draw: 0.00% | Loss: 11.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0177 | Avg Q: 0.0806 | TD Error: 0.0836 | Grad Norm: 0.1732\n",
            "  Detailed metrics: Max Q: 1.0504 | Min Q: -0.9046 | Target Q: 0.0808 | Grad Norm (clipped): 0.1732 | Total train steps: 89897 | Step count: 89928\n",
            "  Detailed metrics: Max Q: 1.0383 | Min Q: -0.9429 | Target Q: 0.0897 | Grad Norm (clipped): 0.1661 | Total train steps: 90329 | Step count: 90360\n",
            "Episode 10300/100000 | Win: 71.00% | Draw: 0.00% | Loss: 29.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 2 | Loss: 0.0117 | Avg Q: 0.0243 | TD Error: 0.0695 | Grad Norm: 0.1844\n",
            "  Detailed metrics: Max Q: 1.0240 | Min Q: -1.0627 | Target Q: 0.0424 | Grad Norm (clipped): 0.1844 | Total train steps: 90786 | Step count: 90817\n",
            "  Detailed metrics: Max Q: 0.9763 | Min Q: -0.9497 | Target Q: 0.0249 | Grad Norm (clipped): 0.1696 | Total train steps: 91266 | Step count: 91297\n",
            "Episode 10400/100000 | Win: 60.00% | Draw: 0.00% | Loss: 40.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0193 | Avg Q: 0.1254 | TD Error: 0.0828 | Grad Norm: 0.1804\n",
            "  Detailed metrics: Max Q: 1.0695 | Min Q: -0.8556 | Target Q: 0.1209 | Grad Norm (clipped): 0.1804 | Total train steps: 91691 | Step count: 91722\n",
            "  Detailed metrics: Max Q: 1.0510 | Min Q: -0.9343 | Target Q: 0.0452 | Grad Norm (clipped): 0.1997 | Total train steps: 92122 | Step count: 92153\n",
            "Episode 10500/100000 | Win: 73.00% | Draw: 0.00% | Loss: 27.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 0 | Loss: 0.0000 | Avg Q: 0.0000 | TD Error: 0.0000 | Grad Norm: 0.0000\n",
            "  Detailed metrics: Max Q: 0.0000 | Min Q: 0.0000 | Target Q: 0.0000 | Grad Norm (clipped): 0.0000 | Total train steps: 92534 | Step count: 92565\n",
            "  Detailed metrics: Max Q: 1.1214 | Min Q: -0.9141 | Target Q: 0.0592 | Grad Norm (clipped): 0.1731 | Total train steps: 93020 | Step count: 93051\n",
            "Episode 10600/100000 | Win: 69.00% | Draw: 0.00% | Loss: 31.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0219 | Avg Q: 0.1331 | TD Error: 0.0886 | Grad Norm: 0.1847\n",
            "  Detailed metrics: Max Q: 1.1104 | Min Q: -0.8577 | Target Q: 0.1419 | Grad Norm (clipped): 0.1847 | Total train steps: 93409 | Step count: 93440\n",
            "  Detailed metrics: Max Q: 1.1013 | Min Q: -0.9214 | Target Q: 0.0930 | Grad Norm (clipped): 0.2187 | Total train steps: 93799 | Step count: 93830\n",
            "Episode 10700/100000 | Win: 87.00% | Draw: 0.00% | Loss: 13.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 15 | Loss: 0.0206 | Avg Q: 0.0867 | TD Error: 0.0850 | Grad Norm: 0.1911\n",
            "  Detailed metrics: Max Q: 1.0428 | Min Q: -0.9136 | Target Q: 0.0929 | Grad Norm (clipped): 0.1911 | Total train steps: 94211 | Step count: 94242\n",
            "  Detailed metrics: Max Q: 0.9964 | Min Q: -0.8936 | Target Q: 0.0916 | Grad Norm (clipped): 0.1746 | Total train steps: 94656 | Step count: 94687\n",
            "Episode 10800/100000 | Win: 72.00% | Draw: 0.00% | Loss: 28.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 5 | Loss: 0.0165 | Avg Q: 0.1030 | TD Error: 0.0793 | Grad Norm: 0.1698\n",
            "  Detailed metrics: Max Q: 1.0535 | Min Q: -1.0204 | Target Q: 0.1000 | Grad Norm (clipped): 0.1698 | Total train steps: 95054 | Step count: 95085\n",
            "  Detailed metrics: Max Q: 1.0316 | Min Q: -0.9213 | Target Q: 0.1243 | Grad Norm (clipped): 0.1802 | Total train steps: 95478 | Step count: 95509\n",
            "Episode 10900/100000 | Win: 67.00% | Draw: 2.00% | Loss: 31.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 6 | Loss: 0.0210 | Avg Q: 0.0869 | TD Error: 0.0847 | Grad Norm: 0.1743\n",
            "  Detailed metrics: Max Q: 0.9369 | Min Q: -0.8541 | Target Q: 0.0928 | Grad Norm (clipped): 0.1743 | Total train steps: 95898 | Step count: 95929\n",
            "  Detailed metrics: Max Q: 1.0606 | Min Q: -0.9901 | Target Q: 0.1066 | Grad Norm (clipped): 0.2327 | Total train steps: 96306 | Step count: 96337\n",
            "Episode 11000/100000 | Win: 67.00% | Draw: 0.00% | Loss: 33.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 10 | Loss: 0.0154 | Avg Q: 0.1316 | TD Error: 0.0773 | Grad Norm: 0.1858\n",
            "  Detailed metrics: Max Q: 1.0726 | Min Q: -0.9892 | Target Q: 0.1269 | Grad Norm (clipped): 0.1858 | Total train steps: 96740 | Step count: 96771\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_11000.pt\n",
            "  Added frozen opponent from episode 11000 to pool (total: 11)\n",
            "  Detailed metrics: Max Q: 1.0312 | Min Q: -0.9905 | Target Q: 0.0317 | Grad Norm (clipped): 0.1533 | Total train steps: 97149 | Step count: 97180\n",
            "Episode 11100/100000 | Win: 74.00% | Draw: 0.00% | Loss: 26.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 4 | Loss: 0.0130 | Avg Q: 0.0527 | TD Error: 0.0713 | Grad Norm: 0.1689\n",
            "  Detailed metrics: Max Q: 1.0196 | Min Q: -1.1016 | Target Q: 0.0636 | Grad Norm (clipped): 0.1689 | Total train steps: 97584 | Step count: 97615\n",
            "  Detailed metrics: Max Q: 1.0449 | Min Q: -0.9473 | Target Q: 0.0589 | Grad Norm (clipped): 0.2152 | Total train steps: 97988 | Step count: 98019\n",
            "Episode 11200/100000 | Win: 64.00% | Draw: 0.00% | Loss: 36.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 5 | Loss: 0.0107 | Avg Q: 0.1686 | TD Error: 0.0719 | Grad Norm: 0.1411\n",
            "  Detailed metrics: Max Q: 1.1184 | Min Q: -0.7676 | Target Q: 0.1592 | Grad Norm (clipped): 0.1411 | Total train steps: 98408 | Step count: 98439\n",
            "  Detailed metrics: Max Q: 1.0712 | Min Q: -0.8996 | Target Q: 0.0993 | Grad Norm (clipped): 0.1761 | Total train steps: 98827 | Step count: 98858\n",
            "Episode 11300/100000 | Win: 71.00% | Draw: 0.00% | Loss: 29.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 4 | Loss: 0.0212 | Avg Q: 0.0743 | TD Error: 0.0898 | Grad Norm: 0.1945\n",
            "  Detailed metrics: Max Q: 1.0093 | Min Q: -1.0581 | Target Q: 0.0570 | Grad Norm (clipped): 0.1945 | Total train steps: 99240 | Step count: 99271\n",
            "  Detailed metrics: Max Q: 1.0336 | Min Q: -0.8678 | Target Q: 0.0969 | Grad Norm (clipped): 0.1481 | Total train steps: 99673 | Step count: 99704\n",
            "Episode 11400/100000 | Win: 70.00% | Draw: 0.00% | Loss: 30.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0166 | Avg Q: 0.1520 | TD Error: 0.0774 | Grad Norm: 0.1774\n",
            "  Detailed metrics: Max Q: 1.0335 | Min Q: -0.8660 | Target Q: 0.1540 | Grad Norm (clipped): 0.1774 | Total train steps: 100107 | Step count: 100138\n",
            "  Detailed metrics: Max Q: 1.0821 | Min Q: -0.9499 | Target Q: 0.1016 | Grad Norm (clipped): 0.1544 | Total train steps: 100511 | Step count: 100542\n",
            "Episode 11500/100000 | Win: 81.00% | Draw: 0.00% | Loss: 19.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0157 | Avg Q: 0.1239 | TD Error: 0.0771 | Grad Norm: 0.1637\n",
            "  Detailed metrics: Max Q: 1.0327 | Min Q: -1.0103 | Target Q: 0.1366 | Grad Norm (clipped): 0.1637 | Total train steps: 100930 | Step count: 100961\n",
            "  Detailed metrics: Max Q: 1.0264 | Min Q: -0.7957 | Target Q: 0.1221 | Grad Norm (clipped): 0.2021 | Total train steps: 101371 | Step count: 101402\n",
            "Episode 11600/100000 | Win: 79.00% | Draw: 0.00% | Loss: 21.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 13 | Loss: 0.0193 | Avg Q: 0.1230 | TD Error: 0.0853 | Grad Norm: 0.1858\n",
            "  Detailed metrics: Max Q: 1.0414 | Min Q: -0.8701 | Target Q: 0.1330 | Grad Norm (clipped): 0.1858 | Total train steps: 101798 | Step count: 101829\n",
            "  Detailed metrics: Max Q: 1.0568 | Min Q: -0.9378 | Target Q: 0.1414 | Grad Norm (clipped): 0.1526 | Total train steps: 102252 | Step count: 102283\n",
            "Episode 11700/100000 | Win: 77.00% | Draw: 0.00% | Loss: 23.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0158 | Avg Q: 0.1240 | TD Error: 0.0810 | Grad Norm: 0.1792\n",
            "  Detailed metrics: Max Q: 1.0462 | Min Q: -0.8703 | Target Q: 0.1295 | Grad Norm (clipped): 0.1792 | Total train steps: 102688 | Step count: 102719\n",
            "  Detailed metrics: Max Q: 1.0709 | Min Q: -0.6618 | Target Q: 0.2136 | Grad Norm (clipped): 0.1928 | Total train steps: 103111 | Step count: 103142\n",
            "Episode 11800/100000 | Win: 78.00% | Draw: 0.00% | Loss: 22.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 14 | Loss: 0.0133 | Avg Q: 0.0988 | TD Error: 0.0752 | Grad Norm: 0.1842\n",
            "  Detailed metrics: Max Q: 1.0863 | Min Q: -0.9510 | Target Q: 0.1094 | Grad Norm (clipped): 0.1842 | Total train steps: 103513 | Step count: 103544\n",
            "  Detailed metrics: Max Q: 1.0864 | Min Q: -0.8175 | Target Q: 0.2013 | Grad Norm (clipped): 0.1646 | Total train steps: 103931 | Step count: 103962\n",
            "Episode 11900/100000 | Win: 77.00% | Draw: 1.00% | Loss: 22.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0161 | Avg Q: 0.1666 | TD Error: 0.0757 | Grad Norm: 0.1551\n",
            "  Detailed metrics: Max Q: 1.0517 | Min Q: -0.8900 | Target Q: 0.1647 | Grad Norm (clipped): 0.1551 | Total train steps: 104326 | Step count: 104357\n",
            "  Detailed metrics: Max Q: 1.0508 | Min Q: -0.9591 | Target Q: 0.1321 | Grad Norm (clipped): 0.1553 | Total train steps: 104712 | Step count: 104743\n",
            "Episode 12000/100000 | Win: 82.00% | Draw: 0.00% | Loss: 18.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0183 | Avg Q: 0.1567 | TD Error: 0.0796 | Grad Norm: 0.1943\n",
            "  Detailed metrics: Max Q: 1.0893 | Min Q: -0.9233 | Target Q: 0.1745 | Grad Norm (clipped): 0.1943 | Total train steps: 105096 | Step count: 105127\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_12000.pt\n",
            "  Added frozen opponent from episode 12000 to pool (total: 12)\n",
            "  Detailed metrics: Max Q: 1.0581 | Min Q: -0.9192 | Target Q: 0.1525 | Grad Norm (clipped): 0.1680 | Total train steps: 105522 | Step count: 105553\n",
            "Episode 12100/100000 | Win: 85.00% | Draw: 4.00% | Loss: 11.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 6 | Loss: 0.0153 | Avg Q: 0.1937 | TD Error: 0.0769 | Grad Norm: 0.1415\n",
            "  Detailed metrics: Max Q: 1.0958 | Min Q: -1.0300 | Target Q: 0.1942 | Grad Norm (clipped): 0.1415 | Total train steps: 105973 | Step count: 106004\n",
            "  Detailed metrics: Max Q: 1.0416 | Min Q: -0.9884 | Target Q: 0.1114 | Grad Norm (clipped): 0.1924 | Total train steps: 106391 | Step count: 106422\n",
            "Episode 12200/100000 | Win: 84.00% | Draw: 1.00% | Loss: 15.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 12 | Loss: 0.0226 | Avg Q: 0.1311 | TD Error: 0.0894 | Grad Norm: 0.2251\n",
            "  Detailed metrics: Max Q: 1.0608 | Min Q: -0.9949 | Target Q: 0.1213 | Grad Norm (clipped): 0.2251 | Total train steps: 106794 | Step count: 106825\n",
            "  Detailed metrics: Max Q: 1.0890 | Min Q: -0.9634 | Target Q: 0.0869 | Grad Norm (clipped): 0.1550 | Total train steps: 107196 | Step count: 107227\n",
            "Episode 12300/100000 | Win: 85.00% | Draw: 0.00% | Loss: 15.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 10 | Loss: 0.0101 | Avg Q: 0.1329 | TD Error: 0.0648 | Grad Norm: 0.1678\n",
            "  Detailed metrics: Max Q: 1.0748 | Min Q: -1.0308 | Target Q: 0.1382 | Grad Norm (clipped): 0.1678 | Total train steps: 107617 | Step count: 107648\n",
            "  Detailed metrics: Max Q: 1.0454 | Min Q: -0.9083 | Target Q: 0.1313 | Grad Norm (clipped): 0.1310 | Total train steps: 108041 | Step count: 108072\n",
            "Episode 12400/100000 | Win: 77.00% | Draw: 0.00% | Loss: 23.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 4 | Loss: 0.0114 | Avg Q: 0.1535 | TD Error: 0.0748 | Grad Norm: 0.1603\n",
            "  Detailed metrics: Max Q: 1.0901 | Min Q: -0.9156 | Target Q: 0.1517 | Grad Norm (clipped): 0.1603 | Total train steps: 108413 | Step count: 108444\n",
            "  Detailed metrics: Max Q: 1.1093 | Min Q: -1.0556 | Target Q: 0.1990 | Grad Norm (clipped): 0.1542 | Total train steps: 108854 | Step count: 108885\n",
            "Episode 12500/100000 | Win: 85.00% | Draw: 0.00% | Loss: 15.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0219 | Avg Q: 0.1742 | TD Error: 0.0851 | Grad Norm: 0.2221\n",
            "  Detailed metrics: Max Q: 1.0536 | Min Q: -0.9290 | Target Q: 0.1687 | Grad Norm (clipped): 0.2221 | Total train steps: 109261 | Step count: 109292\n",
            "  Detailed metrics: Max Q: 1.0248 | Min Q: -0.8454 | Target Q: 0.1888 | Grad Norm (clipped): 0.1335 | Total train steps: 109628 | Step count: 109659\n",
            "Episode 12600/100000 | Win: 87.00% | Draw: 1.00% | Loss: 12.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0113 | Avg Q: 0.2164 | TD Error: 0.0693 | Grad Norm: 0.1631\n",
            "  Detailed metrics: Max Q: 1.0747 | Min Q: -0.9142 | Target Q: 0.2200 | Grad Norm (clipped): 0.1631 | Total train steps: 110072 | Step count: 110103\n",
            "  Detailed metrics: Max Q: 1.1216 | Min Q: -0.7804 | Target Q: 0.2419 | Grad Norm (clipped): 0.1716 | Total train steps: 110513 | Step count: 110544\n",
            "Episode 12700/100000 | Win: 86.00% | Draw: 0.00% | Loss: 14.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 12 | Loss: 0.0142 | Avg Q: 0.2245 | TD Error: 0.0745 | Grad Norm: 0.1790\n",
            "  Detailed metrics: Max Q: 1.0616 | Min Q: -0.7713 | Target Q: 0.2318 | Grad Norm (clipped): 0.1790 | Total train steps: 110958 | Step count: 110989\n",
            "  Detailed metrics: Max Q: 1.0891 | Min Q: -0.8391 | Target Q: 0.1674 | Grad Norm (clipped): 0.1748 | Total train steps: 111378 | Step count: 111409\n",
            "Episode 12800/100000 | Win: 86.00% | Draw: 0.00% | Loss: 14.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0194 | Avg Q: 0.2492 | TD Error: 0.0819 | Grad Norm: 0.2383\n",
            "  Detailed metrics: Max Q: 1.1163 | Min Q: -0.8328 | Target Q: 0.2269 | Grad Norm (clipped): 0.2383 | Total train steps: 111763 | Step count: 111794\n",
            "  Detailed metrics: Max Q: 1.0454 | Min Q: -0.7377 | Target Q: 0.2145 | Grad Norm (clipped): 0.1835 | Total train steps: 112161 | Step count: 112192\n",
            "Episode 12900/100000 | Win: 71.00% | Draw: 0.00% | Loss: 29.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 3 | Loss: 0.0147 | Avg Q: 0.1730 | TD Error: 0.0785 | Grad Norm: 0.1514\n",
            "  Detailed metrics: Max Q: 1.0426 | Min Q: -0.9030 | Target Q: 0.1872 | Grad Norm (clipped): 0.1514 | Total train steps: 112596 | Step count: 112627\n",
            "  Detailed metrics: Max Q: 1.0732 | Min Q: -0.7583 | Target Q: 0.2197 | Grad Norm (clipped): 0.1367 | Total train steps: 112991 | Step count: 113022\n",
            "Episode 13000/100000 | Win: 84.00% | Draw: 0.00% | Loss: 16.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 6 | Loss: 0.0213 | Avg Q: 0.2281 | TD Error: 0.0826 | Grad Norm: 0.2022\n",
            "  Detailed metrics: Max Q: 1.0884 | Min Q: -0.7943 | Target Q: 0.2232 | Grad Norm (clipped): 0.2022 | Total train steps: 113390 | Step count: 113421\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_13000.pt\n",
            "  Added frozen opponent from episode 13000 to pool (total: 13)\n",
            "  Detailed metrics: Max Q: 1.0576 | Min Q: -0.8005 | Target Q: 0.2309 | Grad Norm (clipped): 0.1514 | Total train steps: 113810 | Step count: 113841\n",
            "Episode 13100/100000 | Win: 83.00% | Draw: 0.00% | Loss: 17.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 3 | Loss: 0.0118 | Avg Q: 0.1771 | TD Error: 0.0773 | Grad Norm: 0.1580\n",
            "  Detailed metrics: Max Q: 0.9739 | Min Q: -0.8241 | Target Q: 0.1756 | Grad Norm (clipped): 0.1580 | Total train steps: 114206 | Step count: 114237\n",
            "  Detailed metrics: Max Q: 0.9590 | Min Q: -0.8161 | Target Q: 0.1868 | Grad Norm (clipped): 0.1538 | Total train steps: 114645 | Step count: 114676\n",
            "Episode 13200/100000 | Win: 73.00% | Draw: 1.00% | Loss: 26.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 13 | Loss: 0.0116 | Avg Q: 0.2427 | TD Error: 0.0702 | Grad Norm: 0.1596\n",
            "  Detailed metrics: Max Q: 1.0442 | Min Q: -0.8017 | Target Q: 0.2345 | Grad Norm (clipped): 0.1596 | Total train steps: 115070 | Step count: 115101\n",
            "  Detailed metrics: Max Q: 1.1243 | Min Q: -0.8561 | Target Q: 0.2634 | Grad Norm (clipped): 0.1578 | Total train steps: 115470 | Step count: 115501\n",
            "Episode 13300/100000 | Win: 82.00% | Draw: 1.00% | Loss: 17.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 10 | Loss: 0.0199 | Avg Q: 0.1898 | TD Error: 0.0838 | Grad Norm: 0.2166\n",
            "  Detailed metrics: Max Q: 1.0436 | Min Q: -0.9985 | Target Q: 0.2003 | Grad Norm (clipped): 0.2166 | Total train steps: 115902 | Step count: 115933\n",
            "  Detailed metrics: Max Q: 1.0593 | Min Q: -0.9079 | Target Q: 0.2450 | Grad Norm (clipped): 0.1676 | Total train steps: 116328 | Step count: 116359\n",
            "Episode 13400/100000 | Win: 79.00% | Draw: 3.00% | Loss: 18.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0119 | Avg Q: 0.2447 | TD Error: 0.0733 | Grad Norm: 0.1518\n",
            "  Detailed metrics: Max Q: 1.1045 | Min Q: -0.9495 | Target Q: 0.2493 | Grad Norm (clipped): 0.1518 | Total train steps: 116715 | Step count: 116746\n",
            "  Detailed metrics: Max Q: 1.0698 | Min Q: -0.7645 | Target Q: 0.2627 | Grad Norm (clipped): 0.1480 | Total train steps: 117128 | Step count: 117159\n",
            "Episode 13500/100000 | Win: 74.00% | Draw: 0.00% | Loss: 26.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0130 | Avg Q: 0.2328 | TD Error: 0.0754 | Grad Norm: 0.1861\n",
            "  Detailed metrics: Max Q: 1.0684 | Min Q: -1.0511 | Target Q: 0.2338 | Grad Norm (clipped): 0.1861 | Total train steps: 117607 | Step count: 117638\n",
            "  Detailed metrics: Max Q: 1.0413 | Min Q: -0.8148 | Target Q: 0.2394 | Grad Norm (clipped): 0.1471 | Total train steps: 118000 | Step count: 118031\n",
            "Episode 13600/100000 | Win: 73.00% | Draw: 0.00% | Loss: 27.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 3 | Loss: 0.0160 | Avg Q: 0.2751 | TD Error: 0.0819 | Grad Norm: 0.2082\n",
            "  Detailed metrics: Max Q: 1.1799 | Min Q: -1.0713 | Target Q: 0.2780 | Grad Norm (clipped): 0.2082 | Total train steps: 118436 | Step count: 118467\n",
            "  Detailed metrics: Max Q: 1.0060 | Min Q: -0.9791 | Target Q: 0.1883 | Grad Norm (clipped): 0.1619 | Total train steps: 118854 | Step count: 118885\n",
            "Episode 13700/100000 | Win: 73.00% | Draw: 0.00% | Loss: 27.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0233 | Avg Q: 0.2090 | TD Error: 0.0820 | Grad Norm: 0.2484\n",
            "  Detailed metrics: Max Q: 1.0660 | Min Q: -0.8882 | Target Q: 0.2106 | Grad Norm (clipped): 0.2484 | Total train steps: 119280 | Step count: 119311\n",
            "  Detailed metrics: Max Q: 1.0613 | Min Q: -0.9552 | Target Q: 0.2348 | Grad Norm (clipped): 0.1567 | Total train steps: 119675 | Step count: 119706\n",
            "Episode 13800/100000 | Win: 79.00% | Draw: 0.00% | Loss: 21.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0145 | Avg Q: 0.2232 | TD Error: 0.0774 | Grad Norm: 0.1707\n",
            "  Detailed metrics: Max Q: 1.0340 | Min Q: -1.0031 | Target Q: 0.2191 | Grad Norm (clipped): 0.1707 | Total train steps: 120078 | Step count: 120109\n",
            "  Detailed metrics: Max Q: 1.1141 | Min Q: -0.9026 | Target Q: 0.2173 | Grad Norm (clipped): 0.1600 | Total train steps: 120494 | Step count: 120525\n",
            "Episode 13900/100000 | Win: 79.00% | Draw: 0.00% | Loss: 21.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0136 | Avg Q: 0.2943 | TD Error: 0.0761 | Grad Norm: 0.1650\n",
            "  Detailed metrics: Max Q: 1.0681 | Min Q: -0.7667 | Target Q: 0.3047 | Grad Norm (clipped): 0.1650 | Total train steps: 120917 | Step count: 120948\n",
            "  Detailed metrics: Max Q: 1.0354 | Min Q: -0.8397 | Target Q: 0.2140 | Grad Norm (clipped): 0.1751 | Total train steps: 121313 | Step count: 121344\n",
            "Episode 14000/100000 | Win: 91.00% | Draw: 0.00% | Loss: 9.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 3 | Loss: 0.0058 | Avg Q: 0.3014 | TD Error: 0.0574 | Grad Norm: 0.1177\n",
            "  Detailed metrics: Max Q: 1.0714 | Min Q: -0.6845 | Target Q: 0.3008 | Grad Norm (clipped): 0.1177 | Total train steps: 121758 | Step count: 121789\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_14000.pt\n",
            "  Added frozen opponent from episode 14000 to pool (total: 14)\n",
            "  Detailed metrics: Max Q: 1.0602 | Min Q: -0.8590 | Target Q: 0.2590 | Grad Norm (clipped): 0.1932 | Total train steps: 122211 | Step count: 122242\n",
            "Episode 14100/100000 | Win: 77.00% | Draw: 0.00% | Loss: 23.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 10 | Loss: 0.0110 | Avg Q: 0.2991 | TD Error: 0.0664 | Grad Norm: 0.1361\n",
            "  Detailed metrics: Max Q: 1.1012 | Min Q: -0.9217 | Target Q: 0.3016 | Grad Norm (clipped): 0.1361 | Total train steps: 122594 | Step count: 122625\n",
            "  Detailed metrics: Max Q: 1.0891 | Min Q: -0.8971 | Target Q: 0.3238 | Grad Norm (clipped): 0.1719 | Total train steps: 123024 | Step count: 123055\n",
            "Episode 14200/100000 | Win: 88.00% | Draw: 0.00% | Loss: 12.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0159 | Avg Q: 0.3096 | TD Error: 0.0791 | Grad Norm: 0.1742\n",
            "  Detailed metrics: Max Q: 1.0710 | Min Q: -0.8139 | Target Q: 0.3117 | Grad Norm (clipped): 0.1742 | Total train steps: 123444 | Step count: 123475\n",
            "  Detailed metrics: Max Q: 1.0388 | Min Q: -0.8843 | Target Q: 0.2476 | Grad Norm (clipped): 0.2258 | Total train steps: 123803 | Step count: 123834\n",
            "Episode 14300/100000 | Win: 87.00% | Draw: 2.00% | Loss: 11.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0119 | Avg Q: 0.3087 | TD Error: 0.0745 | Grad Norm: 0.1589\n",
            "  Detailed metrics: Max Q: 1.0677 | Min Q: -0.8980 | Target Q: 0.3125 | Grad Norm (clipped): 0.1589 | Total train steps: 124255 | Step count: 124286\n",
            "  Detailed metrics: Max Q: 1.0773 | Min Q: -0.7865 | Target Q: 0.3311 | Grad Norm (clipped): 0.1444 | Total train steps: 124676 | Step count: 124707\n",
            "Episode 14400/100000 | Win: 82.00% | Draw: 0.00% | Loss: 18.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 12 | Loss: 0.0137 | Avg Q: 0.3109 | TD Error: 0.0731 | Grad Norm: 0.1608\n",
            "  Detailed metrics: Max Q: 1.0796 | Min Q: -0.8722 | Target Q: 0.3084 | Grad Norm (clipped): 0.1608 | Total train steps: 125085 | Step count: 125116\n",
            "  Detailed metrics: Max Q: 1.0443 | Min Q: -0.9635 | Target Q: 0.2316 | Grad Norm (clipped): 0.1952 | Total train steps: 125529 | Step count: 125560\n",
            "Episode 14500/100000 | Win: 86.00% | Draw: 0.00% | Loss: 14.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0167 | Avg Q: 0.3099 | TD Error: 0.0813 | Grad Norm: 0.1718\n",
            "  Detailed metrics: Max Q: 1.0602 | Min Q: -0.9066 | Target Q: 0.3213 | Grad Norm (clipped): 0.1718 | Total train steps: 125964 | Step count: 125995\n",
            "  Detailed metrics: Max Q: 1.1124 | Min Q: -0.9416 | Target Q: 0.2528 | Grad Norm (clipped): 0.1234 | Total train steps: 126365 | Step count: 126396\n",
            "Episode 14600/100000 | Win: 88.00% | Draw: 0.00% | Loss: 12.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0124 | Avg Q: 0.2775 | TD Error: 0.0739 | Grad Norm: 0.1730\n",
            "  Detailed metrics: Max Q: 1.0767 | Min Q: -0.9366 | Target Q: 0.2835 | Grad Norm (clipped): 0.1730 | Total train steps: 126780 | Step count: 126811\n",
            "  Detailed metrics: Max Q: 1.0118 | Min Q: -0.9799 | Target Q: 0.2301 | Grad Norm (clipped): 0.2154 | Total train steps: 127176 | Step count: 127207\n",
            "Episode 14700/100000 | Win: 83.00% | Draw: 1.00% | Loss: 16.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 6 | Loss: 0.0159 | Avg Q: 0.2846 | TD Error: 0.0768 | Grad Norm: 0.2083\n",
            "  Detailed metrics: Max Q: 1.1147 | Min Q: -0.9499 | Target Q: 0.2666 | Grad Norm (clipped): 0.2083 | Total train steps: 127572 | Step count: 127603\n",
            "  Detailed metrics: Max Q: 1.0653 | Min Q: -0.9387 | Target Q: 0.2074 | Grad Norm (clipped): 0.1911 | Total train steps: 127983 | Step count: 128014\n",
            "Episode 14800/100000 | Win: 78.00% | Draw: 0.00% | Loss: 22.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0196 | Avg Q: 0.3040 | TD Error: 0.0806 | Grad Norm: 0.2194\n",
            "  Detailed metrics: Max Q: 1.0765 | Min Q: -0.9451 | Target Q: 0.2831 | Grad Norm (clipped): 0.2194 | Total train steps: 128415 | Step count: 128446\n",
            "  Detailed metrics: Max Q: 1.0718 | Min Q: -0.9067 | Target Q: 0.2982 | Grad Norm (clipped): 0.2264 | Total train steps: 128851 | Step count: 128882\n",
            "Episode 14900/100000 | Win: 87.00% | Draw: 0.00% | Loss: 13.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0117 | Avg Q: 0.3139 | TD Error: 0.0640 | Grad Norm: 0.1406\n",
            "  Detailed metrics: Max Q: 1.0657 | Min Q: -0.7589 | Target Q: 0.3154 | Grad Norm (clipped): 0.1406 | Total train steps: 129255 | Step count: 129286\n",
            "  Detailed metrics: Max Q: 1.0367 | Min Q: -0.8422 | Target Q: 0.2670 | Grad Norm (clipped): 0.1752 | Total train steps: 129675 | Step count: 129706\n",
            "Episode 15000/100000 | Win: 86.00% | Draw: 1.00% | Loss: 13.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 4 | Loss: 0.0209 | Avg Q: 0.3309 | TD Error: 0.0681 | Grad Norm: 0.1870\n",
            "  Detailed metrics: Max Q: 1.0608 | Min Q: -0.9501 | Target Q: 0.3318 | Grad Norm (clipped): 0.1870 | Total train steps: 130113 | Step count: 130144\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_15000.pt\n",
            "  Added frozen opponent from episode 15000 to pool (total: 15)\n",
            "  Detailed metrics: Max Q: 1.1097 | Min Q: -1.0167 | Target Q: 0.3167 | Grad Norm (clipped): 0.1800 | Total train steps: 130529 | Step count: 130560\n",
            "Episode 15100/100000 | Win: 89.00% | Draw: 0.00% | Loss: 11.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0179 | Avg Q: 0.2633 | TD Error: 0.0775 | Grad Norm: 0.1855\n",
            "  Detailed metrics: Max Q: 1.0676 | Min Q: -0.8600 | Target Q: 0.2519 | Grad Norm (clipped): 0.1855 | Total train steps: 130950 | Step count: 130981\n",
            "  Detailed metrics: Max Q: 0.0000 | Min Q: 0.0000 | Target Q: 0.0000 | Grad Norm (clipped): 0.0000 | Total train steps: 131391 | Step count: 131422\n",
            "Episode 15200/100000 | Win: 82.00% | Draw: 1.00% | Loss: 17.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0126 | Avg Q: 0.2574 | TD Error: 0.0730 | Grad Norm: 0.1671\n",
            "  Detailed metrics: Max Q: 1.0543 | Min Q: -0.7788 | Target Q: 0.2516 | Grad Norm (clipped): 0.1671 | Total train steps: 131865 | Step count: 131896\n",
            "  Detailed metrics: Max Q: 1.0807 | Min Q: -0.8007 | Target Q: 0.2806 | Grad Norm (clipped): 0.1562 | Total train steps: 132225 | Step count: 132256\n",
            "Episode 15300/100000 | Win: 84.00% | Draw: 0.00% | Loss: 16.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 10 | Loss: 0.0211 | Avg Q: 0.2787 | TD Error: 0.0819 | Grad Norm: 0.2260\n",
            "  Detailed metrics: Max Q: 1.0215 | Min Q: -0.8650 | Target Q: 0.2935 | Grad Norm (clipped): 0.2260 | Total train steps: 132676 | Step count: 132707\n",
            "  Detailed metrics: Max Q: 1.0909 | Min Q: -0.8850 | Target Q: 0.3339 | Grad Norm (clipped): 0.1597 | Total train steps: 133085 | Step count: 133116\n",
            "Episode 15400/100000 | Win: 81.00% | Draw: 0.00% | Loss: 19.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0279 | Avg Q: 0.2844 | TD Error: 0.0846 | Grad Norm: 0.2568\n",
            "  Detailed metrics: Max Q: 1.1019 | Min Q: -0.9710 | Target Q: 0.2755 | Grad Norm (clipped): 0.2568 | Total train steps: 133499 | Step count: 133530\n",
            "  Detailed metrics: Max Q: 1.0686 | Min Q: -0.9487 | Target Q: 0.3252 | Grad Norm (clipped): 0.3038 | Total train steps: 133922 | Step count: 133953\n",
            "Episode 15500/100000 | Win: 79.00% | Draw: 0.00% | Loss: 21.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 3 | Loss: 0.0223 | Avg Q: 0.3639 | TD Error: 0.0857 | Grad Norm: 0.2878\n",
            "  Detailed metrics: Max Q: 1.0627 | Min Q: -1.0820 | Target Q: 0.3496 | Grad Norm (clipped): 0.2878 | Total train steps: 134253 | Step count: 134284\n",
            "  Detailed metrics: Max Q: 1.0504 | Min Q: -0.9905 | Target Q: 0.2791 | Grad Norm (clipped): 0.2341 | Total train steps: 134660 | Step count: 134691\n",
            "Episode 15600/100000 | Win: 81.00% | Draw: 1.00% | Loss: 18.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0150 | Avg Q: 0.3567 | TD Error: 0.0784 | Grad Norm: 0.1909\n",
            "  Detailed metrics: Max Q: 1.0459 | Min Q: -0.8197 | Target Q: 0.3521 | Grad Norm (clipped): 0.1909 | Total train steps: 135108 | Step count: 135139\n",
            "  Detailed metrics: Max Q: 1.0527 | Min Q: -0.9061 | Target Q: 0.3270 | Grad Norm (clipped): 0.1894 | Total train steps: 135471 | Step count: 135502\n",
            "Episode 15700/100000 | Win: 85.00% | Draw: 0.00% | Loss: 15.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0157 | Avg Q: 0.2942 | TD Error: 0.0790 | Grad Norm: 0.1937\n",
            "  Detailed metrics: Max Q: 1.0706 | Min Q: -0.9312 | Target Q: 0.3067 | Grad Norm (clipped): 0.1937 | Total train steps: 135950 | Step count: 135981\n",
            "  Detailed metrics: Max Q: 1.1009 | Min Q: -0.7421 | Target Q: 0.3793 | Grad Norm (clipped): 0.1649 | Total train steps: 136366 | Step count: 136397\n",
            "Episode 15800/100000 | Win: 85.00% | Draw: 0.00% | Loss: 15.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 12 | Loss: 0.0134 | Avg Q: 0.3636 | TD Error: 0.0754 | Grad Norm: 0.1599\n",
            "  Detailed metrics: Max Q: 1.0895 | Min Q: -0.7755 | Target Q: 0.3597 | Grad Norm (clipped): 0.1599 | Total train steps: 136769 | Step count: 136800\n",
            "  Detailed metrics: Max Q: 1.0784 | Min Q: -0.9587 | Target Q: 0.3191 | Grad Norm (clipped): 0.1863 | Total train steps: 137188 | Step count: 137219\n",
            "Episode 15900/100000 | Win: 89.00% | Draw: 1.00% | Loss: 10.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0194 | Avg Q: 0.3417 | TD Error: 0.0840 | Grad Norm: 0.1994\n",
            "  Detailed metrics: Max Q: 1.0354 | Min Q: -0.6913 | Target Q: 0.3411 | Grad Norm (clipped): 0.1994 | Total train steps: 137591 | Step count: 137622\n",
            "  Detailed metrics: Max Q: 1.0641 | Min Q: -1.1610 | Target Q: 0.3281 | Grad Norm (clipped): 0.1465 | Total train steps: 138005 | Step count: 138036\n",
            "Episode 16000/100000 | Win: 86.00% | Draw: 0.00% | Loss: 14.00% | Epsilon: 0.0300 | Buffer: 20000/20000 (100.0%) | Train steps: 12 | Loss: 0.0220 | Avg Q: 0.3439 | TD Error: 0.0803 | Grad Norm: 0.2087\n",
            "  Detailed metrics: Max Q: 1.0972 | Min Q: -0.8849 | Target Q: 0.3341 | Grad Norm (clipped): 0.2087 | Total train steps: 138451 | Step count: 138482\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_16000.pt\n",
            "  Added frozen opponent from episode 16000 to pool (total: 16)\n",
            "  Detailed metrics: Max Q: 1.1181 | Min Q: -0.8626 | Target Q: 0.3554 | Grad Norm (clipped): 0.1672 | Total train steps: 138878 | Step count: 138909\n"
          ]
        }
      ],
      "source": [
        "# –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è\n",
        "from datetime import datetime\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_type = TRAINING_CONFIG['model_type']\n",
        "run_id = f\"{model_type}_{timestamp}\"\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫–∏ –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ (–≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö —è—á–µ–π–∫–∞—Ö)\n",
        "run_checkpoint_dir = os.path.join(TRAINING_CONFIG['checkpoint_dir'], run_id)\n",
        "run_log_dir = os.path.join(TRAINING_CONFIG['log_dir'], run_id)\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
        "os.makedirs(run_checkpoint_dir, exist_ok=True)\n",
        "os.makedirs(run_log_dir, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è:\")\n",
        "print(f\"   Checkpoints: {run_checkpoint_dir}\")\n",
        "print(f\"   Logs: {run_log_dir}\")\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ\n",
        "training_complete = threading.Event()\n",
        "stop_training_flag = threading.Event()  # –§–ª–∞–≥ –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—É—á–µ–Ω–∏—è\n",
        "training_thread = None\n",
        "current_metrics_file = None  # –ü—É—Ç—å –∫ —Ç–µ–∫—É—â–µ–º—É —Ñ–∞–π–ª—É –º–µ—Ç—Ä–∏–∫\n",
        "\n",
        "def run_training():\n",
        "    \"\"\"–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ.\"\"\"\n",
        "    global current_metrics_file\n",
        "    try:\n",
        "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–µ—Ç—Ä–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω\n",
        "        # MetricsLogger —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª —Å timestamp –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "        current_metrics_file = os.path.join(run_log_dir, f\"metrics_{timestamp}.csv\")\n",
        "        if TRAINING_CONFIG['model_type'] == 'dqn':\n",
        "            train_dqn(\n",
        "                num_episodes=TRAINING_CONFIG['num_episodes'],\n",
        "                learning_rate=TRAINING_CONFIG['learning_rate'],\n",
        "                discount_factor=TRAINING_CONFIG['discount_factor'],\n",
        "                epsilon=TRAINING_CONFIG['epsilon'],\n",
        "                epsilon_decay=TRAINING_CONFIG['epsilon_decay'],\n",
        "                epsilon_min=TRAINING_CONFIG['epsilon_min'],\n",
        "                batch_size=TRAINING_CONFIG['batch_size'],\n",
        "                replay_buffer_size=TRAINING_CONFIG['replay_buffer_size'],\n",
        "                target_update_freq=TRAINING_CONFIG['target_update_freq'],\n",
        "                soft_update=TRAINING_CONFIG['soft_update'],\n",
        "                tau=TRAINING_CONFIG['tau'],\n",
        "                eval_freq=TRAINING_CONFIG['eval_freq'],\n",
        "                eval_episodes=TRAINING_CONFIG['eval_episodes'],\n",
        "                save_freq=TRAINING_CONFIG['save_freq'],\n",
        "                checkpoint_dir=run_checkpoint_dir,\n",
        "                log_dir=run_log_dir,\n",
        "                device=TRAINING_CONFIG['device'],\n",
        "                seed=TRAINING_CONFIG['seed'],\n",
        "                stop_flag=stop_training_flag,\n",
        "                reward_config=REWARD_CONFIG,\n",
        "                heuristic_distribution=HEURISTIC_DISTRIBUTION,\n",
        "                self_play_config=SELF_PLAY_CONFIG,\n",
        "                network_type=TRAINING_CONFIG['network_type'],\n",
        "                random_opening_config=RANDOM_OPENING_CONFIG,\n",
        "            )\n",
        "        elif TRAINING_CONFIG['model_type'] == 'qlearning':\n",
        "            train_qlearning(\n",
        "                num_episodes=TRAINING_CONFIG['num_episodes'],\n",
        "                learning_rate=TRAINING_CONFIG['learning_rate'],\n",
        "                discount_factor=TRAINING_CONFIG['discount_factor'],\n",
        "                epsilon=TRAINING_CONFIG['epsilon'],\n",
        "                epsilon_decay=TRAINING_CONFIG['epsilon_decay'],\n",
        "                epsilon_min=TRAINING_CONFIG['epsilon_min'],\n",
        "                eval_freq=TRAINING_CONFIG['eval_freq'],\n",
        "                eval_episodes=TRAINING_CONFIG['eval_episodes'],\n",
        "                save_freq=TRAINING_CONFIG['save_freq'],\n",
        "                checkpoint_dir=run_checkpoint_dir,\n",
        "                log_dir=run_log_dir,\n",
        "                seed=TRAINING_CONFIG['seed'],\n",
        "                stop_flag=stop_training_flag,\n",
        "                reward_config=REWARD_CONFIG,\n",
        "                random_opening_config=RANDOM_OPENING_CONFIG,\n",
        "            )\n",
        "    except Exception as e:\n",
        "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        training_complete.set()\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
        "print(\"–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...\")\n",
        "training_thread = threading.Thread(target=run_training, daemon=True)\n",
        "training_thread.start()\n",
        "\n",
        "print(\"–û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ!\")\n",
        "print(\"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é —è—á–µ–π–∫—É –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "**–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—É—á–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–æ –∑–∞–ø—É—â–µ–Ω–æ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üõë –°–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –æ–±—É—á–µ–Ω–∏—é!\n",
            "–û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ —ç–ø–∏–∑–æ–¥–∞.\n",
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üõë –û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –Ω–∞ —ç–ø–∏–∑–æ–¥–µ 16060/100000\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_16060_stopped.pt\n",
            "  Added final frozen opponent to pool (total: 17)\n",
            "\n",
            "Training stopped. Final model saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_final.pt\n"
          ]
        }
      ],
      "source": [
        "# –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è\n",
        "if 'stop_training_flag' in globals() and stop_training_flag is not None:\n",
        "    stop_training_flag.set()\n",
        "    print(\"üõë –°–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –æ–±—É—á–µ–Ω–∏—é!\")\n",
        "    print(\"–û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ —ç–ø–∏–∑–æ–¥–∞.\")\n",
        "    print(\"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  –û–±—É—á–µ–Ω–∏–µ –Ω–µ –∑–∞–ø—É—â–µ–Ω–æ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.\")\n",
        "    print(\"–ï—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –≤—Å–µ –µ—â–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ:\")\n",
        "    print(\"1. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —è–¥—Ä–æ –Ω–æ—É—Ç–±—É–∫–∞ (Kernel -> Restart)\")\n",
        "    print(\"2. –ò–ª–∏ –Ω–∞–π—Ç–∏ –ø—Ä–æ—Ü–µ—Å—Å Python –∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –µ–≥–æ –≤—Ä—É—á–Ω—É—é:\")\n",
        "    print(\"   ps aux | grep train_dqn\")\n",
        "    print(\"   kill <PID>\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\n",
        "\n",
        "–ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤. –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω)\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º run_log_dir, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω, –∏–Ω–∞—á–µ fallback –Ω–∞ TRAINING_CONFIG['log_dir']\n",
        "log_dir_to_use = run_log_dir if 'run_log_dir' in globals() else TRAINING_CONFIG['log_dir']\n",
        "\n",
        "if 'current_metrics_file' in globals() and current_metrics_file and Path(current_metrics_file).exists():\n",
        "    df = load_metrics_from_csv(log_dir_to_use, metrics_file=current_metrics_file)\n",
        "    print(f\"üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∞–π–ª: {Path(current_metrics_file).name}\")\n",
        "else:\n",
        "    df = load_metrics_from_csv(log_dir_to_use)\n",
        "    if not df.empty:\n",
        "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, –∫–∞–∫–æ–π —Ñ–∞–π–ª –±—ã–ª –∑–∞–≥—Ä—É–∂–µ–Ω\n",
        "        csv_files = list(Path(log_dir_to_use).glob(\"metrics_*.csv\"))\n",
        "        if csv_files:\n",
        "            latest_file = max(csv_files, key=lambda x: x.stat().st_ctime)\n",
        "            print(f\"üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∞–π–ª: {latest_file.name}\")\n",
        "\n",
        "if not df.empty:\n",
        "    print(f\"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –º–µ—Ç—Ä–∏–∫\")\n",
        "    print(f\"–ü–æ—Å–ª–µ–¥–Ω–∏–π —ç–ø–∏–∑–æ–¥: {df['step'].max()}\")\n",
        "    print(f\"\\n–ü–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏:\")\n",
        "    print(df.tail(1)[['step'] + [m for m in PLOT_CONFIG['metrics_to_plot'] if m in df.columns]].to_string())\n",
        "    print()\n",
        "    \n",
        "    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏\n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    # –ì—Ä–∞—Ñ–∏–∫ win/draw/loss rates\n",
        "    plot_win_rate_comparison(df)\n",
        "    \n",
        "    # –ì—Ä–∞—Ñ–∏–∫–∏ –¥—Ä—É–≥–∏—Ö –º–µ—Ç—Ä–∏–∫\n",
        "    plot_metrics(df, PLOT_CONFIG['metrics_to_plot'])\n",
        "    \n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≤–µ—Ä—à–µ–Ω–æ –ª–∏ –æ–±—É—á–µ–Ω–∏–µ\n",
        "    if training_complete.is_set():\n",
        "        print(\"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\")\n",
        "    else:\n",
        "        print(f\"‚è≥ –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è... (—ç–ø–∏–∑–æ–¥ {df['step'].max()}/{TRAINING_CONFIG['num_episodes']})\")\n",
        "else:\n",
        "    print(\"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö... –û–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –Ω–∞—á–∞–ª–æ—Å—å.\")\n",
        "    if training_complete.is_set():\n",
        "        print(\"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –Ω–æ –º–µ—Ç—Ä–∏–∫–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
        "\n",
        "–ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∫–∞–∂–¥—ã–µ N —Å–µ–∫—É–Ω–¥.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "UPDATE_INTERVAL = 10  # –û–±–Ω–æ–≤–ª—è—Ç—å –∫–∞–∂–¥—ã–µ N —Å–µ–∫—É–Ω–¥\n",
        "MAX_UPDATES = 1000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π\n",
        "\n",
        "print(f\"–ù–∞—á–∏–Ω–∞—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∫–∞–∂–¥—ã–µ {UPDATE_INTERVAL} —Å–µ–∫—É–Ω–¥...\")\n",
        "print(\"–ù–∞–∂–º–∏—Ç–µ Interrupt (Ctrl+C) —á—Ç–æ–±—ã –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å\")\n",
        "\n",
        "for update_count in range(MAX_UPDATES):\n",
        "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω)\n",
        "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º run_log_dir, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω, –∏–Ω–∞—á–µ fallback –Ω–∞ TRAINING_CONFIG['log_dir']\n",
        "    log_dir_to_use = run_log_dir if 'run_log_dir' in globals() else TRAINING_CONFIG['log_dir']\n",
        "    \n",
        "    if 'current_metrics_file' in globals() and current_metrics_file and Path(current_metrics_file).exists():\n",
        "        df = load_metrics_from_csv(log_dir_to_use, metrics_file=current_metrics_file)\n",
        "    else:\n",
        "        df = load_metrics_from_csv(log_dir_to_use)\n",
        "    \n",
        "    if not df.empty:\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        print(f\"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ #{update_count + 1} | –≠–ø–∏–∑–æ–¥: {df['step'].max()}/{TRAINING_CONFIG['num_episodes']}\")\n",
        "        \n",
        "        # –ì—Ä–∞—Ñ–∏–∫ win/draw/loss rates\n",
        "        plot_win_rate_comparison(df)\n",
        "        \n",
        "        # –ì—Ä–∞—Ñ–∏–∫–∏ –¥—Ä—É–≥–∏—Ö –º–µ—Ç—Ä–∏–∫\n",
        "        plot_metrics(df, PLOT_CONFIG['metrics_to_plot'])\n",
        "        \n",
        "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≤–µ—Ä—à–µ–Ω–æ –ª–∏ –æ–±—É—á–µ–Ω–∏–µ\n",
        "        if training_complete.is_set():\n",
        "            print(\"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\")\n",
        "            break\n",
        "        \n",
        "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏\n",
        "        if len(df) > 0:\n",
        "            last_row = df.iloc[-1]\n",
        "            print(f\"\\n–ü–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ (—ç–ø–∏–∑–æ–¥ {last_row['step']}):\")\n",
        "            for metric in PLOT_CONFIG['metrics_to_plot']:\n",
        "                if metric in last_row:\n",
        "                    print(f\"  {metric}: {last_row[metric]:.4f}\")\n",
        "    else:\n",
        "        print(f\"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö... ({update_count + 1}/{MAX_UPDATES})\")\n",
        "    \n",
        "    # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º\n",
        "    time.sleep(UPDATE_INTERVAL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "–ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –§–∏–Ω–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω)\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º run_log_dir, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω, –∏–Ω–∞—á–µ fallback –Ω–∞ TRAINING_CONFIG['log_dir']\n",
        "log_dir_to_use = run_log_dir if 'run_log_dir' in globals() else TRAINING_CONFIG['log_dir']\n",
        "\n",
        "if 'current_metrics_file' in globals() and current_metrics_file and Path(current_metrics_file).exists():\n",
        "    df = load_metrics_from_csv(log_dir_to_use, metrics_file=current_metrics_file)\n",
        "else:\n",
        "    df = load_metrics_from_csv(log_dir_to_use)\n",
        "\n",
        "if not df.empty:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"–§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"–í—Å–µ–≥–æ —ç–ø–∏–∑–æ–¥–æ–≤: {len(df)}\")\n",
        "    print(f\"–ü–æ—Å–ª–µ–¥–Ω–∏–π —ç–ø–∏–∑–æ–¥: {df['step'].max()}\")\n",
        "    print()\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
        "    if 'win_rate' in df.columns:\n",
        "        print(\"Win Rate:\")\n",
        "        print(f\"  –°—Ä–µ–¥–Ω–µ–µ: {df['win_rate'].mean():.2%}\")\n",
        "        print(f\"  –ü–æ—Å–ª–µ–¥–Ω–µ–µ: {df['win_rate'].iloc[-1]:.2%}\")\n",
        "        print(f\"  –ú–∞–∫—Å–∏–º—É–º: {df['win_rate'].max():.2%}\")\n",
        "        print()\n",
        "    \n",
        "    if 'train_loss' in df.columns:\n",
        "        print(\"Training Loss:\")\n",
        "        print(f\"  –°—Ä–µ–¥–Ω–µ–µ: {df['train_loss'].mean():.4f}\")\n",
        "        print(f\"  –ü–æ—Å–ª–µ–¥–Ω–µ–µ: {df['train_loss'].iloc[-1]:.4f}\")\n",
        "        print(f\"  –ú–∏–Ω–∏–º—É–º: {df['train_loss'].min():.4f}\")\n",
        "        print()\n",
        "    \n",
        "    # –°—Ç—Ä–æ–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏\n",
        "    plot_win_rate_comparison(df)\n",
        "    plot_metrics(df, PLOT_CONFIG['metrics_to_plot'])\n",
        "    \n",
        "    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Win rate\n",
        "    if 'win_rate' in df.columns:\n",
        "        axes[0, 0].plot(df['step'], df['win_rate'], label='Win Rate', color='green')\n",
        "        axes[0, 0].set_title('Win Rate')\n",
        "        axes[0, 0].set_xlabel('Episode')\n",
        "        axes[0, 0].set_ylabel('Rate')\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        axes[0, 0].set_ylim([0, 1])\n",
        "    \n",
        "    # Training loss\n",
        "    if 'train_loss' in df.columns:\n",
        "        axes[0, 1].plot(df['step'], df['train_loss'], label='Loss', color='red')\n",
        "        axes[0, 1].set_title('Training Loss')\n",
        "        axes[0, 1].set_xlabel('Episode')\n",
        "        axes[0, 1].set_ylabel('Loss')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Episode reward\n",
        "    if 'episode_reward' in df.columns:\n",
        "        axes[1, 0].plot(df['step'], df['episode_reward'], label='Reward', color='blue')\n",
        "        axes[1, 0].set_title('Episode Reward')\n",
        "        axes[1, 0].set_xlabel('Episode')\n",
        "        axes[1, 0].set_ylabel('Reward')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Epsilon\n",
        "    if 'epsilon' in df.columns:\n",
        "        axes[1, 1].plot(df['step'], df['epsilon'], label='Epsilon', color='orange')\n",
        "        axes[1, 1].set_title('Epsilon (Exploration Rate)')\n",
        "        axes[1, 1].set_xlabel('Episode')\n",
        "        axes[1, 1].set_ylabel('Epsilon')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
        "else:\n",
        "    print(\"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–±—É—á–µ–Ω–∏–µ –±—ã–ª–æ –∑–∞–ø—É—â–µ–Ω–æ.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü–µ—Ä–µ–∏–º–ø–æ—Ä—Ç –º–æ–¥—É–ª—è compare_checkpoints –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
        "# –í—ã–ø–æ–ª–Ω–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É, –µ—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –æ—à–∏–±–∫—É –ø—Ä–æ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ 'epsilon'\n",
        "import importlib\n",
        "import src.training.compare_checkpoints\n",
        "importlib.reload(src.training.compare_checkpoints)\n",
        "print(\"‚úÖ –ú–æ–¥—É–ª—å compare_checkpoints –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –û—Ü–µ–Ω–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
        "\n",
        "–û—Ü–µ–Ω–∏—Ç–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –ø—Ä–æ—Ç–∏–≤ —Ä–∞–∑–Ω—ã—Ö –æ–ø–ø–æ–Ω–µ–Ω—Ç–æ–≤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º\n",
        "\n",
        "–°—Ä–∞–≤–Ω–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –≤ round-robin —Ç—É—Ä–Ω–∏—Ä–µ. –ö–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å —Å—ã–≥—Ä–∞–µ—Ç –ø—Ä–æ—Ç–∏–≤ –∫–∞–∂–¥–æ–π –¥—Ä—É–≥–æ–π.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º\n",
        "from src.training.compare_checkpoints import compare_checkpoints, plot_comparison_results, print_comparison_results\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
        "COMPARISON_CONFIG = {\n",
        "    \"model_type\": \"dqn\",  # \"dqn\" –∏–ª–∏ \"qlearning\"\n",
        "    \"num_games_per_match\": 100,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–≥—Ä –≤ –∫–∞–∂–¥–æ–º –º–∞—Ç—á–µ\n",
        "    \"epsilon\": 0.01,  # 1% —Ä–∞–Ω–¥–æ–º–∞ (0.01 = 1% —Å–ª—É—á–∞–π–Ω—ã—Ö —Ö–æ–¥–æ–≤)\n",
        "    \n",
        "    \"seed\": 42,\n",
        "    \"device\": None,  # None –¥–ª—è auto-detect, –∏–ª–∏ \"cuda\" –∏–ª–∏ \"cpu\"\n",
        "}\n",
        "\n",
        "# –°–ø–æ—Å–æ–±—ã —É–∫–∞–∑–∞—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç—ã:\n",
        "# 1. –£–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—É—Ç–∏ –∫ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º\n",
        "CHECKPOINT_PATHS = [\n",
        "    # –ü—Ä–∏–º–µ—Ä—ã:\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_5000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_10000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_15000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_20000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_25000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_30000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_35000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_40000.pt\",\n",
        "   #   \"../data/checkpoints/dqn_20251109_000844/dqn_episode_40000.pt\",\n",
        "   #  \"../data/checkpoints/dqn_20251109_000844/dqn_episode_7000.pt\",\n",
        "    # \"../data/checkpoints/dqn_20251109_000844/dqn_episode_8000.pt\",\n",
        "   #  \"../data/checkpoints/dqn_20251108_233748/dqn_episode_10000.pt\",\n",
        "   #  \"../data/checkpoints/dqn_20251108_233748/dqn_episode_13000.pt\",\n",
        "     # \"../data/checkpoints/dqn_20251108_195301/dqn_episode_27000.pt\"\n",
        "     \n",
        "]\n",
        "\n",
        "# 2. –ò–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π—Ç–∏ –≤—Å–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã –≤ –ø–∞–ø–∫–µ\n",
        "# –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞:\n",
        "# CHECKPOINT_DIR = \"data/checkpoints/dqn_20240101_120000\"  # –£–∫–∞–∂–∏—Ç–µ –ø–∞–ø–∫—É —Å —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏\n",
        "# CHECKPOINT_PATHS = sorted(glob.glob(f\"{CHECKPOINT_DIR}/*.pt\"))\n",
        "\n",
        "# 3. –ò–ª–∏ –Ω–∞–π—Ç–∏ –≤—Å–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É\n",
        "# CHECKPOINT_PATHS = sorted(glob.glob(\"data/checkpoints/**/dqn_episode_*.pt\", recursive=True))\n",
        "\n",
        "if not CHECKPOINT_PATHS:\n",
        "    print(\"‚ö†Ô∏è  –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç–∏ –∫ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º –≤ CHECKPOINT_PATHS!\")\n",
        "    print(\"–ò–ª–∏ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –∫–æ–¥ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤.\")\n",
        "else:\n",
        "    print(f\"üìã –ù–∞–π–¥–µ–Ω–æ {len(CHECKPOINT_PATHS)} —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:\")\n",
        "    for i, path in enumerate(CHECKPOINT_PATHS, 1):\n",
        "        print(f\"  {i}. {path}\")\n",
        "    \n",
        "    print(f\"\\n‚öôÔ∏è  –ù–∞—Å—Ç—Ä–æ–π–∫–∏:\")\n",
        "    print(f\"  –¢–∏–ø –º–æ–¥–µ–ª–∏: {COMPARISON_CONFIG['model_type']}\")\n",
        "    print(f\"  –ò–≥—Ä –≤ –º–∞—Ç—á–µ: {COMPARISON_CONFIG['num_games_per_match']}\")\n",
        "    print(f\"  Epsilon (—Ä–∞–Ω–¥–æ–º): {COMPARISON_CONFIG['epsilon']:.1%} ({COMPARISON_CONFIG['epsilon']*100:.1f}% —Å–ª—É—á–∞–π–Ω—ã—Ö —Ö–æ–¥–æ–≤)\")\n",
        "    print(f\"  Seed: {COMPARISON_CONFIG['seed']}\")\n",
        "    \n",
        "    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ\n",
        "    print(f\"\\nüöÄ –ó–∞–ø—É—Å–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è...\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    results = compare_checkpoints(\n",
        "        checkpoint_paths=CHECKPOINT_PATHS,\n",
        "        model_type=COMPARISON_CONFIG[\"model_type\"],\n",
        "        num_games_per_match=COMPARISON_CONFIG[\"num_games_per_match\"],\n",
        "        epsilon=COMPARISON_CONFIG[\"epsilon\"],\n",
        "        device=COMPARISON_CONFIG[\"device\"],\n",
        "        seed=COMPARISON_CONFIG[\"seed\"],\n",
        "        reward_config=RewardConfig,\n",
        "        use_epsilon=True,\n",
        "        verbose=True,\n",
        "    )\n",
        "    \n",
        "    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "    print_comparison_results(results)\n",
        "    \n",
        "    # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "    print(\"\\nüìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\")\n",
        "    plot_comparison_results(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from src.training.eval_model import evaluate_model_against_opponents\n",
        "\n",
        "def evaluate_checkpoints_and_plot(\n",
        "    checkpoint_dir=\"../data/checkpoints/dqn_20251109_102818\",\n",
        "    checkpoint_pattern=\"*.pt\",\n",
        "    model_type=\"dqn\",\n",
        "    opponents=(\"random\", \"heuristic\", \"smart_heuristic\"),\n",
        "    num_episodes=200,\n",
        "    seed=42,\n",
        "    epsilon=0.01\n",
        "):\n",
        "    \"\"\"\n",
        "    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤—Å–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã –≤ –ø–∞–ø–∫–µ –ø—Ä–æ—Ç–∏–≤ –∑–∞–¥–∞–Ω–Ω—ã—Ö –æ–ø–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏ —Å—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫ winrate.\n",
        "    \"\"\"\n",
        "    # –°–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –µ–≥–æ (–ø–æ –Ω–æ–º–µ—Ä—É —ç–ø–∏–∑–æ–¥–∞, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)\n",
        "    pattern = os.path.join(checkpoint_dir, checkpoint_pattern)\n",
        "    def extract_version(path):\n",
        "        import re\n",
        "        filename = os.path.basename(path)\n",
        "        m = re.search(r\"(\\d+)\", filename)\n",
        "        return int(m.group(1)) if m else 0\n",
        "\n",
        "    checkpoint_paths = sorted(glob.glob(pattern), key=extract_version)\n",
        "\n",
        "    if not checkpoint_paths:\n",
        "        print(\"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã —á–µ–∫–ø–æ–∏–Ω—Ç—ã –ø–æ –ø—É—Ç–∏:\", pattern)\n",
        "        return\n",
        "\n",
        "    print(f\"üîç –ù–∞–π–¥–µ–Ω–æ {len(checkpoint_paths)} —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤\")\n",
        "    print(f\"–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ—Ç–∏–≤ {opponents} —Å epsilon={epsilon:.2f} ({epsilon*100:.1f}% random) –Ω–∞ {num_episodes} –ø–∞—Ä—Ç–∏—è—Ö\")\n",
        "    print(\"{:<25} {:>8} {:>12} {:>12} {:>12}\".format(\"Checkpoint\", \"Version\", \"Random\", \"Heuristic\", \"SmartHeur\"))\n",
        "\n",
        "    versions = []\n",
        "    winrates_by_opponent = {opp: [] for opp in opponents}\n",
        "    checkpoint_names = []\n",
        "\n",
        "    for i, path in enumerate(checkpoint_paths, 1):\n",
        "        version = extract_version(path)\n",
        "        print(f\"[{i}/{len(checkpoint_paths)}] {os.path.basename(path)}...\", end=\" \", flush=True)\n",
        "\n",
        "        results = evaluate_model_against_opponents(\n",
        "            model_path=path,\n",
        "            model_type=model_type,\n",
        "            opponents=opponents,\n",
        "            num_episodes=num_episodes,\n",
        "            seed=seed,\n",
        "            use_epsilon=True,\n",
        "        )\n",
        "\n",
        "        # –í—Ä—É—á–Ω—É—é —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º epsilon (–¥–ª—è DQN —Å–¥–µ–ª–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç –µ—Å–ª–∏ –∞–≥–µ–Ω—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç)\n",
        "        try:\n",
        "            from src.agents import QLearningAgent, DQNAgent\n",
        "            if model_type == \"qlearning\":\n",
        "                agent = QLearningAgent(seed=seed)\n",
        "                agent.load(path)\n",
        "            else:\n",
        "                agent = DQNAgent(rows=6, cols=7, seed=seed)\n",
        "                agent.load(path)\n",
        "            if hasattr(agent, 'epsilon'):\n",
        "                agent.epsilon = epsilon\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        versions.append(version)\n",
        "        checkpoint_names.append(os.path.basename(path))\n",
        "        winrates = []\n",
        "        for opp in opponents:\n",
        "            win_rate = results[opp][\"win_rate\"]\n",
        "            winrates.append(win_rate)\n",
        "            winrates_by_opponent[opp].append(win_rate)\n",
        "        print(\"{:<25} {:>8} {:>12.2%} {:>12.2%} {:>12.2%}\".format(\n",
        "            os.path.basename(path),\n",
        "            version,\n",
        "            winrates[0], winrates[1], winrates[2]\n",
        "        ))\n",
        "\n",
        "    # –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    for opp in opponents:\n",
        "        plt.plot(versions, winrates_by_opponent[opp], marker='o', label=opp)\n",
        "    plt.title(f\"Win rate vs different opponents (epsilon={epsilon:.2f}, {num_episodes} –∏–≥—Ä)\")\n",
        "    plt.xlabel(\"Checkpoint version\")\n",
        "    plt.ylabel(\"Win rate\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True)\n",
        "    plt.legend(title=\"Opponent\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate_checkpoints_and_plot(checkpoint_dir=\"../data/checkpoints/dqn_20251109_180811\", use_epsilon=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate_checkpoints_and_plot(checkpoint_dir=\"../data/checkpoints/dqn_20251109_193645\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate_checkpoints_and_plot(checkpoint_dir=\"../data/checkpoints/dqn_20251109_170952\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate_checkpoints_and_plot(checkpoint_dir=\"../data/checkpoints/dqn_20251109_110859\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
