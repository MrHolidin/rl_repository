{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Connect Four RL - Training with Live Metrics\n",
        "\n",
        "–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –ø–æ–∑–≤–æ–ª—è–µ—Ç:\n",
        "- –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è\n",
        "- –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ DQN –∏–ª–∏ Q-learning –∞–≥–µ–Ω—Ç–∞\n",
        "- –í–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ò–º–ø–æ—Ä—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!\n"
          ]
        }
      ],
      "source": [
        "# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥—É–ª–µ–π –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ (autoreload)\n",
        "# –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–º–µ–Ω—è—Ç—å –∫–æ–¥ –≤ .py —Ñ–∞–π–ª–∞—Ö –±–µ–∑ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ —è–¥—Ä–∞ –Ω–æ—É—Ç–±—É–∫–∞\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# –ò–º–ø–æ—Ä—Ç—ã\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import clear_output, display\n",
        "import threading\n",
        "from collections import defaultdict\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É\n",
        "sys.path.insert(0, str(Path().resolve().parent))\n",
        "\n",
        "from src.envs import Connect4Env, RewardConfig\n",
        "from src.agents import DQNAgent, QLearningAgent, RandomAgent, HeuristicAgent, SmartHeuristicAgent\n",
        "from src.utils import MetricsLogger\n",
        "from src.selfplay import SelfPlayConfig\n",
        "from src.training.random_opening import RandomOpeningConfig\n",
        "from src.training.train_dqn import train_dqn\n",
        "from src.training.train_qlearning import train_qlearning\n",
        "\n",
        "print(\"–ò–º–ø–æ—Ä—Ç—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã!\n",
            "–¢–∏–ø –º–æ–¥–µ–ª–∏: dqn\n",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤: 100000\n",
            "\n",
            "–ù–∞–≥—Ä–∞–¥—ã:\n",
            "  –ü–æ–±–µ–¥–∞: 1.0\n",
            "  –ü–æ—Ä–∞–∂–µ–Ω–∏–µ: -1.0\n",
            "  –ù–∏—á—å—è: 0.0\n",
            "  3 –≤ —Ä—è–¥: 0.01\n",
            "  –í—Ä–∞–∂–µ—Å–∫–∏–µ 3 –≤ —Ä—è–¥ (—à—Ç—Ä–∞—Ñ): -0.01\n",
            "  –ù–µ–≤–µ—Ä–Ω—ã–π —Ö–æ–¥: -0.1\n",
            "\n",
            "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–≤—Ä–∏—Å—Ç–∏–∫: {'random': 0.1, 'heuristic': 0.7, 'smart_heuristic': 0.2}\n",
            "\n",
            "Self-play:\n",
            "  –°—Ç–∞—Ç—É—Å: –≤–∫–ª—é—á–µ–Ω\n",
            "  –ù–∞—á–∞–ª–æ —Å —ç–ø–∏–∑–æ–¥–∞: 10000\n",
            "  –î–æ–ª—è self-play: 50.0%\n",
            "  –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ: 500 —ç–ø–∏–∑–æ–¥–æ–≤\n",
            "  –ú–∞–∫—Å. frozen –∞–≥–µ–Ω—Ç–æ–≤: 20\n",
            "\n",
            "Random opening:\n",
            "  –°—Ç–∞—Ç—É—Å: –≤–∫–ª—é—á–µ–Ω\n",
            "  –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: 0.50\n",
            "  –ü–æ–ª—É—Ö–æ–¥—ã: 2-6\n"
          ]
        }
      ],
      "source": [
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è\n",
        "TRAINING_CONFIG = {\n",
        "    # –¢–∏–ø –º–æ–¥–µ–ª–∏\n",
        "    \"model_type\": \"dqn\",  # \"dqn\" –∏–ª–∏ \"qlearning\"\n",
        "    \"network_type\": \"dueling_dqn\", \n",
        "    \n",
        "    \n",
        "    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è\n",
        "    \"num_episodes\": 100000,\n",
        "    \"learning_rate\": 0.0005,\n",
        "    \"discount_factor\": 0.99,\n",
        "    \"epsilon\": 1.0,\n",
        "    \"epsilon_decay\": 0.9995,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 0.995 –¥–ª—è –±–æ–ª–µ–µ –º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ decay\n",
        "    # 0.995 -> –º–∏–Ω–∏–º—É–º –Ω–∞ —ç–ø–∏–∑–æ–¥–µ ~919 (—Å–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä–æ)\n",
        "    # 0.999 -> –º–∏–Ω–∏–º—É–º –Ω–∞ —ç–ø–∏–∑–æ–¥–µ ~4603\n",
        "    # 0.9995 -> –º–∏–Ω–∏–º—É–º –Ω–∞ —ç–ø–∏–∑–æ–¥–µ ~9209 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è 50000 —ç–ø–∏–∑–æ–¥–æ–≤)\n",
        "    # 0.9999 -> –º–∏–Ω–∏–º—É–º –Ω–∞ —ç–ø–∏–∑–æ–¥–µ ~46050 (–æ—á–µ–Ω—å –º–µ–¥–ª–µ–Ω–Ω–æ)\n",
        "    \"epsilon_min\": 0.03,\n",
        "    \n",
        "    # DQN —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è –¥–ª—è Q-learning)\n",
        "    \"batch_size\": 32,\n",
        "    \"replay_buffer_size\": 20000,\n",
        "    \"target_update_freq\": 100,\n",
        "    \"soft_update\": True,\n",
        "    \"tau\": 0.01,\n",
        "    \n",
        "    # –û—Ü–µ–Ω–∫–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
        "    \"eval_freq\": 100,\n",
        "    \"eval_episodes\": 100,\n",
        "    \"save_freq\": 1000,\n",
        "    \n",
        "    # –ü—É—Ç–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞)\n",
        "    \"checkpoint_dir\": str(Path().resolve().parent / \"data\" / \"checkpoints\"),\n",
        "    \"log_dir\": str(Path().resolve().parent / \"data\" / \"logs\"),\n",
        "    \n",
        "    # –î—Ä—É–≥–∏–µ\n",
        "    \"device\": None,  # None –¥–ª—è auto-detect, –∏–ª–∏ \"cuda\" –∏–ª–∏ \"cpu\"\n",
        "    \"seed\": 42,\n",
        "}\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞–≥—Ä–∞–¥\n",
        "REWARD_CONFIG = RewardConfig(\n",
        "    win=1.0,  # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –ø–æ–±–µ–¥—É\n",
        "    loss=-1.0,  # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –ø–æ—Ä–∞–∂–µ–Ω–∏–µ\n",
        "    draw=0.0,  # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –Ω–∏—á—å—é\n",
        "    three_in_row=0.01,  # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ 3 –≤ —Ä—è–¥ (–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞)\n",
        "    opponent_three_in_row=-0.01,  # –®—Ç—Ä–∞—Ñ –∑–∞ –≤—Ä–∞–∂–µ—Å–∫–∏–µ 3 –≤ —Ä—è–¥ (–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —à—Ç—Ä–∞—Ñ)\n",
        "    invalid_action=-0.1,  # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –Ω–µ–≤–µ—Ä–Ω—ã–π —Ö–æ–¥\n",
        ")\n",
        "\n",
        "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –æ–ø–ø–æ–Ω–µ–Ω—Ç–æ–≤\n",
        "HEURISTIC_DISTRIBUTION = {\n",
        "    \"random\": 0.1,\n",
        "    \"heuristic\": 0.7,\n",
        "    \"smart_heuristic\": 0.2,\n",
        "}\n",
        "\n",
        "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è self-play (–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ç–∏–≤ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π —Å–µ–±—è)\n",
        "# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ SELF_PLAY_CONFIG = None, —á—Ç–æ–±—ã –æ—Ç–∫–ª—é—á–∏—Ç—å self-play\n",
        "SELF_PLAY_CONFIG = SelfPlayConfig(\n",
        "    start_episode=10000,  # –° –∫–∞–∫–æ–≥–æ —ç–ø–∏–∑–æ–¥–∞ –Ω–∞—á–∏–Ω–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å frozen DQN\n",
        "    save_every=500,  # –ö–∞–∫ —á–∞—Å—Ç–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—É—é \"–≤–µ—Ä—Å–∏—é —Å–µ–±—è\" –≤ –ø—É–ª (–º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –æ—Ç save_freq)\n",
        "    max_frozen_agents=20,  # –°–∫–æ–ª—å–∫–æ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π –º–∞–∫—Å–∏–º—É–º –¥–µ—Ä–∂–∞—Ç—å –≤ –ø—É–ª–µ\n",
        "    fraction=0.5,  # –î–æ–ª—è —ç–ø–∏–∑–æ–¥–æ–≤, –≥–¥–µ –æ–ø–ø–æ–Ω–µ–Ω—Ç = frozen DQN (0.0-1.0)\n",
        ")\n",
        "\n",
        "# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö —Å—Ç–∞—Ä—Ç–æ–≤—ã—Ö –ø–æ–∑–∏—Ü–∏–π (–ø—Ä–æ–ª–æ–≥ –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º –∞–≥–µ–Ω—Ç–∞)\n",
        "# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ RANDOM_OPENING_CONFIG = None, —á—Ç–æ–±—ã –æ—Ç–∫–ª—é—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–ª–æ–≥\n",
        "RANDOM_OPENING_CONFIG = RandomOpeningConfig(\n",
        "    probability=0.5,  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–∞–ø—É—Å–∫–∞ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø—Ä–æ–ª–æ–≥–∞ –ø–µ—Ä–µ–¥ —ç–ø–∏–∑–æ–¥–æ–º\n",
        "    min_half_moves=2,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—É—Ö–æ–¥–æ–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø—Ä–æ–ª–æ–≥–∞\n",
        "    max_half_moves=6,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—É—Ö–æ–¥–æ–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø—Ä–æ–ª–æ–≥–∞\n",
        ")\n",
        "\n",
        "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "PLOT_CONFIG = {\n",
        "    \"update_freq\": 50,  # –û–±–Ω–æ–≤–ª—è—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ –∫–∞–∂–¥—ã–µ N —ç–ø–∏–∑–æ–¥–æ–≤\n",
        "    \"metrics_to_plot\": [\n",
        "        \"win_rate\",\n",
        "        \"loss_rate\",\n",
        "        \"episode_reward\",\n",
        "        \"episode_length\",\n",
        "        \"epsilon\",\n",
        "        \"train_loss\",\n",
        "        \"train_avg_q\",\n",
        "        \"train_td_error\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "print(\"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã!\")\n",
        "print(f\"–¢–∏–ø –º–æ–¥–µ–ª–∏: {TRAINING_CONFIG['model_type']}\")\n",
        "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤: {TRAINING_CONFIG['num_episodes']}\")\n",
        "print(f\"\\n–ù–∞–≥—Ä–∞–¥—ã:\")\n",
        "print(f\"  –ü–æ–±–µ–¥–∞: {REWARD_CONFIG.win}\")\n",
        "print(f\"  –ü–æ—Ä–∞–∂–µ–Ω–∏–µ: {REWARD_CONFIG.loss}\")\n",
        "print(f\"  –ù–∏—á—å—è: {REWARD_CONFIG.draw}\")\n",
        "print(f\"  3 –≤ —Ä—è–¥: {REWARD_CONFIG.three_in_row}\")\n",
        "print(f\"  –í—Ä–∞–∂–µ—Å–∫–∏–µ 3 –≤ —Ä—è–¥ (—à—Ç—Ä–∞—Ñ): {REWARD_CONFIG.opponent_three_in_row}\")\n",
        "print(f\"  –ù–µ–≤–µ—Ä–Ω—ã–π —Ö–æ–¥: {REWARD_CONFIG.invalid_action}\")\n",
        "print(f\"\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–≤—Ä–∏—Å—Ç–∏–∫: {HEURISTIC_DISTRIBUTION}\")\n",
        "print(\"\\nSelf-play:\")\n",
        "if SELF_PLAY_CONFIG is None:\n",
        "    print(\"  –°—Ç–∞—Ç—É—Å: –æ—Ç–∫–ª—é—á–µ–Ω\")\n",
        "else:\n",
        "    print(\"  –°—Ç–∞—Ç—É—Å: –≤–∫–ª—é—á–µ–Ω\")\n",
        "    print(f\"  –ù–∞—á–∞–ª–æ —Å —ç–ø–∏–∑–æ–¥–∞: {SELF_PLAY_CONFIG.start_episode}\")\n",
        "    print(f\"  –î–æ–ª—è self-play: {SELF_PLAY_CONFIG.fraction:.1%}\")\n",
        "    print(f\"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ: {SELF_PLAY_CONFIG.save_every} —ç–ø–∏–∑–æ–¥–æ–≤\")\n",
        "    print(f\"  –ú–∞–∫—Å. frozen –∞–≥–µ–Ω—Ç–æ–≤: {SELF_PLAY_CONFIG.max_frozen_agents}\")\n",
        "\n",
        "print(\"\\nRandom opening:\")\n",
        "if RANDOM_OPENING_CONFIG is None:\n",
        "    print(\"  –°—Ç–∞—Ç—É—Å: –æ—Ç–∫–ª—é—á–µ–Ω\")\n",
        "else:\n",
        "    print(\"  –°—Ç–∞—Ç—É—Å: –≤–∫–ª—é—á–µ–Ω\")\n",
        "    print(f\"  –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {RANDOM_OPENING_CONFIG.probability:.2f}\")\n",
        "    print(f\"  –ü–æ–ª—É—Ö–æ–¥—ã: {RANDOM_OPENING_CONFIG.min_half_moves}-{RANDOM_OPENING_CONFIG.max_half_moves}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –º–µ—Ç—Ä–∏–∫\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_metrics_from_csv(log_dir: str, metrics_file: str = None) -> pd.DataFrame:\n",
        "    \"\"\"–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ CSV —Ñ–∞–π–ª–∞.\n",
        "    \n",
        "    Args:\n",
        "        log_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –ª–æ–≥–∞–º–∏\n",
        "        metrics_file: –ü—É—Ç—å –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ñ–∞–π–ª—É –º–µ—Ç—Ä–∏–∫ (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è)\n",
        "    \"\"\"\n",
        "    if metrics_file and Path(metrics_file).exists():\n",
        "        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–π —Ñ–∞–π–ª\n",
        "        df = pd.read_csv(metrics_file)\n",
        "        return df\n",
        "    \n",
        "    # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏!)\n",
        "    csv_files = list(Path(log_dir).glob(\"metrics_*.csv\"))\n",
        "    if not csv_files:\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è (st_ctime), –∞ –Ω–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
        "    # –≠—Ç–æ –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ, —Ç–∞–∫ –∫–∞–∫ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –æ–±—É—á–µ–Ω–∏—è\n",
        "    latest_file = max(csv_files, key=lambda x: x.stat().st_ctime)\n",
        "    df = pd.read_csv(latest_file)\n",
        "    return df\n",
        "\n",
        "def plot_metrics(df: pd.DataFrame, metrics_to_plot: list, figsize=(15, 10)):\n",
        "    \"\"\"–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫–∏ –º–µ—Ç—Ä–∏–∫.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤\")\n",
        "        return\n",
        "    \n",
        "    n_metrics = len(metrics_to_plot)\n",
        "    n_cols = 2\n",
        "    n_rows = (n_metrics + n_cols - 1) // n_cols\n",
        "    \n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
        "    if n_metrics == 1:\n",
        "        axes = [axes]\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "    \n",
        "    for i, metric in enumerate(metrics_to_plot):\n",
        "        if metric not in df.columns:\n",
        "            continue\n",
        "        \n",
        "        ax = axes[i]\n",
        "        ax.plot(df['step'], df[metric], label=metric, linewidth=2)\n",
        "        ax.set_xlabel('Episode')\n",
        "        ax.set_ylabel(metric)\n",
        "        ax.set_title(f'{metric} over time')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.legend()\n",
        "        \n",
        "        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ\n",
        "        if len(df) > 0:\n",
        "            last_val = df[metric].iloc[-1]\n",
        "            ax.axhline(y=last_val, color='r', linestyle='--', alpha=0.5)\n",
        "            ax.text(len(df), last_val, f'{last_val:.3f}', \n",
        "                   verticalalignment='bottom', fontsize=9)\n",
        "    \n",
        "    # –°–∫—Ä—ã–≤–∞–µ–º –ª–∏—à–Ω–∏–µ subplots\n",
        "    for i in range(n_metrics, len(axes)):\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_win_rate_comparison(df: pd.DataFrame):\n",
        "    \"\"\"–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è win/draw/loss rates.\"\"\"\n",
        "    if df.empty or 'win_rate' not in df.columns:\n",
        "        return\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    \n",
        "    if 'win_rate' in df.columns:\n",
        "        ax.plot(df['step'], df['win_rate'], label='Win Rate', color='green', linewidth=2)\n",
        "    if 'draw_rate' in df.columns:\n",
        "        ax.plot(df['step'], df['draw_rate'], label='Draw Rate', color='gray', linewidth=2)\n",
        "    if 'loss_rate' in df.columns:\n",
        "        ax.plot(df['step'], df['loss_rate'], label='Loss Rate', color='red', linewidth=2)\n",
        "    \n",
        "    ax.set_xlabel('Episode')\n",
        "    ax.set_ylabel('Rate')\n",
        "    ax.set_title('Win/Draw/Loss Rates over Time')\n",
        "    ax.set_ylim([0, 1])\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"–§—É–Ω–∫—Ü–∏–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–æ—Ç–æ–≤—ã!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π\n",
        "\n",
        "–ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ–±—É—á–µ–Ω–∏–µ. –ì—Ä–∞—Ñ–∏–∫–∏ –±—É–¥—É—Ç –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è:\n",
            "   Checkpoints: /home/holidin/projects/RL/data/checkpoints/dqn_20251111_005147\n",
            "   Logs: /home/holidin/projects/RL/data/logs/dqn_20251111_005147\n",
            "–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...\n",
            "–û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ!\n",
            "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é —è—á–µ–π–∫—É –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting DQN training...\n",
            "Network architecture: DUELING_DQN\n",
            "Episodes: 100000\n",
            "Learning rate: 0.0005\n",
            "Discount factor: 0.99\n",
            "Initial epsilon: 1.0\n",
            "Target update: soft (freq: 100)\n",
            "Soft update tau: 0.01\n",
            "Device: cuda\n",
            "Heuristic distribution: {'random': 0.1, 'heuristic': 0.7, 'smart_heuristic': 0.2}\n",
            "Self-play: configured\n",
            "  Start episode: 10000\n",
            "  Self-play fraction: 50.0%\n",
            "  Save every: 500 episodes\n",
            "  Max frozen agents: 20\n",
            "Random opening: p=0.50, half-moves=2-6\n",
            "\n",
            "  Detailed metrics: Max Q: 0.4616 | Min Q: -0.9798 | Target Q: -0.0872 | Grad Norm (clipped): 0.1945 | Total train steps: 390 | Step count: 421\n",
            "Episode 100/100000 | Win: 13.00% | Draw: 0.00% | Loss: 87.00% | Epsilon: 0.9512 | Buffer: 823/20000 (4.1%) | Train steps: 8 | Loss: 0.0078 | Avg Q: -0.1012 | TD Error: 0.0491 | Grad Norm: 0.1097\n",
            "  Detailed metrics: Max Q: 0.2464 | Min Q: -0.9763 | Target Q: -0.1086 | Grad Norm (clipped): 0.1097 | Total train steps: 792 | Step count: 823\n",
            "  Detailed metrics: Max Q: 0.3958 | Min Q: -1.0206 | Target Q: -0.1168 | Grad Norm (clipped): 0.1214 | Total train steps: 1164 | Step count: 1195\n",
            "Episode 200/100000 | Win: 11.00% | Draw: 0.00% | Loss: 89.00% | Epsilon: 0.9048 | Buffer: 1593/20000 (8.0%) | Train steps: 10 | Loss: 0.0137 | Avg Q: -0.1383 | TD Error: 0.0657 | Grad Norm: 0.1669\n",
            "  Detailed metrics: Max Q: 0.3444 | Min Q: -1.1018 | Target Q: -0.1298 | Grad Norm (clipped): 0.1669 | Total train steps: 1562 | Step count: 1593\n",
            "  Detailed metrics: Max Q: 0.4620 | Min Q: -1.1030 | Target Q: -0.1120 | Grad Norm (clipped): 0.1271 | Total train steps: 1938 | Step count: 1969\n",
            "Episode 300/100000 | Win: 13.00% | Draw: 0.00% | Loss: 87.00% | Epsilon: 0.8607 | Buffer: 2354/20000 (11.8%) | Train steps: 11 | Loss: 0.0063 | Avg Q: -0.1238 | TD Error: 0.0488 | Grad Norm: 0.1312\n",
            "  Detailed metrics: Max Q: 0.2784 | Min Q: -0.9991 | Target Q: -0.1403 | Grad Norm (clipped): 0.1312 | Total train steps: 2323 | Step count: 2354\n",
            "  Detailed metrics: Max Q: 0.2427 | Min Q: -1.1176 | Target Q: -0.1627 | Grad Norm (clipped): 0.1361 | Total train steps: 2693 | Step count: 2724\n",
            "Episode 400/100000 | Win: 15.00% | Draw: 0.00% | Loss: 85.00% | Epsilon: 0.8187 | Buffer: 3123/20000 (15.6%) | Train steps: 13 | Loss: 0.0063 | Avg Q: -0.1327 | TD Error: 0.0493 | Grad Norm: 0.1243\n",
            "  Detailed metrics: Max Q: 0.4728 | Min Q: -1.0775 | Target Q: -0.1276 | Grad Norm (clipped): 0.1243 | Total train steps: 3092 | Step count: 3123\n",
            "  Detailed metrics: Max Q: 0.1978 | Min Q: -1.0643 | Target Q: -0.1177 | Grad Norm (clipped): 0.1170 | Total train steps: 3481 | Step count: 3512\n",
            "Episode 500/100000 | Win: 16.00% | Draw: 0.00% | Loss: 84.00% | Epsilon: 0.7788 | Buffer: 3925/20000 (19.6%) | Train steps: 8 | Loss: 0.0124 | Avg Q: -0.1616 | TD Error: 0.0560 | Grad Norm: 0.1737\n",
            "  Detailed metrics: Max Q: 0.2929 | Min Q: -1.0909 | Target Q: -0.1494 | Grad Norm (clipped): 0.1737 | Total train steps: 3894 | Step count: 3925\n",
            "  Detailed metrics: Max Q: 0.3022 | Min Q: -1.0279 | Target Q: -0.1376 | Grad Norm (clipped): 0.1073 | Total train steps: 4335 | Step count: 4366\n",
            "Episode 600/100000 | Win: 13.00% | Draw: 0.00% | Loss: 87.00% | Epsilon: 0.7408 | Buffer: 4752/20000 (23.8%) | Train steps: 2 | Loss: 0.0037 | Avg Q: -0.1645 | TD Error: 0.0449 | Grad Norm: 0.0957\n",
            "  Detailed metrics: Max Q: 0.0430 | Min Q: -1.1212 | Target Q: -0.1464 | Grad Norm (clipped): 0.0957 | Total train steps: 4721 | Step count: 4752\n",
            "  Detailed metrics: Max Q: 0.3049 | Min Q: -0.9926 | Target Q: -0.1091 | Grad Norm (clipped): 0.0871 | Total train steps: 5110 | Step count: 5141\n",
            "Episode 700/100000 | Win: 19.00% | Draw: 0.00% | Loss: 81.00% | Epsilon: 0.7046 | Buffer: 5531/20000 (27.7%) | Train steps: 11 | Loss: 0.0081 | Avg Q: -0.1174 | TD Error: 0.0484 | Grad Norm: 0.1188\n",
            "  Detailed metrics: Max Q: 0.2384 | Min Q: -1.0028 | Target Q: -0.1253 | Grad Norm (clipped): 0.1188 | Total train steps: 5500 | Step count: 5531\n",
            "  Detailed metrics: Max Q: 0.8412 | Min Q: -1.0854 | Target Q: -0.0887 | Grad Norm (clipped): 0.0891 | Total train steps: 5883 | Step count: 5914\n",
            "Episode 800/100000 | Win: 19.00% | Draw: 2.00% | Loss: 79.00% | Epsilon: 0.6703 | Buffer: 6284/20000 (31.4%) | Train steps: 3 | Loss: 0.0038 | Avg Q: -0.1236 | TD Error: 0.0376 | Grad Norm: 0.0808\n",
            "  Detailed metrics: Max Q: 0.0667 | Min Q: -1.0110 | Target Q: -0.1302 | Grad Norm (clipped): 0.0808 | Total train steps: 6253 | Step count: 6284\n",
            "  Detailed metrics: Max Q: 0.4484 | Min Q: -1.0663 | Target Q: -0.1207 | Grad Norm (clipped): 0.1548 | Total train steps: 6629 | Step count: 6660\n",
            "Episode 900/100000 | Win: 19.00% | Draw: 1.00% | Loss: 80.00% | Epsilon: 0.6376 | Buffer: 7079/20000 (35.4%) | Train steps: 6 | Loss: 0.0041 | Avg Q: -0.1643 | TD Error: 0.0423 | Grad Norm: 0.1002\n",
            "  Detailed metrics: Max Q: 0.3651 | Min Q: -1.1293 | Target Q: -0.1581 | Grad Norm (clipped): 0.1002 | Total train steps: 7048 | Step count: 7079\n",
            "  Detailed metrics: Max Q: 0.5975 | Min Q: -1.0374 | Target Q: -0.1145 | Grad Norm (clipped): 0.1152 | Total train steps: 7457 | Step count: 7488\n",
            "Episode 1000/100000 | Win: 17.00% | Draw: 0.00% | Loss: 83.00% | Epsilon: 0.6065 | Buffer: 7919/20000 (39.6%) | Train steps: 8 | Loss: 0.0055 | Avg Q: -0.1662 | TD Error: 0.0452 | Grad Norm: 0.1212\n",
            "  Detailed metrics: Max Q: 0.4691 | Min Q: -1.1621 | Target Q: -0.1647 | Grad Norm (clipped): 0.1212 | Total train steps: 7888 | Step count: 7919\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251111_005147/dqn_episode_1000.pt\n",
            "  Added frozen opponent from episode 1000 to pool (total: 1)\n",
            "  Detailed metrics: Max Q: 0.3597 | Min Q: -1.0020 | Target Q: -0.1291 | Grad Norm (clipped): 0.1071 | Total train steps: 8303 | Step count: 8334\n",
            "Episode 1100/100000 | Win: 9.00% | Draw: 0.00% | Loss: 91.00% | Epsilon: 0.5769 | Buffer: 8755/20000 (43.8%) | Train steps: 9 | Loss: 0.0079 | Avg Q: -0.1386 | TD Error: 0.0436 | Grad Norm: 0.1055\n",
            "  Detailed metrics: Max Q: 0.2171 | Min Q: -0.9851 | Target Q: -0.1320 | Grad Norm (clipped): 0.1055 | Total train steps: 8724 | Step count: 8755\n",
            "  Detailed metrics: Max Q: 0.6921 | Min Q: -1.1266 | Target Q: -0.1394 | Grad Norm (clipped): 0.1482 | Total train steps: 9158 | Step count: 9189\n",
            "Episode 1200/100000 | Win: 12.00% | Draw: 3.00% | Loss: 85.00% | Epsilon: 0.5487 | Buffer: 9614/20000 (48.1%) | Train steps: 6 | Loss: 0.0066 | Avg Q: -0.1531 | TD Error: 0.0467 | Grad Norm: 0.1096\n",
            "  Detailed metrics: Max Q: 0.3281 | Min Q: -1.1324 | Target Q: -0.1539 | Grad Norm (clipped): 0.1096 | Total train steps: 9583 | Step count: 9614\n",
            "  Detailed metrics: Max Q: 0.9394 | Min Q: -1.1997 | Target Q: -0.1527 | Grad Norm (clipped): 0.1284 | Total train steps: 9996 | Step count: 10027\n",
            "Episode 1300/100000 | Win: 23.00% | Draw: 0.00% | Loss: 77.00% | Epsilon: 0.5220 | Buffer: 10442/20000 (52.2%) | Train steps: 5 | Loss: 0.0228 | Avg Q: -0.1454 | TD Error: 0.0718 | Grad Norm: 0.2098\n",
            "  Detailed metrics: Max Q: 0.2843 | Min Q: -1.0231 | Target Q: -0.1533 | Grad Norm (clipped): 0.2098 | Total train steps: 10411 | Step count: 10442\n",
            "  Detailed metrics: Max Q: 0.0746 | Min Q: -1.1161 | Target Q: -0.1558 | Grad Norm (clipped): 0.1621 | Total train steps: 10822 | Step count: 10853\n",
            "Episode 1400/100000 | Win: 20.00% | Draw: 2.00% | Loss: 78.00% | Epsilon: 0.4965 | Buffer: 11239/20000 (56.2%) | Train steps: 5 | Loss: 0.0034 | Avg Q: -0.1225 | TD Error: 0.0376 | Grad Norm: 0.1037\n",
            "  Detailed metrics: Max Q: 0.3312 | Min Q: -0.9501 | Target Q: -0.1148 | Grad Norm (clipped): 0.1037 | Total train steps: 11208 | Step count: 11239\n",
            "  Detailed metrics: Max Q: 0.3495 | Min Q: -1.0732 | Target Q: -0.1557 | Grad Norm (clipped): 0.1394 | Total train steps: 11601 | Step count: 11632\n",
            "Episode 1500/100000 | Win: 15.00% | Draw: 0.00% | Loss: 85.00% | Epsilon: 0.4723 | Buffer: 12082/20000 (60.4%) | Train steps: 9 | Loss: 0.0088 | Avg Q: -0.1221 | TD Error: 0.0478 | Grad Norm: 0.1233\n",
            "  Detailed metrics: Max Q: 0.3645 | Min Q: -1.0652 | Target Q: -0.1238 | Grad Norm (clipped): 0.1233 | Total train steps: 12051 | Step count: 12082\n",
            "  Detailed metrics: Max Q: 0.4679 | Min Q: -1.0354 | Target Q: -0.1141 | Grad Norm (clipped): 0.1066 | Total train steps: 12479 | Step count: 12510\n",
            "Episode 1600/100000 | Win: 21.00% | Draw: 1.00% | Loss: 78.00% | Epsilon: 0.4492 | Buffer: 12934/20000 (64.7%) | Train steps: 6 | Loss: 0.0080 | Avg Q: -0.1375 | TD Error: 0.0450 | Grad Norm: 0.1176\n",
            "  Detailed metrics: Max Q: 0.2501 | Min Q: -1.1091 | Target Q: -0.1456 | Grad Norm (clipped): 0.1176 | Total train steps: 12903 | Step count: 12934\n",
            "  Detailed metrics: Max Q: 0.6332 | Min Q: -1.0853 | Target Q: -0.1308 | Grad Norm (clipped): 0.1345 | Total train steps: 13364 | Step count: 13395\n",
            "Episode 1700/100000 | Win: 15.00% | Draw: 2.00% | Loss: 83.00% | Epsilon: 0.4273 | Buffer: 13878/20000 (69.4%) | Train steps: 10 | Loss: 0.0061 | Avg Q: -0.1300 | TD Error: 0.0473 | Grad Norm: 0.1258\n",
            "  Detailed metrics: Max Q: 0.3367 | Min Q: -1.0611 | Target Q: -0.1499 | Grad Norm (clipped): 0.1258 | Total train steps: 13847 | Step count: 13878\n",
            "  Detailed metrics: Max Q: 0.5013 | Min Q: -1.0767 | Target Q: -0.1381 | Grad Norm (clipped): 0.1125 | Total train steps: 14293 | Step count: 14324\n",
            "Episode 1800/100000 | Win: 19.00% | Draw: 0.00% | Loss: 81.00% | Epsilon: 0.4065 | Buffer: 14819/20000 (74.1%) | Train steps: 4 | Loss: 0.0041 | Avg Q: -0.1615 | TD Error: 0.0379 | Grad Norm: 0.0994\n",
            "  Detailed metrics: Max Q: 0.1207 | Min Q: -1.0888 | Target Q: -0.1704 | Grad Norm (clipped): 0.0994 | Total train steps: 14788 | Step count: 14819\n",
            "  Detailed metrics: Max Q: 0.4932 | Min Q: -1.0547 | Target Q: -0.1536 | Grad Norm (clipped): 0.1131 | Total train steps: 15180 | Step count: 15211\n",
            "Episode 1900/100000 | Win: 27.00% | Draw: 1.00% | Loss: 72.00% | Epsilon: 0.3866 | Buffer: 15665/20000 (78.3%) | Train steps: 8 | Loss: 0.0038 | Avg Q: -0.1294 | TD Error: 0.0385 | Grad Norm: 0.0930\n",
            "  Detailed metrics: Max Q: 0.3887 | Min Q: -1.0954 | Target Q: -0.1263 | Grad Norm (clipped): 0.0930 | Total train steps: 15634 | Step count: 15665\n",
            "  Detailed metrics: Max Q: 0.5958 | Min Q: -1.0626 | Target Q: -0.1422 | Grad Norm (clipped): 0.0900 | Total train steps: 16060 | Step count: 16091\n",
            "Episode 2000/100000 | Win: 26.00% | Draw: 1.00% | Loss: 73.00% | Epsilon: 0.3678 | Buffer: 16528/20000 (82.6%) | Train steps: 8 | Loss: 0.0040 | Avg Q: -0.1290 | TD Error: 0.0385 | Grad Norm: 0.0867\n",
            "  Detailed metrics: Max Q: 0.4686 | Min Q: -1.0363 | Target Q: -0.1387 | Grad Norm (clipped): 0.0867 | Total train steps: 16497 | Step count: 16528\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251111_005147/dqn_episode_2000.pt\n",
            "  Added frozen opponent from episode 2000 to pool (total: 2)\n",
            "  Detailed metrics: Max Q: 0.4425 | Min Q: -1.0329 | Target Q: -0.1268 | Grad Norm (clipped): 0.1015 | Total train steps: 16902 | Step count: 16933\n",
            "Episode 2100/100000 | Win: 21.00% | Draw: 0.00% | Loss: 79.00% | Epsilon: 0.3498 | Buffer: 17409/20000 (87.0%) | Train steps: 13 | Loss: 0.0093 | Avg Q: -0.1635 | TD Error: 0.0477 | Grad Norm: 0.1233\n",
            "  Detailed metrics: Max Q: 0.5482 | Min Q: -1.0524 | Target Q: -0.1643 | Grad Norm (clipped): 0.1233 | Total train steps: 17378 | Step count: 17409\n",
            "  Detailed metrics: Max Q: 0.6731 | Min Q: -0.9737 | Target Q: -0.1104 | Grad Norm (clipped): 0.1102 | Total train steps: 17845 | Step count: 17876\n",
            "Episode 2200/100000 | Win: 17.00% | Draw: 1.00% | Loss: 82.00% | Epsilon: 0.3328 | Buffer: 18307/20000 (91.5%) | Train steps: 3 | Loss: 0.0042 | Avg Q: -0.1238 | TD Error: 0.0437 | Grad Norm: 0.0984\n",
            "  Detailed metrics: Max Q: 0.4766 | Min Q: -1.0999 | Target Q: -0.1278 | Grad Norm (clipped): 0.0984 | Total train steps: 18276 | Step count: 18307\n",
            "  Detailed metrics: Max Q: 0.3470 | Min Q: -1.1182 | Target Q: -0.1601 | Grad Norm (clipped): 0.1391 | Total train steps: 18737 | Step count: 18768\n",
            "Episode 2300/100000 | Win: 30.00% | Draw: 0.00% | Loss: 70.00% | Epsilon: 0.3165 | Buffer: 19206/20000 (96.0%) | Train steps: 11 | Loss: 0.0064 | Avg Q: -0.1523 | TD Error: 0.0457 | Grad Norm: 0.1031\n",
            "  Detailed metrics: Max Q: 0.4625 | Min Q: -1.0409 | Target Q: -0.1555 | Grad Norm (clipped): 0.1031 | Total train steps: 19175 | Step count: 19206\n",
            "  Detailed metrics: Max Q: 0.2364 | Min Q: -1.0441 | Target Q: -0.1786 | Grad Norm (clipped): 0.0824 | Total train steps: 19643 | Step count: 19674\n",
            "Episode 2400/100000 | Win: 41.00% | Draw: 1.00% | Loss: 58.00% | Epsilon: 0.3011 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0187 | Avg Q: -0.1559 | TD Error: 0.0556 | Grad Norm: 0.1960\n",
            "  Detailed metrics: Max Q: 0.6617 | Min Q: -1.0706 | Target Q: -0.1457 | Grad Norm (clipped): 0.1960 | Total train steps: 20152 | Step count: 20183\n",
            "  Detailed metrics: Max Q: 0.3799 | Min Q: -1.0761 | Target Q: -0.1428 | Grad Norm (clipped): 0.1553 | Total train steps: 20617 | Step count: 20648\n",
            "Episode 2500/100000 | Win: 26.00% | Draw: 0.00% | Loss: 74.00% | Epsilon: 0.2864 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0051 | Avg Q: -0.1392 | TD Error: 0.0438 | Grad Norm: 0.1006\n",
            "  Detailed metrics: Max Q: 0.4147 | Min Q: -1.0862 | Target Q: -0.1451 | Grad Norm (clipped): 0.1006 | Total train steps: 21097 | Step count: 21128\n",
            "  Detailed metrics: Max Q: 0.3262 | Min Q: -1.0935 | Target Q: -0.1665 | Grad Norm (clipped): 0.0960 | Total train steps: 21562 | Step count: 21593\n",
            "Episode 2600/100000 | Win: 27.00% | Draw: 0.00% | Loss: 73.00% | Epsilon: 0.2724 | Buffer: 20000/20000 (100.0%) | Train steps: 6 | Loss: 0.0069 | Avg Q: -0.1810 | TD Error: 0.0457 | Grad Norm: 0.1209\n",
            "  Detailed metrics: Max Q: 0.3561 | Min Q: -1.0892 | Target Q: -0.1773 | Grad Norm (clipped): 0.1209 | Total train steps: 22044 | Step count: 22075\n",
            "  Detailed metrics: Max Q: 0.4729 | Min Q: -1.0509 | Target Q: -0.1504 | Grad Norm (clipped): 0.1418 | Total train steps: 22502 | Step count: 22533\n",
            "Episode 2700/100000 | Win: 25.00% | Draw: 0.00% | Loss: 75.00% | Epsilon: 0.2592 | Buffer: 20000/20000 (100.0%) | Train steps: 1 | Loss: 0.0020 | Avg Q: -0.1378 | TD Error: 0.0314 | Grad Norm: 0.0592\n",
            "  Detailed metrics: Max Q: 0.1188 | Min Q: -1.0987 | Target Q: -0.1467 | Grad Norm (clipped): 0.0592 | Total train steps: 22927 | Step count: 22958\n",
            "  Detailed metrics: Max Q: 0.7713 | Min Q: -0.9929 | Target Q: -0.1468 | Grad Norm (clipped): 0.1418 | Total train steps: 23374 | Step count: 23405\n",
            "Episode 2800/100000 | Win: 26.00% | Draw: 0.00% | Loss: 74.00% | Epsilon: 0.2465 | Buffer: 20000/20000 (100.0%) | Train steps: 10 | Loss: 0.0073 | Avg Q: -0.1779 | TD Error: 0.0472 | Grad Norm: 0.1226\n",
            "  Detailed metrics: Max Q: 0.2488 | Min Q: -1.0522 | Target Q: -0.1700 | Grad Norm (clipped): 0.1226 | Total train steps: 23827 | Step count: 23858\n",
            "  Detailed metrics: Max Q: 0.8470 | Min Q: -0.9361 | Target Q: -0.0832 | Grad Norm (clipped): 0.1976 | Total train steps: 24320 | Step count: 24351\n",
            "Episode 2900/100000 | Win: 30.00% | Draw: 0.00% | Loss: 70.00% | Epsilon: 0.2345 | Buffer: 20000/20000 (100.0%) | Train steps: 10 | Loss: 0.0125 | Avg Q: -0.1516 | TD Error: 0.0447 | Grad Norm: 0.1352\n",
            "  Detailed metrics: Max Q: 0.2620 | Min Q: -0.9783 | Target Q: -0.1545 | Grad Norm (clipped): 0.1352 | Total train steps: 24825 | Step count: 24856\n",
            "  Detailed metrics: Max Q: 0.2274 | Min Q: -1.0691 | Target Q: -0.1809 | Grad Norm (clipped): 0.0940 | Total train steps: 25343 | Step count: 25374\n",
            "Episode 3000/100000 | Win: 29.00% | Draw: 1.00% | Loss: 70.00% | Epsilon: 0.2230 | Buffer: 20000/20000 (100.0%) | Train steps: 21 | Loss: 0.0069 | Avg Q: -0.1521 | TD Error: 0.0470 | Grad Norm: 0.1155\n",
            "  Detailed metrics: Max Q: 0.5385 | Min Q: -0.9897 | Target Q: -0.1513 | Grad Norm (clipped): 0.1155 | Total train steps: 25879 | Step count: 25910\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251111_005147/dqn_episode_3000.pt\n",
            "  Added frozen opponent from episode 3000 to pool (total: 3)\n",
            "  Detailed metrics: Max Q: 0.4464 | Min Q: -0.9635 | Target Q: -0.1188 | Grad Norm (clipped): 0.1587 | Total train steps: 26325 | Step count: 26356\n",
            "Episode 3100/100000 | Win: 34.00% | Draw: 1.00% | Loss: 65.00% | Epsilon: 0.2122 | Buffer: 20000/20000 (100.0%) | Train steps: 11 | Loss: 0.0054 | Avg Q: -0.1517 | TD Error: 0.0469 | Grad Norm: 0.1038\n",
            "  Detailed metrics: Max Q: 0.5985 | Min Q: -1.0011 | Target Q: -0.1467 | Grad Norm (clipped): 0.1038 | Total train steps: 26826 | Step count: 26857\n",
            "  Detailed metrics: Max Q: 0.7780 | Min Q: -1.1005 | Target Q: -0.1344 | Grad Norm (clipped): 0.1453 | Total train steps: 27293 | Step count: 27324\n",
            "Episode 3200/100000 | Win: 37.00% | Draw: 2.00% | Loss: 61.00% | Epsilon: 0.2018 | Buffer: 20000/20000 (100.0%) | Train steps: 13 | Loss: 0.0114 | Avg Q: -0.1524 | TD Error: 0.0528 | Grad Norm: 0.1280\n",
            "  Detailed metrics: Max Q: 0.3939 | Min Q: -1.0700 | Target Q: -0.1594 | Grad Norm (clipped): 0.1280 | Total train steps: 27791 | Step count: 27822\n",
            "  Detailed metrics: Max Q: 0.6605 | Min Q: -0.9608 | Target Q: -0.1214 | Grad Norm (clipped): 0.1156 | Total train steps: 28285 | Step count: 28316\n",
            "Episode 3300/100000 | Win: 44.00% | Draw: 0.00% | Loss: 56.00% | Epsilon: 0.1920 | Buffer: 20000/20000 (100.0%) | Train steps: 6 | Loss: 0.0058 | Avg Q: -0.1727 | TD Error: 0.0492 | Grad Norm: 0.1590\n",
            "  Detailed metrics: Max Q: 0.3583 | Min Q: -1.0754 | Target Q: -0.1549 | Grad Norm (clipped): 0.1590 | Total train steps: 28787 | Step count: 28818\n",
            "  Detailed metrics: Max Q: 0.5933 | Min Q: -0.9647 | Target Q: -0.1373 | Grad Norm (clipped): 0.1288 | Total train steps: 29226 | Step count: 29257\n",
            "Episode 3400/100000 | Win: 24.00% | Draw: 2.00% | Loss: 74.00% | Epsilon: 0.1826 | Buffer: 20000/20000 (100.0%) | Train steps: 12 | Loss: 0.0071 | Avg Q: -0.1279 | TD Error: 0.0439 | Grad Norm: 0.1219\n",
            "  Detailed metrics: Max Q: 0.7738 | Min Q: -0.9819 | Target Q: -0.1344 | Grad Norm (clipped): 0.1219 | Total train steps: 29679 | Step count: 29710\n",
            "  Detailed metrics: Max Q: 0.6596 | Min Q: -1.0639 | Target Q: -0.1484 | Grad Norm (clipped): 0.1069 | Total train steps: 30144 | Step count: 30175\n",
            "Episode 3500/100000 | Win: 43.00% | Draw: 0.00% | Loss: 57.00% | Epsilon: 0.1737 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0123 | Avg Q: -0.1274 | TD Error: 0.0496 | Grad Norm: 0.1318\n",
            "  Detailed metrics: Max Q: 0.5670 | Min Q: -0.9901 | Target Q: -0.1196 | Grad Norm (clipped): 0.1318 | Total train steps: 30650 | Step count: 30681\n",
            "  Detailed metrics: Max Q: 0.6925 | Min Q: -0.9652 | Target Q: -0.1329 | Grad Norm (clipped): 0.1463 | Total train steps: 31103 | Step count: 31134\n",
            "Episode 3600/100000 | Win: 46.00% | Draw: 0.00% | Loss: 54.00% | Epsilon: 0.1652 | Buffer: 20000/20000 (100.0%) | Train steps: 18 | Loss: 0.0060 | Avg Q: -0.1474 | TD Error: 0.0460 | Grad Norm: 0.1123\n",
            "  Detailed metrics: Max Q: 0.5474 | Min Q: -0.9476 | Target Q: -0.1480 | Grad Norm (clipped): 0.1123 | Total train steps: 31586 | Step count: 31617\n",
            "  Detailed metrics: Max Q: 0.6307 | Min Q: -0.9474 | Target Q: -0.1228 | Grad Norm (clipped): 0.0980 | Total train steps: 32098 | Step count: 32129\n",
            "Episode 3700/100000 | Win: 28.00% | Draw: 5.00% | Loss: 67.00% | Epsilon: 0.1572 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0064 | Avg Q: -0.1915 | TD Error: 0.0514 | Grad Norm: 0.1199\n",
            "  Detailed metrics: Max Q: 0.4550 | Min Q: -0.9910 | Target Q: -0.1852 | Grad Norm (clipped): 0.1199 | Total train steps: 32616 | Step count: 32647\n",
            "  Detailed metrics: Max Q: 0.6911 | Min Q: -1.0652 | Target Q: -0.1430 | Grad Norm (clipped): 0.1414 | Total train steps: 33160 | Step count: 33191\n",
            "Episode 3800/100000 | Win: 35.00% | Draw: 1.00% | Loss: 64.00% | Epsilon: 0.1495 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0065 | Avg Q: -0.1520 | TD Error: 0.0476 | Grad Norm: 0.1224\n",
            "  Detailed metrics: Max Q: 0.6942 | Min Q: -1.0429 | Target Q: -0.1566 | Grad Norm (clipped): 0.1224 | Total train steps: 33674 | Step count: 33705\n",
            "  Detailed metrics: Max Q: 0.3764 | Min Q: -1.0026 | Target Q: -0.1661 | Grad Norm (clipped): 0.1389 | Total train steps: 34112 | Step count: 34143\n",
            "Episode 3900/100000 | Win: 37.00% | Draw: 1.00% | Loss: 62.00% | Epsilon: 0.1422 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0050 | Avg Q: -0.1282 | TD Error: 0.0492 | Grad Norm: 0.1084\n",
            "  Detailed metrics: Max Q: 0.7949 | Min Q: -0.9732 | Target Q: -0.1318 | Grad Norm (clipped): 0.1084 | Total train steps: 34597 | Step count: 34628\n",
            "  Detailed metrics: Max Q: 0.6571 | Min Q: -0.8208 | Target Q: -0.0970 | Grad Norm (clipped): 0.1542 | Total train steps: 35120 | Step count: 35151\n",
            "Episode 4000/100000 | Win: 46.00% | Draw: 1.00% | Loss: 53.00% | Epsilon: 0.1353 | Buffer: 20000/20000 (100.0%) | Train steps: 4 | Loss: 0.0039 | Avg Q: -0.1144 | TD Error: 0.0441 | Grad Norm: 0.0914\n",
            "  Detailed metrics: Max Q: 0.8007 | Min Q: -1.0419 | Target Q: -0.1192 | Grad Norm (clipped): 0.0914 | Total train steps: 35612 | Step count: 35643\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251111_005147/dqn_episode_4000.pt\n",
            "  Added frozen opponent from episode 4000 to pool (total: 4)\n",
            "  Detailed metrics: Max Q: 0.8031 | Min Q: -0.9808 | Target Q: -0.1292 | Grad Norm (clipped): 0.1516 | Total train steps: 36123 | Step count: 36154\n",
            "Episode 4100/100000 | Win: 38.00% | Draw: 13.00% | Loss: 49.00% | Epsilon: 0.1287 | Buffer: 20000/20000 (100.0%) | Train steps: 16 | Loss: 0.0086 | Avg Q: -0.1488 | TD Error: 0.0501 | Grad Norm: 0.1231\n",
            "  Detailed metrics: Max Q: 0.6486 | Min Q: -1.0154 | Target Q: -0.1505 | Grad Norm (clipped): 0.1231 | Total train steps: 36610 | Step count: 36641\n",
            "  Detailed metrics: Max Q: 0.8307 | Min Q: -0.9711 | Target Q: -0.1286 | Grad Norm (clipped): 0.1117 | Total train steps: 37118 | Step count: 37149\n",
            "Episode 4200/100000 | Win: 39.00% | Draw: 0.00% | Loss: 61.00% | Epsilon: 0.1224 | Buffer: 20000/20000 (100.0%) | Train steps: 6 | Loss: 0.0051 | Avg Q: -0.1180 | TD Error: 0.0450 | Grad Norm: 0.1022\n",
            "  Detailed metrics: Max Q: 1.0044 | Min Q: -1.0321 | Target Q: -0.1241 | Grad Norm (clipped): 0.1022 | Total train steps: 37613 | Step count: 37644\n",
            "  Detailed metrics: Max Q: 0.7597 | Min Q: -0.9796 | Target Q: -0.1363 | Grad Norm (clipped): 0.1128 | Total train steps: 38024 | Step count: 38055\n",
            "Episode 4300/100000 | Win: 47.00% | Draw: 1.00% | Loss: 52.00% | Epsilon: 0.1164 | Buffer: 20000/20000 (100.0%) | Train steps: 14 | Loss: 0.0048 | Avg Q: -0.1766 | TD Error: 0.0461 | Grad Norm: 0.1079\n",
            "  Detailed metrics: Max Q: 0.6460 | Min Q: -1.0341 | Target Q: -0.1829 | Grad Norm (clipped): 0.1079 | Total train steps: 38488 | Step count: 38519\n",
            "  Detailed metrics: Max Q: 0.5833 | Min Q: -1.0474 | Target Q: -0.1558 | Grad Norm (clipped): 0.1270 | Total train steps: 38948 | Step count: 38979\n",
            "Episode 4400/100000 | Win: 39.00% | Draw: 0.00% | Loss: 61.00% | Epsilon: 0.1107 | Buffer: 20000/20000 (100.0%) | Train steps: 14 | Loss: 0.0058 | Avg Q: -0.1460 | TD Error: 0.0471 | Grad Norm: 0.1058\n",
            "  Detailed metrics: Max Q: 0.8343 | Min Q: -1.0434 | Target Q: -0.1486 | Grad Norm (clipped): 0.1058 | Total train steps: 39424 | Step count: 39455\n",
            "  Detailed metrics: Max Q: 0.8254 | Min Q: -0.9158 | Target Q: -0.1152 | Grad Norm (clipped): 0.1330 | Total train steps: 39905 | Step count: 39936\n",
            "Episode 4500/100000 | Win: 41.00% | Draw: 2.00% | Loss: 57.00% | Epsilon: 0.1053 | Buffer: 20000/20000 (100.0%) | Train steps: 8 | Loss: 0.0052 | Avg Q: -0.2238 | TD Error: 0.0487 | Grad Norm: 0.1059\n",
            "  Detailed metrics: Max Q: 0.4475 | Min Q: -1.0621 | Target Q: -0.2135 | Grad Norm (clipped): 0.1059 | Total train steps: 40382 | Step count: 40413\n",
            "  Detailed metrics: Max Q: 0.7727 | Min Q: -0.9374 | Target Q: -0.1269 | Grad Norm (clipped): 0.1250 | Total train steps: 40883 | Step count: 40914\n",
            "Episode 4600/100000 | Win: 49.00% | Draw: 0.00% | Loss: 51.00% | Epsilon: 0.1002 | Buffer: 20000/20000 (100.0%) | Train steps: 5 | Loss: 0.0061 | Avg Q: -0.1296 | TD Error: 0.0514 | Grad Norm: 0.1360\n",
            "  Detailed metrics: Max Q: 0.9162 | Min Q: -1.0225 | Target Q: -0.1403 | Grad Norm (clipped): 0.1360 | Total train steps: 41359 | Step count: 41390\n",
            "  Detailed metrics: Max Q: 0.6625 | Min Q: -0.9937 | Target Q: -0.1642 | Grad Norm (clipped): 0.1606 | Total train steps: 41846 | Step count: 41877\n",
            "Episode 4700/100000 | Win: 64.00% | Draw: 1.00% | Loss: 35.00% | Epsilon: 0.0953 | Buffer: 20000/20000 (100.0%) | Train steps: 3 | Loss: 0.0058 | Avg Q: -0.1811 | TD Error: 0.0513 | Grad Norm: 0.1083\n",
            "  Detailed metrics: Max Q: 0.8792 | Min Q: -1.1025 | Target Q: -0.1760 | Grad Norm (clipped): 0.1083 | Total train steps: 42316 | Step count: 42347\n",
            "  Detailed metrics: Max Q: 0.9282 | Min Q: -0.9948 | Target Q: -0.1264 | Grad Norm (clipped): 0.0970 | Total train steps: 42761 | Step count: 42792\n",
            "Episode 4800/100000 | Win: 43.00% | Draw: 2.00% | Loss: 55.00% | Epsilon: 0.0907 | Buffer: 20000/20000 (100.0%) | Train steps: 1 | Loss: 0.0035 | Avg Q: -0.2423 | TD Error: 0.0446 | Grad Norm: 0.0728\n",
            "  Detailed metrics: Max Q: 0.1538 | Min Q: -1.0984 | Target Q: -0.2435 | Grad Norm (clipped): 0.0728 | Total train steps: 43238 | Step count: 43269\n",
            "  Detailed metrics: Max Q: 0.5718 | Min Q: -0.9804 | Target Q: -0.1401 | Grad Norm (clipped): 0.1362 | Total train steps: 43717 | Step count: 43748\n",
            "Episode 4900/100000 | Win: 55.00% | Draw: 2.00% | Loss: 43.00% | Epsilon: 0.0862 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0064 | Avg Q: -0.1322 | TD Error: 0.0507 | Grad Norm: 0.1251\n",
            "  Detailed metrics: Max Q: 0.8173 | Min Q: -1.0218 | Target Q: -0.1230 | Grad Norm (clipped): 0.1251 | Total train steps: 44160 | Step count: 44191\n",
            "  Detailed metrics: Max Q: 0.8136 | Min Q: -0.9760 | Target Q: -0.1101 | Grad Norm (clipped): 0.1275 | Total train steps: 44613 | Step count: 44644\n",
            "Episode 5000/100000 | Win: 43.00% | Draw: 0.00% | Loss: 57.00% | Epsilon: 0.0820 | Buffer: 20000/20000 (100.0%) | Train steps: 12 | Loss: 0.0054 | Avg Q: -0.1594 | TD Error: 0.0481 | Grad Norm: 0.1084\n",
            "  Detailed metrics: Max Q: 0.8292 | Min Q: -0.9853 | Target Q: -0.1614 | Grad Norm (clipped): 0.1084 | Total train steps: 45067 | Step count: 45098\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251111_005147/dqn_episode_5000.pt\n",
            "  Added frozen opponent from episode 5000 to pool (total: 5)\n",
            "  Detailed metrics: Max Q: 0.8265 | Min Q: -0.9753 | Target Q: -0.1170 | Grad Norm (clipped): 0.1407 | Total train steps: 45528 | Step count: 45559\n",
            "Episode 5100/100000 | Win: 37.00% | Draw: 1.00% | Loss: 62.00% | Epsilon: 0.0780 | Buffer: 20000/20000 (100.0%) | Train steps: 6 | Loss: 0.0095 | Avg Q: -0.1462 | TD Error: 0.0574 | Grad Norm: 0.1419\n",
            "  Detailed metrics: Max Q: 0.6633 | Min Q: -0.9830 | Target Q: -0.1491 | Grad Norm (clipped): 0.1419 | Total train steps: 45974 | Step count: 46005\n",
            "  Detailed metrics: Max Q: 0.9583 | Min Q: -0.9889 | Target Q: -0.1168 | Grad Norm (clipped): 0.1548 | Total train steps: 46465 | Step count: 46496\n",
            "Episode 5200/100000 | Win: 48.00% | Draw: 2.00% | Loss: 50.00% | Epsilon: 0.0742 | Buffer: 20000/20000 (100.0%) | Train steps: 7 | Loss: 0.0071 | Avg Q: -0.1367 | TD Error: 0.0546 | Grad Norm: 0.1306\n",
            "  Detailed metrics: Max Q: 0.8572 | Min Q: -0.8888 | Target Q: -0.1285 | Grad Norm (clipped): 0.1306 | Total train steps: 46923 | Step count: 46954\n",
            "  Detailed metrics: Max Q: 0.6553 | Min Q: -1.0890 | Target Q: -0.1643 | Grad Norm (clipped): 0.1740 | Total train steps: 47437 | Step count: 47468\n",
            "Episode 5300/100000 | Win: 43.00% | Draw: 1.00% | Loss: 56.00% | Epsilon: 0.0706 | Buffer: 20000/20000 (100.0%) | Train steps: 21 | Loss: 0.0097 | Avg Q: -0.1475 | TD Error: 0.0515 | Grad Norm: 0.1445\n",
            "  Detailed metrics: Max Q: 0.8254 | Min Q: -1.0007 | Target Q: -0.1475 | Grad Norm (clipped): 0.1445 | Total train steps: 47952 | Step count: 47983\n",
            "  Detailed metrics: Max Q: 0.8533 | Min Q: -0.9893 | Target Q: -0.1345 | Grad Norm (clipped): 0.1526 | Total train steps: 48424 | Step count: 48455\n",
            "Episode 5400/100000 | Win: 37.00% | Draw: 0.00% | Loss: 63.00% | Epsilon: 0.0672 | Buffer: 20000/20000 (100.0%) | Train steps: 9 | Loss: 0.0047 | Avg Q: -0.0820 | TD Error: 0.0470 | Grad Norm: 0.0952\n",
            "  Detailed metrics: Max Q: 0.8816 | Min Q: -0.8874 | Target Q: -0.0819 | Grad Norm (clipped): 0.0952 | Total train steps: 48913 | Step count: 48944\n",
            "  Detailed metrics: Max Q: 1.0070 | Min Q: -1.0828 | Target Q: -0.1114 | Grad Norm (clipped): 0.1763 | Total train steps: 49390 | Step count: 49421\n",
            "Episode 5500/100000 | Win: 54.00% | Draw: 3.00% | Loss: 43.00% | Epsilon: 0.0639 | Buffer: 20000/20000 (100.0%) | Train steps: 16 | Loss: 0.0079 | Avg Q: -0.1277 | TD Error: 0.0576 | Grad Norm: 0.1293\n",
            "  Detailed metrics: Max Q: 0.9544 | Min Q: -0.9013 | Target Q: -0.1287 | Grad Norm (clipped): 0.1293 | Total train steps: 49794 | Step count: 49825\n",
            "  Detailed metrics: Max Q: 0.6597 | Min Q: -0.8615 | Target Q: -0.1483 | Grad Norm (clipped): 0.0671 | Total train steps: 50263 | Step count: 50294\n",
            "Episode 5600/100000 | Win: 55.00% | Draw: 2.00% | Loss: 43.00% | Epsilon: 0.0608 | Buffer: 20000/20000 (100.0%) | Train steps: 5 | Loss: 0.0091 | Avg Q: -0.1365 | TD Error: 0.0537 | Grad Norm: 0.1728\n",
            "  Detailed metrics: Max Q: 0.9549 | Min Q: -0.9903 | Target Q: -0.1374 | Grad Norm (clipped): 0.1728 | Total train steps: 50764 | Step count: 50795\n"
          ]
        }
      ],
      "source": [
        "# –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è\n",
        "from datetime import datetime\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_type = TRAINING_CONFIG['model_type']\n",
        "run_id = f\"{model_type}_{timestamp}\"\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º –ø–æ–¥–ø–∞–ø–∫–∏ –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ (–≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö —è—á–µ–π–∫–∞—Ö)\n",
        "run_checkpoint_dir = os.path.join(TRAINING_CONFIG['checkpoint_dir'], run_id)\n",
        "run_log_dir = os.path.join(TRAINING_CONFIG['log_dir'], run_id)\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏\n",
        "os.makedirs(run_checkpoint_dir, exist_ok=True)\n",
        "os.makedirs(run_log_dir, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø–∞–ø–∫–∞ –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è:\")\n",
        "print(f\"   Checkpoints: {run_checkpoint_dir}\")\n",
        "print(f\"   Logs: {run_log_dir}\")\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ\n",
        "training_complete = threading.Event()\n",
        "stop_training_flag = threading.Event()  # –§–ª–∞–≥ –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—É—á–µ–Ω–∏—è\n",
        "training_thread = None\n",
        "current_metrics_file = None  # –ü—É—Ç—å –∫ —Ç–µ–∫—É—â–µ–º—É —Ñ–∞–π–ª—É –º–µ—Ç—Ä–∏–∫\n",
        "\n",
        "def run_training():\n",
        "    \"\"\"–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ.\"\"\"\n",
        "    global current_metrics_file\n",
        "    try:\n",
        "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–µ—Ç—Ä–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω\n",
        "        # MetricsLogger —Å–æ–∑–¥–∞–µ—Ç —Ñ–∞–π–ª —Å timestamp –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏\n",
        "        current_metrics_file = os.path.join(run_log_dir, f\"metrics_{timestamp}.csv\")\n",
        "        if TRAINING_CONFIG['model_type'] == 'dqn':\n",
        "            train_dqn(\n",
        "                num_episodes=TRAINING_CONFIG['num_episodes'],\n",
        "                learning_rate=TRAINING_CONFIG['learning_rate'],\n",
        "                discount_factor=TRAINING_CONFIG['discount_factor'],\n",
        "                epsilon=TRAINING_CONFIG['epsilon'],\n",
        "                epsilon_decay=TRAINING_CONFIG['epsilon_decay'],\n",
        "                epsilon_min=TRAINING_CONFIG['epsilon_min'],\n",
        "                batch_size=TRAINING_CONFIG['batch_size'],\n",
        "                replay_buffer_size=TRAINING_CONFIG['replay_buffer_size'],\n",
        "                target_update_freq=TRAINING_CONFIG['target_update_freq'],\n",
        "                soft_update=TRAINING_CONFIG['soft_update'],\n",
        "                tau=TRAINING_CONFIG['tau'],\n",
        "                eval_freq=TRAINING_CONFIG['eval_freq'],\n",
        "                eval_episodes=TRAINING_CONFIG['eval_episodes'],\n",
        "                save_freq=TRAINING_CONFIG['save_freq'],\n",
        "                checkpoint_dir=run_checkpoint_dir,\n",
        "                log_dir=run_log_dir,\n",
        "                device=TRAINING_CONFIG['device'],\n",
        "                seed=TRAINING_CONFIG['seed'],\n",
        "                stop_flag=stop_training_flag,\n",
        "                reward_config=REWARD_CONFIG,\n",
        "                heuristic_distribution=HEURISTIC_DISTRIBUTION,\n",
        "                self_play_config=SELF_PLAY_CONFIG,\n",
        "                network_type=TRAINING_CONFIG['network_type'],\n",
        "                random_opening_config=RANDOM_OPENING_CONFIG,\n",
        "            )\n",
        "        elif TRAINING_CONFIG['model_type'] == 'qlearning':\n",
        "            train_qlearning(\n",
        "                num_episodes=TRAINING_CONFIG['num_episodes'],\n",
        "                learning_rate=TRAINING_CONFIG['learning_rate'],\n",
        "                discount_factor=TRAINING_CONFIG['discount_factor'],\n",
        "                epsilon=TRAINING_CONFIG['epsilon'],\n",
        "                epsilon_decay=TRAINING_CONFIG['epsilon_decay'],\n",
        "                epsilon_min=TRAINING_CONFIG['epsilon_min'],\n",
        "                eval_freq=TRAINING_CONFIG['eval_freq'],\n",
        "                eval_episodes=TRAINING_CONFIG['eval_episodes'],\n",
        "                save_freq=TRAINING_CONFIG['save_freq'],\n",
        "                checkpoint_dir=run_checkpoint_dir,\n",
        "                log_dir=run_log_dir,\n",
        "                seed=TRAINING_CONFIG['seed'],\n",
        "                stop_flag=stop_training_flag,\n",
        "                reward_config=REWARD_CONFIG,\n",
        "                random_opening_config=RANDOM_OPENING_CONFIG,\n",
        "            )\n",
        "    except Exception as e:\n",
        "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        training_complete.set()\n",
        "\n",
        "# –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\n",
        "print(\"–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...\")\n",
        "training_thread = threading.Thread(target=run_training, daemon=True)\n",
        "training_thread.start()\n",
        "\n",
        "print(\"–û–±—É—á–µ–Ω–∏–µ –∑–∞–ø—É—â–µ–Ω–æ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ!\")\n",
        "print(\"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é —è—á–µ–π–∫—É –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "**–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ–±—É—á–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω–æ –∑–∞–ø—É—â–µ–Ω–æ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üõë –°–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –æ–±—É—á–µ–Ω–∏—é!\n",
            "–û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ —ç–ø–∏–∑–æ–¥–∞.\n",
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üõë –û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –Ω–∞ —ç–ø–∏–∑–æ–¥–µ 16060/100000\n",
            "Checkpoint saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_episode_16060_stopped.pt\n",
            "  Added final frozen opponent to pool (total: 17)\n",
            "\n",
            "Training stopped. Final model saved: /home/holidin/projects/RL/data/checkpoints/dqn_20251110_220602/dqn_final.pt\n"
          ]
        }
      ],
      "source": [
        "# –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–±—É—á–µ–Ω–∏—è\n",
        "if 'stop_training_flag' in globals() and stop_training_flag is not None:\n",
        "    stop_training_flag.set()\n",
        "    print(\"üõë –°–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –æ–±—É—á–µ–Ω–∏—é!\")\n",
        "    print(\"–û–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ —ç–ø–∏–∑–æ–¥–∞.\")\n",
        "    print(\"–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  –û–±—É—á–µ–Ω–∏–µ –Ω–µ –∑–∞–ø—É—â–µ–Ω–æ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.\")\n",
        "    print(\"–ï—Å–ª–∏ –æ–±—É—á–µ–Ω–∏–µ –≤—Å–µ –µ—â–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ:\")\n",
        "    print(\"1. –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —è–¥—Ä–æ –Ω–æ—É—Ç–±—É–∫–∞ (Kernel -> Restart)\")\n",
        "    print(\"2. –ò–ª–∏ –Ω–∞–π—Ç–∏ –ø—Ä–æ—Ü–µ—Å—Å Python –∏ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –µ–≥–æ –≤—Ä—É—á–Ω—É—é:\")\n",
        "    print(\"   ps aux | grep train_dqn\")\n",
        "    print(\"   kill <PID>\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏\n",
        "\n",
        "–ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤. –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –º–Ω–æ–≥–æ–∫—Ä–∞—Ç–Ω–æ.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω)\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º run_log_dir, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω, –∏–Ω–∞—á–µ fallback –Ω–∞ TRAINING_CONFIG['log_dir']\n",
        "log_dir_to_use = run_log_dir if 'run_log_dir' in globals() else TRAINING_CONFIG['log_dir']\n",
        "\n",
        "if 'current_metrics_file' in globals() and current_metrics_file and Path(current_metrics_file).exists():\n",
        "    df = load_metrics_from_csv(log_dir_to_use, metrics_file=current_metrics_file)\n",
        "    print(f\"üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∞–π–ª: {Path(current_metrics_file).name}\")\n",
        "else:\n",
        "    df = load_metrics_from_csv(log_dir_to_use)\n",
        "    if not df.empty:\n",
        "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, –∫–∞–∫–æ–π —Ñ–∞–π–ª –±—ã–ª –∑–∞–≥—Ä—É–∂–µ–Ω\n",
        "        csv_files = list(Path(log_dir_to_use).glob(\"metrics_*.csv\"))\n",
        "        if csv_files:\n",
        "            latest_file = max(csv_files, key=lambda x: x.stat().st_ctime)\n",
        "            print(f\"üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–∞–π–ª: {latest_file.name}\")\n",
        "\n",
        "if not df.empty:\n",
        "    print(f\"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –º–µ—Ç—Ä–∏–∫\")\n",
        "    print(f\"–ü–æ—Å–ª–µ–¥–Ω–∏–π —ç–ø–∏–∑–æ–¥: {df['step'].max()}\")\n",
        "    print(f\"\\n–ü–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏:\")\n",
        "    print(df.tail(1)[['step'] + [m for m in PLOT_CONFIG['metrics_to_plot'] if m in df.columns]].to_string())\n",
        "    print()\n",
        "    \n",
        "    # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏\n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    # –ì—Ä–∞—Ñ–∏–∫ win/draw/loss rates\n",
        "    plot_win_rate_comparison(df)\n",
        "    \n",
        "    # –ì—Ä–∞—Ñ–∏–∫–∏ –¥—Ä—É–≥–∏—Ö –º–µ—Ç—Ä–∏–∫\n",
        "    plot_metrics(df, PLOT_CONFIG['metrics_to_plot'])\n",
        "    \n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≤–µ—Ä—à–µ–Ω–æ –ª–∏ –æ–±—É—á–µ–Ω–∏–µ\n",
        "    if training_complete.is_set():\n",
        "        print(\"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\")\n",
        "    else:\n",
        "        print(f\"‚è≥ –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è... (—ç–ø–∏–∑–æ–¥ {df['step'].max()}/{TRAINING_CONFIG['num_episodes']})\")\n",
        "else:\n",
        "    print(\"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö... –û–±—É—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –Ω–∞—á–∞–ª–æ—Å—å.\")\n",
        "    if training_complete.is_set():\n",
        "        print(\"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –Ω–æ –º–µ—Ç—Ä–∏–∫–∏ –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)\n",
        "\n",
        "–ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∫–∞–∂–¥—ã–µ N —Å–µ–∫—É–Ω–¥.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "UPDATE_INTERVAL = 10  # –û–±–Ω–æ–≤–ª—è—Ç—å –∫–∞–∂–¥—ã–µ N —Å–µ–∫—É–Ω–¥\n",
        "MAX_UPDATES = 1000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π\n",
        "\n",
        "print(f\"–ù–∞—á–∏–Ω–∞—é –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∫–∞–∂–¥—ã–µ {UPDATE_INTERVAL} —Å–µ–∫—É–Ω–¥...\")\n",
        "print(\"–ù–∞–∂–º–∏—Ç–µ Interrupt (Ctrl+C) —á—Ç–æ–±—ã –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å\")\n",
        "\n",
        "for update_count in range(MAX_UPDATES):\n",
        "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω)\n",
        "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º run_log_dir, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω, –∏–Ω–∞—á–µ fallback –Ω–∞ TRAINING_CONFIG['log_dir']\n",
        "    log_dir_to_use = run_log_dir if 'run_log_dir' in globals() else TRAINING_CONFIG['log_dir']\n",
        "    \n",
        "    if 'current_metrics_file' in globals() and current_metrics_file and Path(current_metrics_file).exists():\n",
        "        df = load_metrics_from_csv(log_dir_to_use, metrics_file=current_metrics_file)\n",
        "    else:\n",
        "        df = load_metrics_from_csv(log_dir_to_use)\n",
        "    \n",
        "    if not df.empty:\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        print(f\"–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ #{update_count + 1} | –≠–ø–∏–∑–æ–¥: {df['step'].max()}/{TRAINING_CONFIG['num_episodes']}\")\n",
        "        \n",
        "        # –ì—Ä–∞—Ñ–∏–∫ win/draw/loss rates\n",
        "        plot_win_rate_comparison(df)\n",
        "        \n",
        "        # –ì—Ä–∞—Ñ–∏–∫–∏ –¥—Ä—É–≥–∏—Ö –º–µ—Ç—Ä–∏–∫\n",
        "        plot_metrics(df, PLOT_CONFIG['metrics_to_plot'])\n",
        "        \n",
        "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≤–µ—Ä—à–µ–Ω–æ –ª–∏ –æ–±—É—á–µ–Ω–∏–µ\n",
        "        if training_complete.is_set():\n",
        "            print(\"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\")\n",
        "            break\n",
        "        \n",
        "        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏\n",
        "        if len(df) > 0:\n",
        "            last_row = df.iloc[-1]\n",
        "            print(f\"\\n–ü–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ (—ç–ø–∏–∑–æ–¥ {last_row['step']}):\")\n",
        "            for metric in PLOT_CONFIG['metrics_to_plot']:\n",
        "                if metric in last_row:\n",
        "                    print(f\"  {metric}: {last_row[metric]:.4f}\")\n",
        "    else:\n",
        "        print(f\"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö... ({update_count + 1}/{MAX_UPDATES})\")\n",
        "    \n",
        "    # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º\n",
        "    time.sleep(UPDATE_INTERVAL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è\n",
        "\n",
        "–ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –≥—Ä–∞—Ñ–∏–∫–æ–≤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –§–∏–Ω–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω)\n",
        "# –ò—Å–ø–æ–ª—å–∑—É–µ–º run_log_dir, –µ—Å–ª–∏ –æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω, –∏–Ω–∞—á–µ fallback –Ω–∞ TRAINING_CONFIG['log_dir']\n",
        "log_dir_to_use = run_log_dir if 'run_log_dir' in globals() else TRAINING_CONFIG['log_dir']\n",
        "\n",
        "if 'current_metrics_file' in globals() and current_metrics_file and Path(current_metrics_file).exists():\n",
        "    df = load_metrics_from_csv(log_dir_to_use, metrics_file=current_metrics_file)\n",
        "else:\n",
        "    df = load_metrics_from_csv(log_dir_to_use)\n",
        "\n",
        "if not df.empty:\n",
        "    print(\"=\" * 80)\n",
        "    print(\"–§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"–í—Å–µ–≥–æ —ç–ø–∏–∑–æ–¥–æ–≤: {len(df)}\")\n",
        "    print(f\"–ü–æ—Å–ª–µ–¥–Ω–∏–π —ç–ø–∏–∑–æ–¥: {df['step'].max()}\")\n",
        "    print()\n",
        "    \n",
        "    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
        "    if 'win_rate' in df.columns:\n",
        "        print(\"Win Rate:\")\n",
        "        print(f\"  –°—Ä–µ–¥–Ω–µ–µ: {df['win_rate'].mean():.2%}\")\n",
        "        print(f\"  –ü–æ—Å–ª–µ–¥–Ω–µ–µ: {df['win_rate'].iloc[-1]:.2%}\")\n",
        "        print(f\"  –ú–∞–∫—Å–∏–º—É–º: {df['win_rate'].max():.2%}\")\n",
        "        print()\n",
        "    \n",
        "    if 'train_loss' in df.columns:\n",
        "        print(\"Training Loss:\")\n",
        "        print(f\"  –°—Ä–µ–¥–Ω–µ–µ: {df['train_loss'].mean():.4f}\")\n",
        "        print(f\"  –ü–æ—Å–ª–µ–¥–Ω–µ–µ: {df['train_loss'].iloc[-1]:.4f}\")\n",
        "        print(f\"  –ú–∏–Ω–∏–º—É–º: {df['train_loss'].min():.4f}\")\n",
        "        print()\n",
        "    \n",
        "    # –°—Ç—Ä–æ–∏–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏\n",
        "    plot_win_rate_comparison(df)\n",
        "    plot_metrics(df, PLOT_CONFIG['metrics_to_plot'])\n",
        "    \n",
        "    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Win rate\n",
        "    if 'win_rate' in df.columns:\n",
        "        axes[0, 0].plot(df['step'], df['win_rate'], label='Win Rate', color='green')\n",
        "        axes[0, 0].set_title('Win Rate')\n",
        "        axes[0, 0].set_xlabel('Episode')\n",
        "        axes[0, 0].set_ylabel('Rate')\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "        axes[0, 0].set_ylim([0, 1])\n",
        "    \n",
        "    # Training loss\n",
        "    if 'train_loss' in df.columns:\n",
        "        axes[0, 1].plot(df['step'], df['train_loss'], label='Loss', color='red')\n",
        "        axes[0, 1].set_title('Training Loss')\n",
        "        axes[0, 1].set_xlabel('Episode')\n",
        "        axes[0, 1].set_ylabel('Loss')\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Episode reward\n",
        "    if 'episode_reward' in df.columns:\n",
        "        axes[1, 0].plot(df['step'], df['episode_reward'], label='Reward', color='blue')\n",
        "        axes[1, 0].set_title('Episode Reward')\n",
        "        axes[1, 0].set_xlabel('Episode')\n",
        "        axes[1, 0].set_ylabel('Reward')\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Epsilon\n",
        "    if 'epsilon' in df.columns:\n",
        "        axes[1, 1].plot(df['step'], df['epsilon'], label='Epsilon', color='orange')\n",
        "        axes[1, 1].set_title('Epsilon (Exploration Rate)')\n",
        "        axes[1, 1].set_xlabel('Episode')\n",
        "        axes[1, 1].set_ylabel('Epsilon')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!\")\n",
        "else:\n",
        "    print(\"‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –æ–±—É—á–µ–Ω–∏–µ –±—ã–ª–æ –∑–∞–ø—É—â–µ–Ω–æ.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü–µ—Ä–µ–∏–º–ø–æ—Ä—Ç –º–æ–¥—É–ª—è compare_checkpoints –¥–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π\n",
        "# –í—ã–ø–æ–ª–Ω–∏—Ç–µ —ç—Ç—É —è—á–µ–π–∫—É, –µ—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –æ—à–∏–±–∫—É –ø—Ä–æ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ 'epsilon'\n",
        "import importlib\n",
        "import src.training.compare_checkpoints\n",
        "importlib.reload(src.training.compare_checkpoints)\n",
        "print(\"‚úÖ –ú–æ–¥—É–ª—å compare_checkpoints –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –û—Ü–µ–Ω–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
        "\n",
        "–û—Ü–µ–Ω–∏—Ç–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –ø—Ä–æ—Ç–∏–≤ —Ä–∞–∑–Ω—ã—Ö –æ–ø–ø–æ–Ω–µ–Ω—Ç–æ–≤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º\n",
        "\n",
        "–°—Ä–∞–≤–Ω–∏—Ç–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –≤ round-robin —Ç—É—Ä–Ω–∏—Ä–µ. –ö–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å —Å—ã–≥—Ä–∞–µ—Ç –ø—Ä–æ—Ç–∏–≤ –∫–∞–∂–¥–æ–π –¥—Ä—É–≥–æ–π.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –¥—Ä—É–≥ —Å –¥—Ä—É–≥–æ–º\n",
        "from src.training.compare_checkpoints import compare_checkpoints, plot_comparison_results, print_comparison_results\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
        "COMPARISON_CONFIG = {\n",
        "    \"model_type\": \"dqn\",  # \"dqn\" –∏–ª–∏ \"qlearning\"\n",
        "    \"num_games_per_match\": 100,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–≥—Ä –≤ –∫–∞–∂–¥–æ–º –º–∞—Ç—á–µ\n",
        "    \"epsilon\": 0.01,  # 1% —Ä–∞–Ω–¥–æ–º–∞ (0.01 = 1% —Å–ª—É—á–∞–π–Ω—ã—Ö —Ö–æ–¥–æ–≤)\n",
        "    \n",
        "    \"seed\": 42,\n",
        "    \"device\": None,  # None –¥–ª—è auto-detect, –∏–ª–∏ \"cuda\" –∏–ª–∏ \"cpu\"\n",
        "}\n",
        "\n",
        "# –°–ø–æ—Å–æ–±—ã —É–∫–∞–∑–∞—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç—ã:\n",
        "# 1. –£–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—É—Ç–∏ –∫ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º\n",
        "CHECKPOINT_PATHS = [\n",
        "    # –ü—Ä–∏–º–µ—Ä—ã:\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_5000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_10000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_15000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_20000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_25000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_30000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_35000.pt\",\n",
        "     \"../data/checkpoints/dqn_20251109_180811/dqn_episode_40000.pt\",\n",
        "   #   \"../data/checkpoints/dqn_20251109_000844/dqn_episode_40000.pt\",\n",
        "   #  \"../data/checkpoints/dqn_20251109_000844/dqn_episode_7000.pt\",\n",
        "    # \"../data/checkpoints/dqn_20251109_000844/dqn_episode_8000.pt\",\n",
        "   #  \"../data/checkpoints/dqn_20251108_233748/dqn_episode_10000.pt\",\n",
        "   #  \"../data/checkpoints/dqn_20251108_233748/dqn_episode_13000.pt\",\n",
        "     # \"../data/checkpoints/dqn_20251108_195301/dqn_episode_27000.pt\"\n",
        "     \n",
        "]\n",
        "\n",
        "# 2. –ò–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π—Ç–∏ –≤—Å–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã –≤ –ø–∞–ø–∫–µ\n",
        "# –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞:\n",
        "# CHECKPOINT_DIR = \"data/checkpoints/dqn_20240101_120000\"  # –£–∫–∞–∂–∏—Ç–µ –ø–∞–ø–∫—É —Å —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏\n",
        "# CHECKPOINT_PATHS = sorted(glob.glob(f\"{CHECKPOINT_DIR}/*.pt\"))\n",
        "\n",
        "# 3. –ò–ª–∏ –Ω–∞–π—Ç–∏ –≤—Å–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É\n",
        "# CHECKPOINT_PATHS = sorted(glob.glob(\"data/checkpoints/**/dqn_episode_*.pt\", recursive=True))\n",
        "\n",
        "if not CHECKPOINT_PATHS:\n",
        "    print(\"‚ö†Ô∏è  –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç–∏ –∫ —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º –≤ CHECKPOINT_PATHS!\")\n",
        "    print(\"–ò–ª–∏ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –∫–æ–¥ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤.\")\n",
        "else:\n",
        "    print(f\"üìã –ù–∞–π–¥–µ–Ω–æ {len(CHECKPOINT_PATHS)} —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:\")\n",
        "    for i, path in enumerate(CHECKPOINT_PATHS, 1):\n",
        "        print(f\"  {i}. {path}\")\n",
        "    \n",
        "    print(f\"\\n‚öôÔ∏è  –ù–∞—Å—Ç—Ä–æ–π–∫–∏:\")\n",
        "    print(f\"  –¢–∏–ø –º–æ–¥–µ–ª–∏: {COMPARISON_CONFIG['model_type']}\")\n",
        "    print(f\"  –ò–≥—Ä –≤ –º–∞—Ç—á–µ: {COMPARISON_CONFIG['num_games_per_match']}\")\n",
        "    print(f\"  Epsilon (—Ä–∞–Ω–¥–æ–º): {COMPARISON_CONFIG['epsilon']:.1%} ({COMPARISON_CONFIG['epsilon']*100:.1f}% —Å–ª—É—á–∞–π–Ω—ã—Ö —Ö–æ–¥–æ–≤)\")\n",
        "    print(f\"  Seed: {COMPARISON_CONFIG['seed']}\")\n",
        "    \n",
        "    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ\n",
        "    print(f\"\\nüöÄ –ó–∞–ø—É—Å–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è...\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    results = compare_checkpoints(\n",
        "        checkpoint_paths=CHECKPOINT_PATHS,\n",
        "        model_type=COMPARISON_CONFIG[\"model_type\"],\n",
        "        num_games_per_match=COMPARISON_CONFIG[\"num_games_per_match\"],\n",
        "        epsilon=COMPARISON_CONFIG[\"epsilon\"],\n",
        "        device=COMPARISON_CONFIG[\"device\"],\n",
        "        seed=COMPARISON_CONFIG[\"seed\"],\n",
        "        reward_config=RewardConfig,\n",
        "        use_epsilon=True,\n",
        "        verbose=True,\n",
        "    )\n",
        "    \n",
        "    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "    print_comparison_results(results)\n",
        "    \n",
        "    # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
        "    print(\"\\nüìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...\")\n",
        "    plot_comparison_results(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from src.training.eval_model import evaluate_model_against_opponents\n",
        "\n",
        "def evaluate_checkpoints_and_plot(\n",
        "    checkpoint_dir=\"../data/checkpoints/dqn_20251109_102818\",\n",
        "    checkpoint_pattern=\"*.pt\",\n",
        "    model_type=\"dqn\",\n",
        "    opponents=(\"random\", \"heuristic\", \"smart_heuristic\"),\n",
        "    num_episodes=200,\n",
        "    seed=42,\n",
        "    epsilon=0.01\n",
        "):\n",
        "    \"\"\"\n",
        "    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç –≤—Å–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã –≤ –ø–∞–ø–∫–µ –ø—Ä–æ—Ç–∏–≤ –∑–∞–¥–∞–Ω–Ω—ã—Ö –æ–ø–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏ —Å—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫ winrate.\n",
        "    \"\"\"\n",
        "    # –°–æ–±–∏—Ä–∞–µ–º —Å–ø–∏—Å–æ–∫ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –µ–≥–æ (–ø–æ –Ω–æ–º–µ—Ä—É —ç–ø–∏–∑–æ–¥–∞, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)\n",
        "    pattern = os.path.join(checkpoint_dir, checkpoint_pattern)\n",
        "    def extract_version(path):\n",
        "        import re\n",
        "        filename = os.path.basename(path)\n",
        "        m = re.search(r\"(\\d+)\", filename)\n",
        "        return int(m.group(1)) if m else 0\n",
        "\n",
        "    checkpoint_paths = sorted(glob.glob(pattern), key=extract_version)\n",
        "\n",
        "    if not checkpoint_paths:\n",
        "        print(\"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã —á–µ–∫–ø–æ–∏–Ω—Ç—ã –ø–æ –ø—É—Ç–∏:\", pattern)\n",
        "        return\n",
        "\n",
        "    print(f\"üîç –ù–∞–π–¥–µ–Ω–æ {len(checkpoint_paths)} —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤\")\n",
        "    print(f\"–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ—Ç–∏–≤ {opponents} —Å epsilon={epsilon:.2f} ({epsilon*100:.1f}% random) –Ω–∞ {num_episodes} –ø–∞—Ä—Ç–∏—è—Ö\")\n",
        "    print(\"{:<25} {:>8} {:>12} {:>12} {:>12}\".format(\"Checkpoint\", \"Version\", \"Random\", \"Heuristic\", \"SmartHeur\"))\n",
        "\n",
        "    versions = []\n",
        "    winrates_by_opponent = {opp: [] for opp in opponents}\n",
        "    checkpoint_names = []\n",
        "\n",
        "    for i, path in enumerate(checkpoint_paths, 1):\n",
        "        version = extract_version(path)\n",
        "        print(f\"[{i}/{len(checkpoint_paths)}] {os.path.basename(path)}...\", end=\" \", flush=True)\n",
        "\n",
        "        results = evaluate_model_against_opponents(\n",
        "            model_path=path,\n",
        "            model_type=model_type,\n",
        "            opponents=opponents,\n",
        "            num_episodes=num_episodes,\n",
        "            seed=seed,\n",
        "            use_epsilon=True,\n",
        "        )\n",
        "\n",
        "        # –í—Ä—É—á–Ω—É—é —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º epsilon (–¥–ª—è DQN —Å–¥–µ–ª–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç –µ—Å–ª–∏ –∞–≥–µ–Ω—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç)\n",
        "        try:\n",
        "            from src.agents import QLearningAgent, DQNAgent\n",
        "            if model_type == \"qlearning\":\n",
        "                agent = QLearningAgent(seed=seed)\n",
        "                agent.load(path)\n",
        "            else:\n",
        "                agent = DQNAgent(rows=6, cols=7, seed=seed)\n",
        "                agent.load(path)\n",
        "            if hasattr(agent, 'epsilon'):\n",
        "                agent.epsilon = epsilon\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        versions.append(version)\n",
        "        checkpoint_names.append(os.path.basename(path))\n",
        "        winrates = []\n",
        "        for opp in opponents:\n",
        "            win_rate = results[opp][\"win_rate\"]\n",
        "            winrates.append(win_rate)\n",
        "            winrates_by_opponent[opp].append(win_rate)\n",
        "        print(\"{:<25} {:>8} {:>12.2%} {:>12.2%} {:>12.2%}\".format(\n",
        "            os.path.basename(path),\n",
        "            version,\n",
        "            winrates[0], winrates[1], winrates[2]\n",
        "        ))\n",
        "\n",
        "    # –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    for opp in opponents:\n",
        "        plt.plot(versions, winrates_by_opponent[opp], marker='o', label=opp)\n",
        "    plt.title(f\"Win rate vs different opponents (epsilon={epsilon:.2f}, {num_episodes} –∏–≥—Ä)\")\n",
        "    plt.xlabel(\"Checkpoint version\")\n",
        "    plt.ylabel(\"Win rate\")\n",
        "    plt.ylim(0, 1)\n",
        "    plt.grid(True)\n",
        "    plt.legend(title=\"Opponent\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate_checkpoints_and_plot(checkpoint_dir=\"../data/checkpoints/dqn_20251109_180811\", use_epsilon=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate_checkpoints_and_plot(checkpoint_dir=\"../data/checkpoints/dqn_20251109_193645\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate_checkpoints_and_plot(checkpoint_dir=\"../data/checkpoints/dqn_20251109_170952\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluate_checkpoints_and_plot(checkpoint_dir=\"../data/checkpoints/dqn_20251109_110859\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
